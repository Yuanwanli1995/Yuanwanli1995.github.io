<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>加载github很慢怎么解决？</title>
    <url>/2021/08/26/2021-08-27-%E5%8A%A0%E8%BD%BDgithub%E5%BE%88%E6%85%A2%E6%80%8E%E4%B9%88%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<h2 id="在使用github的时候常常用到加载很慢的或加载不出来的问题，对我们的学习工作造成一定阻碍"><a href="#在使用github的时候常常用到加载很慢的或加载不出来的问题，对我们的学习工作造成一定阻碍" class="headerlink" title="在使用github的时候常常用到加载很慢的或加载不出来的问题，对我们的学习工作造成一定阻碍"></a>在使用github的时候常常用到加载很慢的或加载不出来的问题，对我们的学习工作造成一定阻碍</h2><p>尝试有效的解决方法：在你的电脑里添加github的ip地址</p>
<p><code>进入C:\Windows\System32\drivers\etc</code></p>
<p>使用记事本编辑host文件，将下面内容追加到host文件中</p>
<pre><code># github
204.232.175.78 http://documentcloud.github.com
207.97.227.239 http://github.com
204.232.175.94 http://gist.github.com
107.21.116.220 http://help.github.com
207.97.227.252 http://nodeload.github.com
199.27.76.130 http://raw.github.com
107.22.3.110 http://status.github.com
204.232.175.78 http://training.github.com
207.97.227.243 http://www.github.com`
</code></pre>
<p> 保存即可</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>我为什么要记读书笔记</title>
    <url>/2021/08/26/2021-08-27-%E5%BC%80%E5%A7%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p>最近几年一直有读书的习惯，每个月也有读几本书，我深知读书记笔记可以加深印象，促进理解。但不是每一篇都记了笔记。</p>
<h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p>我习惯使用kindle看书，因为kindle下载书籍很方便，而且kindle很便捷，在地铁、车上随时随地都可以使用。但是记笔记没那么方便了，大多数时候一本书看完了就好像完成了一个任务一样，就懒得再去思考整理记笔记了。 </p>
<h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><p>虽然我看书也不求收获，基本当成一个对抗无聊、转移注意力使得自己尽量不在网上冲浪的习惯， 当然遇到质量高的书籍也确实十分有趣。但我近来越发感受到人对事物的了解或对知识的理解是有程度的区别的，这是很显然易见的问题，但我对这个问题的重视并不够。举例来说，有一次导师让我审稿一篇文章，我拿到论文游览一遍之后，懵了，虽然大部分句子都能读通，但完全不知道作者在做什么。没有办法，我只能一遍一遍的读，我明显能感觉到，越看越明白了。第十次读完的时候，我差不多看懂了，第十五次读完的时候，完成了一篇审稿意见。回过头来看，我大受震撼，这里蕴含的规律就是古人说的”书读百遍，其意自现”。这是感性的认识， 认识论的观点就是“认识运动是不断反复和无限发展的，即人类的认识是永无止境、无限发展的，它表现为实践、认识、再实现、再认识的无限循环过程，由低级阶段向高级阶段不断推移的永无止境的前进运动，这种无限发展过程，在形式上是循环往复，实质上是前进上升“。</p>
<h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><p>我说这些是什么意思呢？我就是想说，根据我的经验，对于我来说，读书若只是风卷残云过一遍，当时可能有点印象，但一段时间过后，就什么也不记得啦。《非暴力沟通》我看了2遍，你让我说说非暴力沟通的方法，我答不上来。认识指导实践，认识若只停留在表面，那么如何指导实践呢？ 也就是学习要学的深一点。 </p>
<h2 id="5"><a href="#5" class="headerlink" title="5"></a>5</h2><p>那么如何深一点呢？ 如何深入的理解，与作者对话，带入自己的经验呢？方法有很多，可以多读几遍、向别人转述，也可以记笔记。在记笔记的时候有助于引导加深记忆，引导自己思考。<br>所以以后在这里记笔记啦。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《幸福的勇气》</title>
    <url>/2021/09/07/2021-09-07-%E3%80%8A%E5%B9%B8%E7%A6%8F%E7%9A%84%E5%8B%87%E6%B0%94%E3%80%8B/</url>
    <content><![CDATA[<h1 id="人们误解了阿德勒的思想"><a href="#人们误解了阿德勒的思想" class="headerlink" title="人们误解了阿德勒的思想"></a>人们误解了阿德勒的思想</h1><blockquote>
<p>加入有人一接触阿德勒思想便立即感激的说，“活的更轻松了”，那么这个人一定是大大误解了阿德勒。因为，如果真正理解了阿德勒对我们提出的要求，那就一定会震惊于他的严厉。 </p>
</blockquote>
<p>确实，如果一种观点或思想能做的让你在相同的境遇下，活的更轻松一些，减少痛苦。那么并不能说明这种思想的正确性，完全可能是宗教。 另外，难道人去追求的思想，就一定是使得自己活的更轻松的观点吗？如果说，现实就是，付出一些辛苦也可以获得幸福，我想我们也没有理由抱怨。我们不应该期望，存在一种思想，只要了解它，我们就可以轻而易举获得幸福，而不需要付出，这就是自娱自乐，自欺欺人的说辞。</p>
<blockquote>
<p>幸福并非一劳永逸的事情，必须在幸福之路上坚持不懈地努力向前。</p>
</blockquote>
<h2 id="第一章-可恶的他人-可怜的自己"><a href="#第一章-可恶的他人-可怜的自己" class="headerlink" title="第一章 可恶的他人 可怜的自己"></a>第一章 可恶的他人 可怜的自己</h2><h4 id="1阿德勒心理学是宗教吗"><a href="#1阿德勒心理学是宗教吗" class="headerlink" title="1阿德勒心理学是宗教吗"></a>1阿德勒心理学是宗教吗</h4><p>首先，阿德勒心理学不是传统的科学，因为其不可证伪。</p>
<p>宗教和哲学的区别是宗教说故事，而哲学永远在求知。 </p>
<p>宗教宣传无所不知，而哲学成为自己无知之知。 </p>
<h4 id="2-教育的目标是自立"><a href="#2-教育的目标是自立" class="headerlink" title="2 教育的目标是自立"></a>2 教育的目标是自立</h4><blockquote>
<p>教育的目标价简而言之就是自立</p>
<p>人人都有逃脱无力状态不断追求进步的需求，也就是优越性追求。</p>
<p>教育不是干涉，而是帮助其自立</p>
</blockquote>
<h4 id="3-所谓尊重就是实事求是的看待一个人"><a href="#3-所谓尊重就是实事求是的看待一个人" class="headerlink" title="3 所谓尊重就是实事求是的看待一个人"></a>3 所谓尊重就是实事求是的看待一个人</h4><blockquote>
<p>尊重就是实事求是的看待一个人并认识到其独特个性的能力 ——埃里克 弗洛姆</p>
<p>不做任何否定，不做任何强迫，接受并尊重那个人真实的样子</p>
</blockquote>
<p>即使是你不喜欢的、 你反感的、你觉得没有用的、你觉得没有价值、你觉得违反公共秩序和社会良俗的 ，但是 是 真实的。 </p>
<blockquote>
<p>尊重就是要努力低使对方能成长和发展自己</p>
<p>即使你能够将其带到水边也无法强迫其喝水</p>
</blockquote>
<h4 id="4-关心他人兴趣"><a href="#4-关心他人兴趣" class="headerlink" title="4 关心他人兴趣"></a>4 关心他人兴趣</h4><blockquote>
<p>对他人的兴趣给予更多关心</p>
<p>用他的眼睛去看，用他的耳朵去听，用他人的心去感受</p>
<p>孩子们并不认为自己的兴趣粗俗 </p>
</blockquote>
<p>这一点并不一定，一个人经常做的事并不非要是其内心也十分肯定的事。人的行为受到多方面的影响，并不是只有自己喜不喜欢决定。 </p>
<h4 id="5-加入拥有同样的心灵和人生"><a href="#5-加入拥有同样的心灵和人生" class="headerlink" title="5 加入拥有同样的心灵和人生"></a>5 加入拥有同样的心灵和人生</h4><blockquote>
<p>人不是活在客观的世界而是活在自己营造的主观世界里 </p>
<p>假如我拥有和此人一样的心灵和人生情况会如何？</p>
<p>共鸣是接近他人的技术和态度</p>
</blockquote>
<h4 id="6-勇气会传染，尊重也会"><a href="#6-勇气会传染，尊重也会" class="headerlink" title="6 勇气会传染，尊重也会"></a>6 勇气会传染，尊重也会</h4><blockquote>
<p>正因为对他们是人， 才必须给予最大的尊重。不俯视、不仰视、不讨好、平等以待、对他们感兴趣的事物产生共鸣。 </p>
<p>由你开始，即使没人理解和赞同，你也必须首先点亮火把，展示勇气和尊重。火把照亮的范围最多也就是半径数米，也许感觉像是一个人走在空无一人的夜道路上。但是数百米外的人也可以看到你所举着的火把。大家就会知道那里有人，有光，走过去有路。不久，你的周围就会聚集数十数百盏火把，数十数百的人们都会被这些火把照亮。 </p>
</blockquote>
<h4 id="7-无法改变的真正理由"><a href="#7-无法改变的真正理由" class="headerlink" title="7 无法改变的真正理由"></a>7 无法改变的真正理由</h4><blockquote>
<p>在判定自己言行以及他人言行时，思考其背后所蕴含的目的。</p>
<p>无法改变的真正理由是，不想改变。</p>
<p>决定我们生活方式的并不是过去的经历，而是我们自己赋予经历的意义。</p>
<p>为了肯定现在而去肯定不幸的经历</p>
<p>我们这个世界上根本不存在什么真正意义的过去</p>
</blockquote>
<h4 id="8-你的现在决定了过去"><a href="#8-你的现在决定了过去" class="headerlink" title="8 你的现在决定了过去"></a>8 你的现在决定了过去</h4><blockquote>
<p>历史是被时代掌权者不断篡改的一个巨大故事。历史常常按照掌权者指定的是非观被巧妙的篡改。一切年表和史书都是被篡改过的伪书，目的就是为了证明时代掌权者的正统性。</p>
<p>人人都是“我”这个故事的编纂者，为了证明现在我的正统性，其过去往往会被随意改写。</p>
<p>人会从过去发生的庞大事件系统中只选择符合现在目的的时间按并赋予其意义，继而当作自己的记忆。反过来说就是不符合现在目的的事件就会被抹掉。</p>
</blockquote>
<h4 id="9-可恶的他人，可怜的自己"><a href="#9-可恶的他人，可怜的自己" class="headerlink" title="9 可恶的他人，可怜的自己"></a>9 可恶的他人，可怜的自己</h4><blockquote>
<p>心理咨询者无非是在讨论可恶的他人或可怜的自己</p>
</blockquote>
<h4 id="10-阿德勒心理学并无魔法"><a href="#10-阿德勒心理学并无魔法" class="headerlink" title="10 阿德勒心理学并无魔法"></a>10 阿德勒心理学并无魔法</h4><blockquote>
<p>我并非因为冷漠而置若罔闻，是因为这些事情不值得讨论。</p>
<p>阿德勒心理学要讨论的是 ”以后要怎么做？“</p>
<p>阿德勒心理学并不是神秘的魔法，而是具有建设性和科学性并基于对人的尊重的一种理解人性的心理学。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>心理学导论</title>
    <url>/2021/09/07/2021-09-07-%E5%BF%83%E7%90%86%E5%AD%A6%E5%AF%BC%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="1-心理学不是什么？"><a href="#1-心理学不是什么？" class="headerlink" title="1 心理学不是什么？"></a>1 心理学不是什么？</h3><ol>
<li>心理学不是算命，不是看面相，不是看星座。</li>
<li>心理学不仅是心理治疗，研究人心理的方方面面。</li>
<li>“心理就是让人开心一点，正面一点，积极一点” 并不是这样</li>
<li>心理学研究不仅仅是常识，心理学可以发现常识的错误。</li>
</ol>
<h3 id="2-什么是心理学？"><a href="#2-什么是心理学？" class="headerlink" title="2 什么是心理学？"></a>2 什么是心理学？</h3><p>定义：心理学是一门研究人的行为、心理过程的科学。</p>
<p>理解：</p>
<ol>
<li>首先心理学是一门科学，需要证伪、客观、预测、经验、观察、假设、测试。 是用科学的方法得出的结论，而并非凭空想象。</li>
<li>其次心理学研究生的是人的外在行为和心理特征。 </li>
</ol>
<blockquote>
<p>学科的定义可以从两发面分析讨论，学科研究的问题与方法</p>
</blockquote>
<p>心理过程包括那些？</p>
<ul>
<li>感觉，是个体对刺激物个别属性的觉察，它是客观的、直接的，是大脑的一种机能。</li>
<li>知觉， 是对刺激物的整体觉察，是对感觉信息的整合和解释，它主观色彩更浓。</li>
<li>记忆， 是人获取信息并加工储存并提取信息的过程</li>
<li>学习，人们有经验产生的知识活行为，产生相对永久的改变</li>
<li>判断， 思维是信息的交换、加工和理解的过程。</li>
<li>决策，</li>
<li>情绪， 情绪是由内外刺激所引发的一种主观状态， 它由主观的感受、生理的反应、认知的评估、行为的反应等四种成分交互而成。</li>
<li>意识，意识是对我们自身、对行为、对周围世界的觉知，是人类特有的心理现象。</li>
<li>社会关系</li>
<li>社会行为</li>
<li>道德意识</li>
</ul>
<p>心理学的一些概念：</p>
<ul>
<li>自我，指个人心目中对自己的印象包括对自己存在的认识，身体能力、性格、态度、思想等方面的认识。</li>
<li>动机和需要， 激发和维持和调节二体进行某种活动，并出示该活动朝向某一目标的心理倾向或动力。</li>
<li>社会心理学，人在社会环境中的行为、思想和情感、包括社会认知、社会关系社会影响等。</li>
<li>发展心理学， 发展心理学研究欣慰和能力的逐步变化，包括生命从过一个受精卵到死亡的每个阶段。</li>
<li>创造，创造力或创造性才思，是一种基于概念工具以及精神上技巧的人类精神现象而最终产生或发展为创意启发及直觉的过程。</li>
<li>审美，即人所进行的一切创造和欣赏美的活动。是构成人对现实的审美关系，满足人的精神需要的实践、心理活动。是理智与直觉、认识与创造、功利性与非功利性的统一。</li>
<li>幸福，幸福不单单是快乐情绪，快乐与幸福的区别在于，快乐常指个人的、短时间的情绪感受；幸福则涉及到与他人、家庭的长期正面的交互过程，以及度事业、生活发展的积极的体验和认识 。</li>
<li>道德，指衡量行为正当与否的观念标准。</li>
<li>文化，指生物在其发展的过程中逐步积累起来的跟自身生活相关的知识或经验，是其适应自然环境或周围环境的体现，不同的人对文化的有不同的定义，广义上的文化包括文字、语言、建筑、饮食、工具、技能、知识、习俗、艺术等。</li>
</ul>
<blockquote>
<p>心理学的负向倾向，即心理学多研究人的负面情绪的倾向。、</p>
</blockquote>
<h3 id="3-心理学研究领域"><a href="#3-心理学研究领域" class="headerlink" title="3 心理学研究领域"></a>3 心理学研究领域</h3><p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E5%BF%83%E7%90%86%E5%AD%A61.png"></p>
<h3 id="4-实验方法简介"><a href="#4-实验方法简介" class="headerlink" title="4 实验方法简介"></a>4 实验方法简介</h3><p>科学研究方法的三大原则 ：</p>
<ul>
<li>证据</li>
<li>证明</li>
<li>证伪</li>
</ul>
<p>问题的提出，设计实验，数据收集，探索分析</p>
<ul>
<li>真实验，指的是有操纵、有控制、能够随机分派被试的实验研究。 </li>
<li>准实验，指的是无需安排被试，运用原始样本在比较自然的情况下进行实验处理的研究。</li>
<li>数据收集指的是研究者为了描述或解释心理现象而采用观察、自我报告或生理计量等方法采集心理或行为数据的过程。（观察法、自我报告、自动采集）</li>
<li>自我报告法，是心理学用来研究人的心理活动的一种方法，有被测试者对自我主观体验和主观状态进行自我观察，并进行自我评定。</li>
</ul>
<h3 id="5-社会赞许性及数据采集"><a href="#5-社会赞许性及数据采集" class="headerlink" title="5 社会赞许性及数据采集"></a>5 社会赞许性及数据采集</h3><ul>
<li><p>社会赞许性, 是个体为了给他人留下好印象或出于自己的心理的需要， 而表现出良好形象的倾向。</p>
</li>
<li><p>朴素现实主义，我们经常不认为自己不知道，而认为自己知道，也就是我们认为自己所让认为的世界就是现实世界。 </p>
</li>
<li><p>简单重复效应,  或单纯曝光效应，指的是我们会偏好自己熟悉的事物。</p>
</li>
<li><p>自动采集法，记录社交网络数据</p>
</li>
</ul>
<h3 id="6-实验研究设计"><a href="#6-实验研究设计" class="headerlink" title="6 实验研究设计"></a>6 实验研究设计</h3><p>三种方法：描述性研究，相关性研究</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E5%BF%83%E7%90%86%E5%AD%A62.png"></p>
<p><strong>为什么相关不等于因果？</strong></p>
<ol>
<li> 因果比相关更复杂</li>
<li> 受到第三方因素影响</li>
</ol>
<h3 id="7-伦理问题"><a href="#7-伦理问题" class="headerlink" title="7 伦理问题"></a>7 伦理问题</h3><p><strong>伦理原则</strong></p>
<ol>
<li><p>知情同意， 需要被试者在自觉、自愿的条件下，参加心理学的实验，不能强迫，不能欺骗，实验前应尽量地告诉被试实验的足够多的内容，可以随时退出实验。</p>
</li>
<li><p> 事后说明， 被试要求，事后说明，如果试验中有不适当的地方，不应该牵涉到的隐私，必须让被试有足够的了解，有身体、心理的不适，必须使其恢复。</p>
</li>
<li><p>最小风险原则，不能侵犯被试的隐私，不能造成伤害，最起码的标准，就是被试者走进实验室是啥样，出来也应该是啥样。  </p>
</li>
</ol>
<p><strong>人类有五大终极问题 NBICS</strong> </p>
<ol>
<li>N, 纳米技术</li>
<li>B, 生物科学</li>
<li>I, 信息技术</li>
<li>C, 认知思维科学</li>
<li>S, 社会科学</li>
</ol>
<h3 id="8-心理学的历史"><a href="#8-心理学的历史" class="headerlink" title="8 心理学的历史"></a>8 心理学的历史</h3><p>心理学有一个长期的过去，但是只有一个短暂的历史——艾宾浩斯</p>
<ol>
<li><p> 冯特创建心理学第一个实验 冯特心理学之父 。学生铁钦拿，将心理学实验带到美国，结构主义。</p>
</li>
<li><p>机能主义， 是心理学历史的第二个流派， 主张研究人类意识及其功能。詹姆士为首。 威廉 詹姆斯 认为意识就像一条生命的泉水，源源不断融入到我们的心中，所以他创造了一个概念 - 意识流。 信奉达尔文主义，认为人类的心理活动，都是几千万年， 人类进化选择出来的心理特征和心理特质， 都有其存在的意义。</p>
</li>
<li><p>精神分析理论 佛洛依德 , 20世纪最有影响的心理学家，对人类的哲学，艺术，历史学，社会学，政治学都有非常大的影响。 主要理论，冰山理论，潜意识理论，心理发展阶段理论，心理防御机制。很多观点和理论缺乏科学证据。</p>
</li>
<li><p>行为主义，约翰-华生， 研究可以观察、测量、定义的心理学变量——行为。行为是人类外显的表现，可以做具体的观察、研究。是对外在刺激一种自发、自动的反应。   任何人如果给予足够的行为和塑造，可以让他变成我们所期望的任何其他人。——华生  斯金钠  郭任远</p>
</li>
<li><p>人文主义， 马斯洛 人类有很多的需求， 有些需求，是我们基本的生存需求，但是人类也有很多更高级的追求，在基本需求满足以后，我们人类一定会追求高级的心理需求。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E5%BF%83%E7%90%86%E5%AD%A64.png"></p>
<p>自我实现者的十五种的心理特质</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E5%BF%83%E7%90%86%E5%AD%A65.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E5%BF%83%E7%90%866.png"></p>
</li>
</ol>
<p><strong>为什么心理学有这么多的学派？</strong> </p>
<p>核心的问题， 心理学的复杂， 心理活动的不可琢磨， 心理研究的巨大挑战。</p>
<p>各个流派抓住了心理的不同角度， 整合起来就形成了对心理的基本判断。 </p>
<p><strong>心理学未来如何发展呢</strong>？</p>
<ol>
<li>认知神经领域， 结合脑科学更深刻认识人的认知过程。</li>
<li>文化心理学，东方和西方人在思维，意识上有许多差异。</li>
<li>积极心理学 ，马丁 撒里格曼 ，心理学应该关注人的美德，优点和优良行为。</li>
</ol>
<h3 id="9-感觉是什么"><a href="#9-感觉是什么" class="headerlink" title="9 感觉是什么"></a>9 感觉是什么</h3><ul>
<li> 感觉是人脑对直接作用于各种感官系统的一种个体属性的直接反应。</li>
<li>五大感官系统， 视觉、听觉、触觉、嗅觉、味觉。 </li>
</ul>
<p>感官系统的分析角度 </p>
<ol>
<li> 信息的来源</li>
<li>感官的生理器官 </li>
<li>产生的心理现象</li>
</ol>
<h3 id="10-感觉的作用"><a href="#10-感觉的作用" class="headerlink" title="10 感觉的作用"></a>10 感觉的作用</h3><p>感觉让我生活的更加的积极，主动。失去感觉，让人类非常痛苦。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>计算机网路</title>
    <url>/2021/09/08/2021-09-09-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E8%B7%AF%E8%AF%BE%E7%A8%8B%E7%9B%AE%E6%A0%87/</url>
    <content><![CDATA[<h2 id="计算机网路课程目标"><a href="#计算机网路课程目标" class="headerlink" title="计算机网路课程目标"></a>计算机网路课程目标</h2><p>笔记中科大 郑烇老师计算网络课程</p>
<p>掌握计算机网路</p>
<ol>
<li> 基本概念</li>
<li>常用原理</li>
<li>常用技术</li>
</ol>
<p>如何学好这门课 </p>
<ul>
<li>注重基础概念的理解， 大量基础概念</li>
<li>注重逻辑推理  </li>
<li>下功夫</li>
</ul>
<h2 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h2><ul>
<li>计算机网络和互联网</li>
<li>应用层</li>
<li>传输层</li>
<li>网络层： 数据平面</li>
<li>网络层： 控制平面</li>
<li>数据链路层和局域网</li>
<li>网络安全</li>
<li>无线和移动网路</li>
<li>多媒体网路</li>
<li>网路管理</li>
</ul>
<h2 id="第一章-概论"><a href="#第一章-概论" class="headerlink" title="第一章 概论"></a>第一章 概论</h2><h3 id="1-1-什么是internet"><a href="#1-1-什么是internet" class="headerlink" title="1.1 什么是internet"></a>1.1 什么是internet</h3><p>概念定义 ： </p>
<ul>
<li>网络， 节点和边组成的结构</li>
<li>计算机网络， 有计算机为点组成的网络结构</li>
<li>节点， 主机节点，(host, end system)主机及其上运行的应用程序。交换节点，路由器交换机等网络交换设备</li>
<li>边，通信道路。接入网链路，主机连接到互联网的链路。主干链路，路由器间的链路。</li>
<li>协议，对等层的实体（或多个实体）进行通信的规则的集合。规定pdu的格式，次序，动作。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E7%BD%91%E8%B7%AF1.jpg"></p>
<ol>
<li>物理层：简单地说，物理层协议对与基本物理信号传输有关的机械、电气等功能进行描述。若生产相互连接的两个设备的两个厂商都遵循相同物理层规范，则二者必定能被连接在一起，并能接收对方发来的电、光或其他的物理信号，而且能正确地将这些物理信号理解为二进制的0和1序列。物理层只负责正确地接收和发送比特，并不关心这些比特的具体含义。</li>
<li>数据链路层<strong>：</strong>数据链路层简称链路层，它依赖物理层提供的比特传输能力把数据组织成为有边界的传输单位，称为“帧”。链路层把来自网络层的数据组织成“帧”，然后再通过物理层向外发送。当然，链路层也要负责从来自物理层的比特序列（或者字节序列）中区分出一个个的帧，并将帧中的数据传递给网络层。为了将各个帧区分开来，需要在帧的头部和尾部附加一些特点的信息，这个过程称为“封装”，其相反的过程称为“解封装”。“封装”的概念不只在链路层中存在，在更高的各层协议中同样存在。所有层上的“封装”问题的共同特征是把来自高层的封装单位根据本层的需要附加上特定信息形成本层的封装单位，然后向低层传递，同时把来自低层的数据解封装后向高层传递。另外，链路层还可以有其他的诸如差错校验、流量控制等功能，但要理解整个协议体系，则首先应记住它和帧之间的密切关系，因为帧使无头无尾的比特序列变成容易控制的有界单位。</li>
<li><a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E5%B1%82">网络层</a>：网络层解决如何标识通信各方和数据如何从源到达目的这个问题。网络层用特定的网络层地址来标识整个网络中的一个节点，并负责使来自传输层的应该到达某个网络层地址的数据能够被送达这个网络层地址所对应的网络节点。网络层的封装单位称为“包”，“包”需要被进一步封装成链路层的帧然后才能通过物理层发送出去，而在接收方，包在链路层的帧中被解封装出来。最典型的的网络层协议就是在Internet中使用的IP协议，它使用IP地址唯一地标识Internet中的一台主机，路由设备根据IP包中的目的IP地址将IP包一步步转发至目的主机。</li>
<li><a href="https://baike.baidu.com/item/%E4%BC%A0%E8%BE%93%E5%B1%82">传输层</a>：依赖物理层、数据链路层和网络层，任意一个网络节点都能把任何信息传递到其他任意节点，而传输层在物理层、数据链路层和网络层提供的节点间的通信能力基础上进一步提供了面向应用的服务。传输层向上层提供屏蔽了传输细节的数据传输服务，将来自高层的数据进行分段并将来自低层的数据重组，对数据传输进行差错恢复和流量控制。通过对每个网络节点的多个进程进行标识，传输层可以实现对网络层的多路复用。</li>
<li><a href="https://baike.baidu.com/item/%E4%BC%9A%E8%AF%9D%E5%B1%82/4329656">会话层</a>：会话层用于建立和管理不同主机的两个进程之间的对话。会话层可以管理对话，可允许对话在两个方向上同时进行，也可以强制对话同时只在一个方向上进行。在后一种情况下，会话层可以提供会话令牌来控制某时刻哪一方可以发生数据。会话层还可以提供同步服务，它可以在数据流中插入同步点，每当因网络出现故障而造成大量数据传输中断时，通过同步点机制可以使两个进程之间的数据传输不需要从头开始，而是从最后一个同步点开始继续传输。</li>
<li><a href="https://baike.baidu.com/item/%E8%A1%A8%E7%A4%BA%E5%B1%82/4329716">表示层</a>：表示层协议规定对来自应用层的数据如何进行表达，例如采用什么样的文字编码、是否及如何进行压缩、是否及如何加密等。</li>
<li><a href="https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E5%B1%82/16412033">应用层</a>：应用层是ISO/OSI模型中最靠近用户的一层，<a href="https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE/3668945">应用层协议</a>直接面对用户的需求，例如与发送邮件相关的应用层协议可以规定诸如邮件地址的格式、邮件内容的段落表示、客户与服务器进行交互的命令串等。</li>
</ol>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E7%BD%91%E8%B7%AF2.png"></p>
<ul>
<li> PDU,协议数据单元</li>
</ul>
<blockquote>
<p>从服务角度，internet分为分布式应用和提供服务的基础设施。</p>
</blockquote>
<h3 id="1-2-网路边缘"><a href="#1-2-网路边缘" class="headerlink" title="1.2 网路边缘"></a>1.2 网路边缘</h3><p>网路结构分为三种：</p>
<ol>
<li>网路边缘，主机，应用程序</li>
<li>网路核心，互联着的路由器，网路的网路</li>
<li>接入网、物理媒体， 有线或者无限通信链路</li>
</ol>
<p>网路边缘的两种模式</p>
<ol>
<li> 客户/服务器模式，客户端向服务器请求，接收服务。如web客户端/服务器；email客户端/服务器。</li>
<li>对等(peer-peer)模式</li>
</ol>
<p>面向连接的服务TCP </p>
<ul>
<li>可靠的，有序的，确认重传</li>
<li>浏流量控制，发送方不好淹没接收方</li>
<li>拥塞控制，当网络拥塞时，发送方降低发送频率</li>
</ul>
<p>无连接的服务UDP</p>
<ul>
<li>不打招呼，不可靠</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>VM多台虚拟机网路设置</title>
    <url>/2021/09/09/2021-09-17-VM%E5%A4%9A%E5%8F%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E8%B7%AF%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="VM多台虚拟机网路设置"><a href="#VM多台虚拟机网路设置" class="headerlink" title="VM多台虚拟机网路设置"></a>VM多台虚拟机网路设置</h2><p>背景：我需要多台联网的虚拟机搭建集群，使用vmmare构建，设置网路使得：</p>
<ul>
<li> 虚拟机1，虚拟机2 能联通外网</li>
<li>虚拟机1，虚拟机2能相互ping</li>
<li>虚拟机1，虚拟机2ping通主机 </li>
</ul>
<h3 id="第一步-查看当前主机网路的ip、子网掩码、网关"><a href="#第一步-查看当前主机网路的ip、子网掩码、网关" class="headerlink" title="第一步  查看当前主机网路的ip、子网掩码、网关"></a><strong><code>第一步</code></strong>  查看当前主机网路的ip、子网掩码、网关</h3><p>在cmd中使用 <code>ipconfig</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Users\brisk&gt;ipconfig</span><br><span class="line">Windows IP 配置</span><br><span class="line">...</span><br><span class="line">无线局域网适配器 WLAN:</span><br><span class="line"></span><br><span class="line">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class="line">   IPv6 地址 . . . . . . . . . . . . : 2001:db8:1:0:e9a5:d9a2:231d:a421</span><br><span class="line">   临时 IPv6 地址. . . . . . . . . . : 2001:db8:1:0:157c:d1b:73f2:2c43</span><br><span class="line">   本地链接 IPv6 地址. . . . . . . . : fe80::e9a5:d9a2:231d:a421%8</span><br><span class="line">   IPv4 地址 . . . . . . . . . . . . : 192.168.2.101</span><br><span class="line">   子网掩码  . . . . . . . . . . . . : 255.255.255.0</span><br><span class="line">   默认网关. . . . . . . . . . . . . : fe80::2eb2:1aff:fe5f:5699%8</span><br><span class="line">                                       192.168.2.1</span><br></pre></td></tr></table></figure>

<ul>
<li> ip: 192.168.2.10</li>
<li>子网掩码：255.255.255.0</li>
<li>网关：192.168.2.1 </li>
</ul>
<h3 id="第二步-设置虚拟网卡"><a href="#第二步-设置虚拟网卡" class="headerlink" title="第二步 设置虚拟网卡"></a><strong><code>第二步</code></strong> 设置虚拟网卡</h3><p>网络设配器—&gt;VMnet8—&gt;属性，按照下图所示设置</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/k8s2.png"></p>
<p>将VMnet8的ip设为192.168.1.1，即为win10网络的网关。这里其实就是把vmnet8这个当成一个虚拟的网关了。</p>
<h3 id="第三步-设置NAT"><a href="#第三步-设置NAT" class="headerlink" title="第三步 设置NAT"></a><strong><code>第三步</code></strong> 设置NAT</h3><p>打开vmware中的 编辑—&gt;编辑虚拟网络编辑器 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/k8s3.png"></p>
<h3 id="第四步-编辑每个虚拟机的网络配置"><a href="#第四步-编辑每个虚拟机的网络配置" class="headerlink" title="第四步 编辑每个虚拟机的网络配置"></a><strong><code>第四步</code></strong> 编辑每个虚拟机的网络配置</h3><p>   配置文件在/etc/sysconfig/network-scripts路径下，一个ip配置为192.168.1.10，另一个192.168.1.11.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 </span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens33</span><br><span class="line">UUID=150fb0ae-7bba-4aa1-b6dd-a335f9f116ca</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.2.10</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.2.2</span><br><span class="line">DNS1=114.114.114.114</span><br></pre></td></tr></table></figure>

<p>注意修改的如下： </p>
<ul>
<li>BOOTPROTO=static</li>
<li>ONBOOT=yes</li>
<li>IPADDR=192.168.2.10<br>NETMASK=255.255.255.0<br>GATEWAY=192.168.2.2<br>DNS1=114.114.114.114</li>
</ul>
<p>另一台虚拟机相同设置，只是IPADDR不同， IPADDR=192.168.2.11</p>
<h3 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h3><ol>
<li> 虚拟机ping 百度 </li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@localhost /]# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (36.152.44.95) 56(84) bytes of data.</span><br><span class="line">64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=1 ttl=128 time=18.7 ms</span><br><span class="line">64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=2 ttl=128 time=19.1 ms</span><br><span class="line">64 bytes from 36.152.44.95 (36.152.44.95): icmp_seq=3 ttl=128 time=18.9 ms</span><br><span class="line">^C</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li> 虚拟机1 ping 虚拟机2 </li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# ping 192.168.2.10</span><br><span class="line">PING 192.168.2.10 (192.168.2.10) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.2.10: icmp_seq=1 ttl=64 time=2.88 ms</span><br><span class="line">64 bytes from 192.168.2.10: icmp_seq=2 ttl=64 time=3.05 ms</span><br><span class="line">64 bytes from 192.168.2.10: icmp_seq=3 ttl=64 time=2.22 ms</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>

<ol start="3">
<li> 虚拟机1ping 主机</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost /]# ping 192.168.2.101</span><br><span class="line">PING 192.168.2.101 (192.168.2.101) 56(84) bytes of data.</span><br><span class="line">From 192.168.2.11 icmp_seq=1 Destination Host Unreachable</span><br><span class="line">From 192.168.2.11 icmp_seq=2 Destination Host Unreachable</span><br><span class="line">From 192.168.2.11 icmp_seq=3 Destination Host Unreachable</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>行为经济学</title>
    <url>/2021/09/20/2021-09-20-%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A6/</url>
    <content><![CDATA[<h2 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h2><h2 id="第十二讲-损失厌恶：-赢与输总是绝对的吗？"><a href="#第十二讲-损失厌恶：-赢与输总是绝对的吗？" class="headerlink" title="第十二讲 损失厌恶： 赢与输总是绝对的吗？"></a>第十二讲 损失厌恶： 赢与输总是绝对的吗？</h2><p>损失厌恶：人们讨厌损失</p>
<p>但真的是一种非理性的行为吗? </p>
<p>实验： 训练猴子使用硬币。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A61.png"></p>
<p>从进化论，错配的角度来说，损失厌恶让我更有动力， 有更大的冒险欲望。大脑对盈利和损失是不对称的。 </p>
<p>例子：为什么经营不好的时候， 公司不减低工资而去裁员。降低工资会给员工带来损失厌恶。</p>
<p>框架效应： 同样一个东西， 可以在一个框架下，是盈利的。另一个框架下，是损失的。</p>
<p>处置效应： 卖掉挣钱的，保留亏钱的。 </p>
<p>应用： </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A62.png"></p>
<p>改进：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A63.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A65.png"></p>
<p>沉没成本： </p>
<p>已经失去的损失，我们不应该再留恋他。</p>
<h2 id="第十三讲：-突出事件放大：-为什么有人买彩票"><a href="#第十三讲：-突出事件放大：-为什么有人买彩票" class="headerlink" title="第十三讲： 突出事件放大： 为什么有人买彩票"></a>第十三讲： 突出事件放大： 为什么有人买彩票</h2><p>小概率事件高估： 预期中的偏差 </p>
<p>突出事件较大的权重： 偏好的偏差</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A66.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A67.png"></p>
<h2 id="第十四讲：心智账户：我们把钱存在哪-？"><a href="#第十四讲：心智账户：我们把钱存在哪-？" class="headerlink" title="第十四讲：心智账户：我们把钱存在哪 ？"></a>第十四讲：心智账户：我们把钱存在哪 ？</h2><p>心智账户，人常把钱分到不同的想象的账户里</p>
<p>由于CEO和部门经理的心智账户不同，导致不同投资策略。 </p>
<p>每个人的心智账户都不同。 </p>
<p>一块100元巧克力自己吃，你可能会觉得贵，但是买送给女朋友，你觉得不贵。</p>
<p>因为自己消费的账户和社交不是一个账户</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A68.png"></p>
<p><strong>禀赋效应</strong>是指当个人一旦拥有某项物品，那么他对该物品价值的评价要比未拥有之前大大提高。它是由Richard Thaler(1980)提出的。这一<a href="https://baike.baidu.com/item/%E7%8E%B0%E8%B1%A1/2808631">现象</a>可以用<a href="https://baike.baidu.com/item/%E8%A1%8C%E4%B8%BA%E9%87%91%E8%9E%8D%E5%AD%A6/58795">行为金融学</a>中的“<a href="https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1%E5%8E%8C%E6%81%B6/2921704">损失厌恶</a>”理论来解释，该理论认为一定量的损失给人们带来的效用降低要多过相同的收益给人们带来的效用增加。因此人们在决策过程中对利害的权衡是不均衡的，对“避害”的考虑远大于对“趋利”的考虑。出于对损失的畏惧，人们在出卖商品时往往索要过高的价格。</p>
<h2 id="第十五章：-羊群效应：人为什么喜欢模仿"><a href="#第十五章：-羊群效应：人为什么喜欢模仿" class="headerlink" title="第十五章： 羊群效应：人为什么喜欢模仿"></a>第十五章： 羊群效应：人为什么喜欢模仿</h2><p>羊群效应：人类的群体模仿行为</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A69.png"></p>
<p>人有盲目跟从的冲动 。</p>
<p>镜像神经元：来体会别人的感受</p>
<h2 id="第十六章：-当前偏差-拖延症是怎么来的？"><a href="#第十六章：-当前偏差-拖延症是怎么来的？" class="headerlink" title="第十六章： 当前偏差 拖延症是怎么来的？"></a>第十六章： 当前偏差 拖延症是怎么来的？</h2><p>当前偏差：当前的折现率会高于未来的折现率。会导致我们更看重当前的快乐。</p>
<p>原因：错配</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A610.png"></p>
<p>当前偏差和讲话语言有没有未来时态有关</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A611.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A612.png"></p>
<p>自控是需要消耗能量的，累的时候更难自控</p>
<p>冥想有助于增加前额皮层的灰质 </p>
<p>呼吸变慢有助于让你冷静</p>
<h2 id="第17讲-市场情绪：怎么衡量非理性？"><a href="#第17讲-市场情绪：怎么衡量非理性？" class="headerlink" title="第17讲 市场情绪：怎么衡量非理性？"></a>第17讲 市场情绪：怎么衡量非理性？</h2><p>投资者情绪高：投资者对它有过分的需求，过高的预期，并非基本面的原因</p>
<p>各种偏差的总结。</p>
<p>投资者心情影响股票市场。 </p>
<p>投资者心情可能受到月亮的影响。</p>
<p>罪恶股票和社会价值股票的差异</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A613.png"></p>
<p>如何测量市场情绪？</p>
<p>ipo数量， 新开账户等。</p>
<p>百度指数 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A613.png"></p>
<h2 id="第18讲-低风险策略：低风险可以有高收益么？"><a href="#第18讲-低风险策略：低风险可以有高收益么？" class="headerlink" title="第18讲 低风险策略：低风险可以有高收益么？"></a>第18讲 低风险策略：低风险可以有高收益么？</h2><h2 id="第19讲-高品质策略：巴菲特真的喜欢价值投资么？"><a href="#第19讲-高品质策略：巴菲特真的喜欢价值投资么？" class="headerlink" title="第19讲 高品质策略：巴菲特真的喜欢价值投资么？"></a>第19讲 高品质策略：巴菲特真的喜欢价值投资么？</h2><p>大佬的投资策略</p>
<p>索罗斯和沃森 ：低风险高收益</p>
<p>巴菲特： 高品质投资， 价值投资</p>
<h2 id="第20讲-量化投资的风险有哪些？"><a href="#第20讲-量化投资的风险有哪些？" class="headerlink" title="第20讲 量化投资的风险有哪些？"></a>第20讲 量化投资的风险有哪些？</h2><p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A615.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A616.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A617.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A618.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A619.png"></p>
<p>量化投资策略三个风险： </p>
<p>失效风险</p>
<p>流通性风险 </p>
<p>模型风险</p>
<h2 id="第二十一讲：-量化投资误区有哪些？"><a href="#第二十一讲：-量化投资误区有哪些？" class="headerlink" title="第二十一讲： 量化投资误区有哪些？"></a>第二十一讲： 量化投资误区有哪些？</h2><p>1 基本面好就会收益率高，不一定。 国家GDP增速好不一定股票表现好， 新新行业不一定比老行业收益率高。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A620.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%A1%8C%E4%B8%BA%E7%BB%8F%E6%B5%8E%E5%AD%A621.png"></p>
<p>2 AI 投资不一定比人好。 </p>
<p>3 智能投顾效果有限</p>
<p>4 在国外市场得出的经验不一定在中国有效</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《我们》</title>
    <url>/2021/09/22/2021-09-22-%E3%80%8A%E6%88%91%E4%BB%AC%E3%80%8B%20%E6%91%98%E5%BD%95/</url>
    <content><![CDATA[<h2 id="《我们》-摘录"><a href="#《我们》-摘录" class="headerlink" title="《我们》 摘录"></a>《我们》 摘录</h2><p>叶甫盖尼·扎米亚京  陈超译 </p>
<ul>
<li>上帝曾经让天堂里那两位作出自己的选择：或者选择没有自由的幸福，或者选择没有幸福的自由，第三种选择是没有的。</li>
<li>“这表明，你喜欢。你怕它，是因为它的力量大于你。你讨厌它，是因为你怕它。你喜欢它，是因为你无法使它顺从你。人只喜欢他无法占有的东西。”</li>
<li>自由与犯罪是密不可分的，就像…嗯，就像飞机的运动与它的速度，当它速度为零时，它就是静止的，当人没有自由时，他就不会犯罪。这是很清楚的道理。不让人犯罪的唯一途径就是剥夺他的自由。</li>
<li>“告诉我们什么是最后的数字，最终的数字，最大的数字。” “但这太荒唐了！数字的数目是无限的，怎么会有最后的数字呢？” “那怎么会有最后的革命呢？最后的革命是不存在的：革命是无休止的。” </li>
</ul>
<p><strong>附录部分：</strong></p>
<ul>
<li>革命无处不在， 革命蕴涵在万物之中。他是无限的，没有最后的革命，也没有最终的数字。 社会革命只是无限的数字革命中的一个：革命的法则不是社会法则，而是无法估量的更伟大的法则。它是普世的宇宙法则——就像能亮守恒法则和能量耗散法则。终有一天，一道确切的革命法则公式将会确立，在这道公司里，国家、阶级、星星——还有书籍，都会作为数字变量加以描述。</li>
<li>有害的文学作品要比有用的文学作品更有意义，因为它在与熵对抗，它是对抗僵化、硬化、结痂、苔藓、静止的手段。 </li>
<li>异端对于健康是必须的，如果没有异端，就应该催生异端。 </li>
<li>孩子们是最勇敢的哲学家，他们赤裸裸的来到世上，不为最细微的教条、绝对真理、信条所蒙蔽。这就是为什么他们问的每一个问题都很荒唐、天真而又复杂的惊人。</li>
<li>生机勃勃的人总在犯错，总是在追寻、提问、受折磨。</li>
<li>答案可能是错的，哲学可能是谬误——错误比真理更有价值：真理就像机器， 而错误是鲜活的。</li>
<li>荒唐吗？是的。平行线相交也是荒唐的，但它只是在欧几里得的经典几何才是荒唐的。在非欧几何里，它是一则定理，你需要做的就是不再局限于平面，超越平面。</li>
<li>刺痛自己是很困难的，甚至是危险的。但对于那些活着的人来说，在今天像昨天一样生活是更加困难的事情。 </li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《美丽新世界》</title>
    <url>/2021/09/30/2021-09-30-%E3%80%8A%E7%BE%8E%E4%B8%BD%E6%96%B0%E4%B8%96%E7%95%8C%E3%80%8B/</url>
    <content><![CDATA[<p>《美丽新世界》</p>
<p><strong>作者</strong></p>
<p>奥尔德斯•赫胥黎（Aldous Huxley, 1894—1963），英国杰出的小说家、诗人、散文家、批评家和剧作家，著名的人道主义者。他以大量的小说和散文、杂文、评论作品，有意识地担负起一个人文主义知识分子的道义职责，充当了社会道德和现代文明的拷问者。</p>
<p><strong>摘录</strong></p>
<ul>
<li>有一种东西叫做民主。好像人和人之间除了物理和化学性能平等之外还有什么别的东西也会平等似的。</li>
<li>“如果人不必考虑幸福的话，”他想，“哪会多么有趣！”</li>
<li>慢性悔恨是一种最不健康的情绪。如果你做错了事，你可以忏悔，然后尽自己所能进行弥补，让自己下一次做得更好。千万不要沉浸在过去的错误中，在淤泥中打滚绝对无法让你变得干净</li>
<li>他们为人类准备好了床，如果人类不适应这张床，那就只能自认倒霉，只能把人拉长或截短。</li>
<li>例如，我们去一个热带岛屿，在DDT杀虫剂的帮助下，我们消灭了疟疾，在两三年的时间里，拯救了成千上万的生命。这显然是件好事。但是这些被拯救的成千上万人生育了数百万的孩子，这个岛屿上的可利用资源无法满足这些孩子衣食住行和教育的需要。疟疾带来的快速死亡已经不存在了，但是由于营养不良和拥挤，这里的生活痛苦不堪，饥饿造成的慢性死亡威胁着更多人的生命。</li>
<li>在一个大规模生产和营销的世界里，资金不足的小人物常常处于劣势，在和大人物的竞争中，他失去自己的资本，最后被大人物吞食，失去作为独立生产者存在的权利。</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《受戒》</title>
    <url>/2021/10/03/2021-10-03-%E3%80%8A%E5%8F%97%E6%88%92%E3%80%8B/</url>
    <content><![CDATA[<p>《受戒》</p>
<p><strong>作者</strong></p>
<p>汪曾祺（1920年3月5日—1997年5月16日），男，汉族，江苏高邮人，当代作家、散文家、戏剧家，京派作家的代表人物。早年毕业于西南联大，历任中学教师、北京市文联干部、《北京文艺》编辑、北京京剧院编辑。汪曾祺在短篇小说创作上颇有成就，著有小说集《邂逅集》，小说《受戒》、《大淖记事》，散文集《蒲桥集》，其大部分作品收录在《汪曾祺全集》中。被誉为“抒情的人道主义者，中国最后一个纯粹的文人，中国最后一个士大夫。”1997年5月16日上午10点30分，汪曾祺因病医治无效去世，享年77岁。 ——豆瓣</p>
<p><strong>摘录</strong></p>
<ul>
<li><p>“当了沙弥尾跟别的和尚有什么不同？</p>
<p>” “沙弥头，沙弥尾，将来都能当方丈。现在的方丈退居了，就当。石桥原本就是沙弥尾。”</p>
<p> “你当沙弥尾吗？”</p>
<p> “还不一定哪。”</p>
<p> “你当方丈，管善因寺？管那么大一个庙？！” </p>
<p>“还早哪！” </p>
<p><strong>划了一气</strong>，小英子说：“你不要当方丈！”</p>
<p> “好，不当。” </p>
<p>“你也不要当沙弥尾！”</p>
<p> “好，不当。” <strong>又划了一气</strong>，看见那一片芦花荡子了。 小英子忽然把桨放下，走到船尾，趴在名字的耳朵旁边，小声地说： “我给你当老婆，你要不要？” <strong>明子眼睛鼓得大大的</strong>。 “你说话呀！” </p>
<p>明子说：“嗯。” </p>
<p>“什么叫‘嗯’呀！要不要，要不要？”</p>
<p> 明子大声地说：“要！” </p>
<p>“你喊什么！” </p>
<p>明子小小声地说：“要——！”</p>
<p> “快点划！” 英子跳到中舱，两只桨<strong>飞快地</strong>划起来，划进了芦花荡。 </p>
<p>——写的太温柔， 小英子的勇敢矜持，明子的懵懂羞涩，人类最美好的感情，是两小无猜的欢喜</p>
</li>
<li><p>各种卖小吃的都来了。卖牛肉高粱酒的，卖回卤豆腐干的，卖五香花生米的、芝麻灌香糖的，卖豆腐脑的，卖煮荸荠的，还有卖河鲜——卖紫皮鲜菱角和新剥鹅头米的……</p>
</li>
<li><p>同事之间为了“联络感情”，时常轮流做东，约好了在星期天早上“吃早茶”。这地方“吃早茶”不是喝茶，主要是吃各种点心——蟹肉包子、火腿烧麦、冬笋蒸饺、脂油千层糕。还可叫一个三鲜煮干丝，小酌两杯。</p>
</li>
<li><p>这家专做“草炉烧饼”。这种烧饼是一箩到底的粗面做的，做蒂子只涂很少一点油，没有什么层，因为是贴在吊炉里用一把稻草烘熟的，故名草炉烧饼，以别于在桶状的炭炉中烤出的加料插酥的“桶炉烧饼”。这种烧饼便宜，也实在，乡下人进城，爱买了当饭。几个草庐烧饼，一碗宽汤饺面，有吃有喝，就饱了。</p>
</li>
<li><p>“晚茶”大都是一碗干拌面，——葱花、猪油、酱油、虾子、虾米为料，面下在里面；或几个麻团、“油墩子”，——白铁敲成浅模，浇入稀面，以萝卜丝为馅，入油炸熟。八千岁家的晚茶，一年三百六十日，都是草炉烧饼，一人两个。这里的店铺，有“客人”，照例早上要请上茶馆。“上茶馆”是喝茶，吃包子、蒸饺、烧麦。照例由店里的“先生”或东家作陪。一般都是叫一笼“杂花色”（即各样包点都有）…… </p>
<p>——汪先生对食物的描写，妙笔柔情，劳苦大众普通的饮食，变得温柔。这些简单的东西，不知道我会写成什么样， 这样的文字应当细品，但是我都没有心思，静下来细读，我们是不是过的太着急？</p>
</li>
<li><p>高先生很孤僻，不出人情，不随份子，几乎不与人通庆吊。他家从不请客，他也从不赴宴。他教书之外，还为人写寿序，撰挽联，委托的人家照例都得请请他，知单送到，他照例都在自己的名字下书一个“谢”字。久而久之，都知道他这脾气，也就不来多此一举了。 他不吃烟，不饮酒，不打牌，不看戏。除了学校和自己的家，哪里也不去，每天他清早出门，傍晚回家。拍拍白木的板门，过了一会儿，门开了。进门是一条狭长的过道，砖缝里长着扫帚苗，苦艾，和一种名叫“七里香”其实是闻不出什么气味，开着蓝色的碎花的野草，有两个黄蝴蝶寂寞的飞着。高先生就从这些野草丛中踏着沉重的步子走进去，走进里面一个小门，好像走进了一个深深的洞穴，高大的背影消失了。木板门又关了，把门上的一副春联关在外面。</p>
</li>
<li><p>  高先生在东街住过的老屋倒塌了，临街的墙壁和白木板门倒还没有倒。板门上高先生写的春联也还在。大红朱笺被风雨漂得几乎是白色的了，墨写的字迹却还很浓，很黑。    辛夸高岭桂    未徙北溟鹏</p>
</li>
</ul>
<p>   ——汪先生笔下皆小人物，高先生有自己的个性，风格，坚持，信仰(尊师)，怎能不令人，动容</p>
<ul>
<li> 一天夜里，李小龙在梦里闻到一股醉人的香味。他忽然惊醒了：昙花开了！ 李小龙一骨碌坐了起来，划根火柴，点亮了煤油灯：昙花真的开了！ 李小龙好像在做梦。 昙花真美呀！雪白雪白的。白的像玉，想通草，像天上的云。花心淡黄，淡得像没有颜色，淡得真雅。她像一个睡醒了的美人，正在舒展着她的肢体，一面吹出醉人的香气。啊呀，真香呀！香死了！ 李小龙两手托着下巴，目不转睛的看着昙花。看了很久，很久。 他困了。他想就这样看他一夜，但是他困了。吹熄了灯，他睡了。一睡就睡着了。 睡着之后，他做了一个梦，梦见昙花开了。 于是李小龙有了两盆昙花。一盆在他的床前，一盆在他的梦里。 </li>
</ul>
<p>​       ——孩子的童心，心思 </p>
<ul>
<li>他们吃饭不怎么嚼，只在嘴里打一个滚，咕咚一声就咽下去了。看他们吃得那样香，你会觉得世界上再没有比这个饭更好吃的饭了。</li>
<li>都到岁数了，心里不是没有。只是像一片薄薄的云，飘过来，飘过去，下不成雨。</li>
<li>她们像男人一样的挣钱，走相、坐相也像男人。走起来一阵风，坐下来两条叉得很开。她们像男人一样亦脚穿草鞋（脚指甲却用风仙花 染红）。她们嘴里不生冷，男人怎么说话她们怎么说话，她们也用男人骂人的话骂人。打起号子来也是“好大娘个歪歪子咧！” 没出门子的姑娘还文雅一点 一做了媳妇就简直是“姜太公在此百无禁忌”，要多野有多野。 这里人家的婚嫁极少明媒正娶，花轿吹鼓手是挣不着他们的钱的媳妇，多是自己跑来的；姑娘，一般是自己找人。她们在男女关系上是比较随便的。姑娘在家生私孩子；一个媳妇，在丈夫之外，再“靠”个，不是稀奇事。这里的女人和男人好，还是恼，只有一个标准：情愿。有的姑娘、媳妇相与了一个男人，自然也跟他要钱买花戴，但是有的不但不要他们的钱，反而把钱给他花，叫做“倒贴”。 因此，街里的人说这里“风气不好” 到底是哪里的风气更好一些呢？难说。</li>
<li>“他们打你，你只要说不再进我家的门，就不打你了，你就不会吃这样大的苦了，你为什么不说？” “你要我说么?” “不要。” “我知道你不要。” “你值么?” “我值。 “十一子,你真好!我喜欢你!你快点好。” “你亲我一下,我就好得快。” “好,亲你!”</li>
</ul>
<p>​     ——大淖人敢爱敢恨</p>
<ul>
<li><p>小吕有一件大红的球衣，干活时他喜欢把外面的衣裳脱去，于是，在果园里就经常看见通红的一团，轻快地、兴冲冲地弹跳出没于高高低低、深深浅浅的丛绿之中，惹得过路的人看了，眼睛里也不由得漾出笑意，觉得天色也明朗，风吹得也舒服</p>
<p>——劳动人民单纯的幸福，我想到了少平把力气都用完。</p>
</li>
<li><p>晚饭米都没得一颗，还你妈的之乎——者也！</p>
</li>
</ul>
<p>——痛苦的文人，哎，读书</p>
<ul>
<li>  全县第一个大画家是季匋民，第一个鉴赏家是叶三。 </li>
</ul>
<p>——传说先秦的琴师伯牙一次在荒山野地弹琴，樵夫钟子期竟能领会这是 描绘“峨峨兮若泰山”和“洋洋兮若江河”。伯牙惊道：“善哉，子之心而与吾心同。”钟子期死后，伯牙痛失知音，摔琴绝弦，终生不弹，故有高山流水之曲。季匋民与叶三现代伯牙子期。</p>
<ul>
<li>陈相公挨了打，当时没敢哭。到了晚上，上了门，一个人呜呜地哭了半天。他向他远在故乡的母亲说：“妈妈，我又挨打了！妈妈，不要紧的，再挨两年打，我就能养活你老人家了！”</li>
<li>陈小手的得名是因为他的手特别小，比女人的手还小，比一般女人的手还更柔软细嫩。他专能治难产。横生、倒生，都能接生下来（他当然也要借助于药物和器械）。据说因为他的手小，动作细腻，可以减少产妇很多的痛苦。大户人家，非到万不得已，是不会请他的。中小户人家，忌讳较少，遇到产妇胎位不正，老娘束手，老娘就会建议：“去请陈小手吧。” …… 有一年，来了联军。我们那里那几年打来打去的，是两支军队。一支是国民革命军，当称之为“党军”；相对的一支是孙传芳的军队。孙传芳自称“五省联军总司令”，他的部队就被称为“联军”。联军驻扎在天王寺，有一团人。团长的太太（谁知道是正太太还是姨太太），要生了，生不下来。叫来几个老娘，还是弄不出来。这太太杀猪也似的乱叫。团长派人去叫称小手。 …… 这女人身上的脂油太多，陈小手费九牛二虎之力，总算把孩子掏出来了…… 陈小手出了天王寺，跨上马。团长掏出枪来，从后面，一枪就把他打了下来。 团长：“我的女人，怎么让他摸来摸去！他身上，除了我，任何男人都不许碰！这小子，太欺负人了！日他奶奶！” 团长觉得怪委屈。</li>
<li>宋侉子每年要在虞小兰家住一两个月，朝朝寒食，夜夜元宵。他老婆死了，也不续弦，这里就是他的家。他有个孩子，有时也带了孩子来玩。他和关家算起来有点远亲，小兰叫他宋大哥。到钱花得差不多了，就说一声：“我明天有事，不来了。”跨上他的踢雪乌骓骏马，一扬鞭子，没影儿了。在一起时，恩恩义义；分开时，潇潇洒洒。 虞小兰有时出来走走，逛逛宜园。夏天的傍晚，穿了一身剪裁合体的白绸衫裤，拿一柄生丝白团扇，站在柳树下面，或倚定红桥栏杆，看人捕鱼采藕。她长得像一颗水蜜桃，皮肤非常白嫩，腰身、手脚都好看。路上行人看见，就不禁放慢了脚步，或者停下来装做看天上的晚霞，好好地看她几眼。他们在心里想：这样的人，这样的命，深深为她惋惜；有人不免想到家中洗衣做饭的黄脸老婆，为自己感到一点不平；或在心里轻轻吟道：“牡丹绝色三春暖，不是梅花处士妻”，情绪相当复杂。</li>
<li>养鸭是一种游离，一种放逐，一种流浪。 </li>
</ul>
<p>——汪先生对劳苦大众有深刻的洞察，有无差别的爱</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《牧羊人的奇幻之旅》</title>
    <url>/2021/08/26/2021-10-03-%E3%80%8A%E7%89%A7%E7%BE%8A%E4%BA%BA%E7%9A%84%E5%A5%87%E5%B9%BB%E4%B9%8B%E6%97%85%E3%80%8B/</url>
    <content><![CDATA[<h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><p>有一个小伙子喜欢旅行，他为了实现自己的愿望，没有依从父亲的期望，成为了一个牧羊人。</p>
<p>牧羊人四处游荡，只要有水草的地方都可以去。他识字，常带一本书。 再一次卖羊毛时爱上了商店老板的女儿。 </p>
<p>他重复做一个梦，一个小男孩告诉他金字塔地下有宝藏。</p>
<p>吉普赛女巫和撒冷之王告诉他宝藏可能存在，并鼓励他追寻自己的梦。</p>
<h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><p>牧羊人终于没有忍受住宝藏的诱惑，卖掉了羊，接受了撒冷王的祝福之后和占卜的宝石，出发去了埃及。到了一个陌生的国度，他才发现，语言不通。因为语言不同，他在港口被一个年轻人骗去了所有的财产。</p>
<p>他感到失望，十分怀念放羊的快乐生活。占卜的宝石给他一个好的预示，他收拾好了心情继续前进。</p>
<p>可是在水晶玻璃店的老板那里了解到，金字塔离这里几千公里，他无法筹集到这么多的路费。</p>
<p>他绝望了，只能在玻璃店里工作希望能挣到回家的路费和买羊群的钱。</p>
<h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><p>他慢慢适应了枯燥的工作，但他心里并不喜爱这份工作。他希望能通过一些改变改善玻璃点的生意，老板是喜欢维持现状，也不想挣更多的钱，他害怕知道原来自己可以做到，但自己没有去做。老板心里也有一个梦——去朝圣一次，他依靠这个梦维持一成不变的生活，也不准备去实现这个梦。</p>
<p>最终老板让牧羊人做了一些改变，店里的生意变得很好， 而小伙子很快赚够了回家和买羊的钱，他离开了。</p>
<p>但是他犹豫是回去继续做一个牧羊人还是去金字塔追梦。</p>
<p>他遇到了一个英国探险家，他来寻找神秘的炼金术士，他们居然拥有相同的占卜宝石，这可能是神谕，他们一起跟着一个商队准备穿越大沙漠了。</p>
<p>沙漠非常凶险，一旦迷失方向就可能被困在沙漠里，路上认识了驼夫们，他们拥有不同的故事。</p>
<h2 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h2><p>在沙漠中前进的过程中，商队听到了消息，战争就要来了。</p>
<p>驼夫们也并不慌张，他们相信命运已经注定，今天死亡和任何一天死亡并没有区别。 </p>
<p>终于， 他们遇到了一篇绿洲。 </p>
<p>英国人在绿洲里找到炼金术士，在炼金术士的指引下，继续追寻他的炼金之路。</p>
<p>而牧羊人在这里遇到了他的真爱，部落里的女子。牧羊人告白之后， 她们两个人相爱了。 </p>
<p>牧羊人看到了预示—绿洲将会被进攻，他想部落报告了此事，部落相信了。但如果没有敌人来袭，牧羊人将献出生命。</p>
<p>有一位神秘的骑士过来考验牧羊人勇气，并给他一些在沙漠生存的建议。</p>
<h2 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h2><p>少年和炼金术士出发去追寻心的指引，与沙漠里心爱的女人告别，途中遇到了战争，被部落的首领绑架，被抢了所有的财产，之后通过天地之心展现神迹活了下去。</p>
<h2 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h2><p>牧羊少年历经万难，终于来到了金字塔脚下，他不停的挖，始终找不到宝藏。  之后被难民抓住，一顿暴打之下他说出来自己的来历，不想被难民嘲讽，之前他也反复做一个梦，在牧羊人栖息的大树下有一个宝藏，但他却没有愚蠢的相信。牧羊人才知道原来他一直追寻的宝藏就在他身边。 </p>
<h2 id="终章"><a href="#终章" class="headerlink" title="终章"></a>终章</h2><p>少年回到了家乡，找到了宝藏， 回馈了吉普赛人，然后寻找他沙漠里的爱人</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《毛泽东传》</title>
    <url>/2021/10/19/2021-10-19-%E3%80%8A%E6%AF%9B%E6%B3%BD%E4%B8%9C%E4%BC%A0%E3%80%8B/</url>
    <content><![CDATA[<p>迪克•威尔逊 </p>
<ul>
<li>如果老师的课枯燥乏味，他就看小说或打瞌睡——他后来解释说，这是对那些不会用提问和对话引起学生兴趣的老师的一种惩罚。</li>
<li>笔记中说：“我之界当扩而充之，是故宇宙一大我也。”毛指出古代的仁人志士“有杀身亡家而不悔者矣”。毛解释说，这样的人毒蛇螫手，他必断腕。 毛评论说：“彼仁人者，以天下万事为身，而以一身一家为腕，惟其爱天下万世之诚也，是以不敢爱其身家。身家虽死，天下万世固生，仁人之心安矣。”从毛自己写的这些话中可以明显地看出，毛就自己的行为对家庭的影响有一种社会犯罪感，可以看出，他是在为他后来抛弃自己的家庭进行辩护。从笔记中当然也看出毛的使命感。 毛在会上“从不轻易表态”，无论是主持会议还是一般发言——最突出的是他从不作冗长、离题而混乱的讲话。如果他旁边的其他人开始辩论，甚至吵起来的时候，毛都静静地用心倾听各方面的意见。 无论什么时候其他人谈话时，毛都“略低着头或偏着头听别人谈话，而自己只‘嗯’、‘是的’的回答，在倾听对方说完之后，他有条有理地给对谈者分析，提出要点，作出结论。他的话并不多，但每一句都很中肯，都能启发人。” 我过了20年甘露般的生活，对世界一无所知。——毛 他读了查尔斯·达尔文的《物种起源》、亚当斯密的《原富》、穆勒的《名学》、赫伯特·斯宾塞的《群学肆言》、孟德斯鸠的《法意》、让·雅克·卢梭的《社会契约论》以及赫胥黎的《天演论》。 毛在军营中的雇佣兵生活使他懂得，依靠这种军队来达到革命的目的是徒劳的，因为在政治上很难教育他们。毛明白，要成功地进行农村改革运动……就必须武装农民自己。</li>
<li>毛回忆说：“我的军饷是每月七元，每月伙食用去2元。我还得花钱买水。士兵用水必须到城外去挑，但是我是一个学生，不屑挑水，只好向挑夫买水。”毛年轻时很看重劳动的贵贱。 <strong>在大家争辩激烈时，从不轻易表态，等到大家意见发挥已尽，他才从容作出总结</strong>。他的总结总是取长舍短，斟酌尽善；对于一个问题，一种争论，总是分析深入，抓住要害。所以大家都心悦诚服。好些争论即因他精切简当的剖析而得到解决。 署名是“二十八画生启事”——“毛泽东”三个字共有二十八画。 毛反驳说：“如果领袖没有权利，就不可能执行计划，就不能得心应手。领袖拥有的权力多，事情就比较容易办。为了改造一个国家，国民必须刻苦自励，并且需要作出牺牲。” 毛说：“是的，压迫是政治的精髓。如果你压迫得法，说明你的政治是成功的。归根结底，政治的影响力十分简单，不过是经常保持压迫罢了。</li>
</ul>
<p>——争辩往往不能达成共识，除非两个人诚心讨论，这样的情况很少。不表态是更有效的做法。</p>
<ul>
<li>这时，拿未曾改造的知识分子同工人农民比较，就觉得知识分子不干净了，最干净的还是工人农民，尽管他们手是黑的，脚上有牛屎，还是比资产阶级和小资产阶级知识分子都干净。</li>
<li>919年的五四运动是北京自发产生的抗议内忧外患的学生运动，当时毛正在参观他自己国家的圣地——显然他从中汲取了营养。 得出结论认为失败的原因在于中国知识分子脱离广大人民群众。知识领袖要取得任何革命的胜利都必须密切联系这个国家的公民。 我并不想去欧洲。我觉得我对自己的国家还了解的不够，我把时间花在中国会更有益处。</li>
<li>毛清楚地记得在广州听孙讲话以及与他交谈的情景。毛说：“他是一个演说家，一个鼓动家，讲起话来雄辩有力，赢得了一片掌声——他不容别人与他争论，或提出他们自己的观点。实际上他的话<strong>水分很多，油很少</strong>。他不讲民主。</li>
<li>尽管当时工人运动处于低潮，毛任凭风浪起，稳坐钓鱼船。他完全从容自若，似乎一切都在安排之中。 若干年后毛回想起那些日子他进行农村调查的经历。他说，你不能仅下到村里去就希望能了解他们的结构和社会状况。我花了十几年功夫，才搞清楚。茶馆、赌场，什么人都接近、调查……我在家乡，找贫苦农民调查。 但毛也警告他的读者，不要人为地加速造反的行动。“菩萨是农民立起来的，到了一定时期农民会用他们的双手丢开这些菩萨，无需旁人过早地代庖丢菩萨。” 他有突出的军事素质，但缺乏政治判断力，当冲突的命令来自不同的政治司令部时，往往发生动摇。他的忠诚主要是依靠有毛和他在一起。</li>
<li>最初几天起义进行得很顺利，许多重要城镇落到了起义军手里。然而，长沙的工人并没有像毛所期望的那样，起来支持农民。当两支已脱离国民党的部队决定在他们之间开战后，力量单薄的起义军就面临内部火并的危险，于是，安源矿工差不多都被消灭了，毛的农军也中了埋伏。在起义爆发后的一个星期内，毛不得不放弃毫无希望的整个行动。正如他所承认的，“部队的纪律差，政治训练水平低，指战员中有许多动摇分子。开小差的很多。</li>
<li>毛忠告做领导工作的人，“迈开你的双脚，到你的工作范围的各部分各地方去走走，学个孔夫子的’每事问‘。’”“调查就像‘十月怀胎’，解决问题就像‘一朝分娩’。” 你对于某个问题没有调查，就停止你对于某个问题的发言权。——毛 林彪在古田支持了毛，但也许为进一步坚定他的信心，因而毛于1月5日给他写了一封信，题为《星星之火，可以燎原》。</li>
<li>另一个需要纠正的极端是绝对平均主义。“官长骑马，不认为是工作需要，而认为是不平等制度”。有些人要求分物品和背米一律平等：“司令部住了一间大点的房子也要骂起来。” 毛解释说：“就是在社会主义时期”，也“绝无所谓绝对的平均”。1930年元旦，红四军领导在古田举行会议，毛同意重新恢复政治部，牺牲了士兵苏维埃的权力。毛按会议精神对部队官兵进行了整顿，巩固了他的领导，因为类似苏维埃式的民主制度有可能给他的对手钻空子的机会。 他还建议加强党在军队中的作用，党支部由官兵混合组成。那些有“错误的政治倾向”的党员，那些只想大吃大喝、抽鸦片、赌博，或不惜犯罪去获取外币黄金发财又不思悔改的党员，应被从党内清除出去。 至于军队本身，毛建议军事指挥员和政治委员应该“共同的平等的”参与决策。他制定了详细的、新的、严格的纪律条例，要求官兵在党的政治口号下进行工作。 总之，他这样对待他的同志是有点过分的。林彪支持他，但彭德怀有意见。在井冈山周围游击了两年之后，毛的战地指挥员们对以江西的贫瘠农村为支撑红军的根据地，已有了显而易见的不满。从而更倾向于李立三路线，在城市地区振兴革命，现在听来就要比毛的路线更具有吸引力。指挥员们试图立即就移驻到城市去。毛使用整编打乱指挥的方式，才调换了许多高级指挥员。</li>
<li>他告诫说，民主应是集中指导下的民主。党的领导机关要有正确的指导路线，就必须“明了下级机关的情况和群众生活的情况，成为正确指导的客观基础”。决议不要太随便，一经形成，就必须坚决执行。“少数服从多数”，但是党内批评应该加强，必须认识到“党内批评是坚强党的组织、增加党的战斗力的武器……不应当利用批评去做攻击个人的工具”。 由于这样一些原因，革命的进程是缓慢的。“红军每到一地，群众冷冷清清，经过宣传之后，才慢慢地起来。”接下去从毛的笔下流露出的便是他一生中最具动摇和痛苦情绪的句子：“我们深深感觉寂寞，我们时刻盼望这种寂寞生活的终了。” 毛遭到监禁，第三次被从中央委员会中清除出去。由于在莫斯科的王明和在瑞金的博古的共同努力，此时，毛面临被永久排除出中国共产党高级领导层的前景。当听到他被监禁的消息后，一个后来脱党的老伙伴龚楚，带了一些酒和鸡看他，他们一边吃一边回忆上井冈山之前第一次会面的情形。日落后，他们又喝了很长时间，当他的朋友要回去时，毛打着手势说：“唉，井冈山同志的天下一去不复返了。” 两个星期后，长征开始了。</li>
<li>我郑重地向大会提出，我们应该深刻地注意群众生活的问题，从土地、劳动问题，到柴米油盐问题。……一切这些群众生活上的问题，都应该把它提到自己的议事日程上。应该讨论，应该决定，应该实行，应该检查。要使广大群众认识我们是代表他们的利益的，是和他们呼吸相通的。要使他们从这些事情出发，了解我们提出来的最高的任务，革命战争的任务，拥护革命，把革命推到全国去，接受我们的政治号召，为革命的胜利斗争到底。同志们，真正的铜墙铁壁是什么？是群众，是千百万真心实意地拥护革命的群众。</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《周恩来传》</title>
    <url>/2021/10/31/2021-10-31-%E3%80%8A%E5%91%A8%E6%81%A9%E6%9D%A5%E4%BC%A0%E3%80%8B/</url>
    <content><![CDATA[<h2 id="《周恩来传》"><a href="#《周恩来传》" class="headerlink" title="《周恩来传》"></a>《周恩来传》</h2><p>原文摘录：</p>
<ul>
<li> 在人们看来，赫鲁晓夫可能令人恼怒地攻击过周的阶级出身“你的这种批评很好，周同志，”他说，“不过你得承认，我来自工人阶级，而你却出于资产阶级家庭。” 一 阵沉默。而后，周镇静地答道：“是的，赫鲁晓夫同志。但是我俩少有一点是共同的，我们俩都背叛了自己的阶级。” </li>
<li>周思来同志 我们要造你一点反，就是请求你改变现在的工作方式和生活习惯，以适应你的身体变化情，从而你才能为党工作得长久一些，更多一些。这是我们从党和革命的最高的长远的利益出发。所以强烈地请求你接受我们的恳求。</li>
<li>周开始向外国人解释为什么中国不能像西方国家那样行事。他告诉一位外国记者： 中国不能轻率地实行像美国、英国和其他真正民主国家那样的民主。中国人民受过长期的压迫，在他们理解诚实投票的重要性和意义之前，还需要几代人的政治训练。我们还没有为一个彻底的民主制度做好准备。我们必须慢慢来。</li>
<li>司徒雷登本想在6月底访问北京，但未能成行，他收到周一封相当消极的私人信件，该信件戳了一些老伤疤，周取消了对司徒雷登的邀请。几周后又把这个运气不佳的大使描绘成“惯于以和蔼可亲的面目掩盖其虚伪和欺骗”。 周的直率和他那不装模作样的共产主义作风在1949年夏季中的一次讲演中大放光彩，他在北京的一次青年大会上对那些共产主义的下一代谈到毛时说，毛是一个伟人，但与普通人没什么两样，他不应该被看成是“一个偶然的、天生的、神秘的、无法学习的领袖”，年轻人向他学实习时应该从他的历史发展来学习，不要只看今天的成就伟大而不看历史的发展”，昨天迷信的孩子可以变成今天的毛主席(当然，我不是说所有的孩子都可以成毛主席)。他再次提醒说，毛也曾在农村问题上犯过错误。然而，毛已经开始美化他自己的历史，允许献媚的助手去篡改文献。这一腐败倾向在7年前的“整风运动”中就开始了。 周讲话结束时表示完全同意刘少奇对毛的赞扬之词，即毛成功地运用普遍真理于中国的实际。但他补充说，为了使老百姓在这一真理中受益，必须首先通过教育和宣传来使他们提高政治觉悟，因此，周正确地预见了以后10年中国的政策路线斗争，表明他选择了一种缓慢而实用的变革进程，而不是向一种难以捉摸的社会主义作疯狂冲刺。</li>
<li>中国不能轻率地实行像美国、英国和其他真正的民主国家那样的民主。中国人民受过长期的压迫，在他们理解诚实投票的重要性和意义之前，还需要几代人的政治训练。我们还没有为一个初底的民主制度做好准备。我们必须慢慢来。</li>
<li>在一次修面时，周恩来突然咳嗽起来，结果理发师刮破了他的下巴。周恩来看到他那惶恐的样子，迅速道歉说：“我本该在咳嗽前先给你打声招呼。”</li>
<li>周恩来一直没有遭到什么毁灭性的麻烦，因为毛泽东和江青都需要他。甚至在某种程度上，当默默羞辱他的时候，他们也需要利用他那别人无法比拟的才能。</li>
<li>在天安门出现了这样一份悼词，它写道：“他没有遗产，他没有嗣息，他没有坟墓，他也没有留下骨灰，他的骨灰撒在祖国的山河中。他似乎什么也没有给我们留下，但是他拥有全中国，他儿孙好几亿，遍地黄士都是他的。”</li>
<li>他的考虑是对方既富有，家中又有权势，自己家中贫穷，将来会受制于人。</li>
<li>从高级领导层看，这场“文化大革命”也可算作一场夺权的斗争。在斗争中，毛泽东依靠他与周来和代表军队的林彪建立的强大联盟，从刘少奇手中重新夺回了他的领导权。西方观察家一般都认为周恩来是一个温和派，但在这场特殊的斗争中，他与毛泽东站在一起。这可能是因为他更信任、尊敬毛泽东。周恩来与他亲密地共同工作了35年，而刘少奇与周恩来却不太熟悉。</li>
<li>诱使一个世界上最有权力的政治领导人，同时也是一个长期以来对中国共产主义怀有深仇大恨的国家的元首来中国进行官方访问(他的政府甚至还没有承认中国)并与中国领导人就悬而未决的双边问题进行谈判，这是周恩来长期外交生涯中最辉煌的成就。甚至周恩来自己也用同样夸张的语言把它称为国际关系中令人高兴的一个突破。</li>
<li>一名医生后来回忆说：“周恩来是被逼死的。······他们不让他休息。······甚至在我们给周总理输血时，江青也会挂电话来命令在她与总理说话时停止输血，她尽扯些无聊的事，她却把这些称为‘国家大事’。”传说有名医生还声称，中国最优秀的癌症专家提出的治疗方案没被采纳。</li>
<li>周恩来接受了这样一个事实，那就是，中国共产主义的活力将不得不由一个农民领袖来提供。这个人知道农民是如何生活的，并清楚他们在想些什么。而另一方面，毛泽东则需要一个能在世界上代表中国共产主义运动的外交家。周恩来并不奉承毛泽东，但他熟悉毛泽东的个性。毛泽东一方面不信任溜须拍马之辈，另一方面又对潜在的背叛十分敏感。周恩来能够熟练地平息这些不安全因素，而毛泽东为周恩来提供了一个坚如磐石般的长者形象，周恩来童年的经历或许已使他对这样一个形象十分向往。</li>
<li>不是周恩来低估了共产主义，而是毛泽东等走的太快，因为他们在目标与手段之间失去了平衡，他们贪心地以违背自然规律的速度去追求效果，准备把人性中最坏的部分引导出来，还着魔似的相信这可以达到好的目的。这不是共产主义，这只是一个壮观的带有孩子气的梦幻。只有周恩来才是真正的共产主义者，别的人只不过是在玩弄空头政治，而这是他所不擅长的，他有着经过改头换面的拿破仑式的博学，还带有梅特涅式的政治上的坚韧。</li>
<li>周恩来一生的事业可以用消极的色彩来描绘。他献身于共产主义事业，而它能否实现还是个问题；他后来发现，甚至在经济发展这类问题上，其精选出来的信条加上他自己那第一流的实干技巧也不能带来所希望的结果。他自己也在20世纪40年代就认识到除非千百万人民被成功地教育过来，把他们的思想改造得具有合作与集体主义精神，否则的话，共产主义在中国就不会起什么作用。但是，一旦他成为这个巨大国家的政府领导人，他就被驱使着为立即实现共产主义的所有目标而全速前进。</li>
<li>周恩来最后没能实现他的诺言，终其一生也没能把中国决定性地带入一个明显有着更高生活水平的更先进的工业和技术发展的现代社会。严格地说，这不是他的错，而更多的应归因于客观条件的无情。任何想在这样一个落后的大国迅速取得巨大进步的人都难免会遭到巨大挫折。然而，周恩来没有在这不可避免的挫折面前撒手不管或是作出过激的反应。他只是不动声色地坚守他的阵地，为使共产党中国的改革能继续下去提供唯一的一股主要动力。他这么做的时候，不像其他领导人那样以一种执拗的、决不通融的方式进行，而是以一种永远使人感到振奋的、非常民主的风格来进行，这就使得别人不断地集合在他的周围并帮助他奋力去实现目标。</li>
<li>苗谴责周为他的革命把少帅当成了牺牲品。 “不，苗兄，不是我的革命，是为了我们民族的命运，为了正在流血牺牲的千千万万个我们的同胞。你在少帅的舒适的司令部里待得太久了。你还没有亲自到川西、陕北，以及那么多无法生活的地方走走，你还没有看见我们的大多数人民是怎样生活的，他们祖祖辈辈都过着非人的生活啊！” 苗坚持说周对少帅没有感情。“我曾听说共产党人从不为自己同志的死而落泪。” “不！”周回答，“我们从不为悲哀落泪，我们只有愤怒的相，这是绝对不同的，我们正在为人民而战，感伤是没有用的。我们的革命经验是我们的同志用生命换来的，我们的政策是用鲜血写成的，靠几滴伤感的泪水是不行的。” </li>
<li>妇女权利是周恩来热忱改革的对象之一。他对上海的一个妇女组织说：“家庭是很重要的。你们不要看不起家务工作。不管怎么说，你们每个人都负责个一人政府。你们每个人都管理着你们家庭的内政部和外交部。还有谁的工作比这还重要？” </li>
<li>他们是一些错误地判断了人类本性的理想主义者。周恩来接着说，社会主义道路应该是一步一步地走，首先要教育群众，使他们达到一个公平社会的道德水平所要求的高度。在过渡时期，必须认识到群众仍是一些普通的人，他们中间有些人先进，有些人落后，因此“物质刺激”是必要的，鉴于那些一厢情愿的思想家曾经一度认为中国在十几年内就能跨入发达国家的行列，周恩来估计中国还将需要30~-40年才能做到资金和消费品的自给自足，而要达到西方那么高的生活水平，还需要差不多100年的时间。</li>
<li>一些国民党人想把他从共产党这里争取过去，“他们从来没有成功过，因为他从不在意个人的安逸、财富和势力”。</li>
<li>像以往一样，周恩来的策略是找出双方的理亏之处，迫使双方都作出使对方满意的让步。</li>
<li>“文化大革命”中所发生的事是如此复杂，使人们几乎不可能对它作一个简单的分析。但是，看清它的最好的方法是重新观察一下三个融合在一起的,性质截然不同而又都刻有“文革”标记的现象。首先，我们看到的是一场为改变大部分党员和非党员头脑中的传统观念以及封建主义和非社会主义 思想而进行的意识形态运动。这场运动的最终目标是使民主、社会主义和集体主义精神达到一个更高的水平，周恩来是这一愿望的拥护者。 后来，周恩来就是从这个意义出发，把“文革”解释为一个漫长过程 第一步，认为它“不可能一下子解决所有的问题”。几年后，他在与费利克斯・格林谈话时引述了毛的革命思想，并说道：“类似这样的革命应该一次又一次地进行，而且每一次都应达到一个更高的阶段，每一次都应比前一次更深入。”周恩来在这里并不是违心地讲话，而是以一个热心的社会主义者的身份讲这番话的。他在这里以他一的乐观主义态度假定下一次革命可以免无政府主义和权力斗争。 从高级领导层看，这场“文化大革命”也可算作一场夺权的斗争。在斗争中、毛泽东依靠他与周恩来和代表军队的林彪建立的强大联盟，从少奇手中新夺回了他的领导权。西方观察家一般都认为周恩来是一个温和派，但在这场特殊的斗争中，他与毛泽东站在起。这可能是因为他更信任、尊敬毛泽东。周恩来与他亲密地共同工作了35年，而刘少奇与周恩来却不太熟悉。 最后，还有一个低层次的“文化大革命”。这一革命发生在远离北京的地方。它打破正常的法律和秩序的限制，允许一些个人和派别进行报复活动权行动。这场革命最初像是一次有益的周期性放血，但最后却演变成 影全国性的混乱，于是周恩来转而坚决反对它并在最后取得了成功。 </li>
<li>他的一个崇拜者后来这样写道：“他甚至能与魔鬼共事，并从中获胜。 毛泽东开始把周恩来叫做“管家”，这是一个善意的称呼。有一个欧洲外交家曾经这样评论道：如果把中国比作一个家庭，那么，“深受人民喜爱的周恩来就扮演了一个母亲的角色，而一开始受人尊敬、后来又让人害怕的毛泽东则扮演了父亲的角色”。 一个美国学者在华盛顿举行的参议院听证会上警告说，不应过于乐观地把周恩来看做一个实用主义者和一个讲道理的人。“实际上”弗朗茨・迈克尔教授说他是一个很难对付的领导人，但迈克尔所代表的观点在美国舆论界的优势地位正在动摇。周恩来那过人的才能使他不仅在国内压倒了林彪和陈伯达，而且在国外也击败了那些反对他的人。</li>
</ul>
<p>同在《毛泽东传》中一样，作者把总理漫长一生的政治道路选择投射到其童年经历，企图追根溯源作出宿命论的诠释。真可笑。不过，算上文化的间隔，总体上还算客观。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>四成负载均衡HA集群搭建</title>
    <url>/2021/11/03/2021-11-03-%E5%9B%9B%E6%88%90%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1HA%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h3 id="一-集群介绍"><a href="#一-集群介绍" class="headerlink" title="一 集群介绍"></a>一 集群介绍</h3><p>使用高可用配置的方式在生产环境安装 Rancher，用户可以一直访问 Rancher 服务。在 Kubernetes 集群中安装 Rancher 时，Rancher 会与集群的 etcd 数据库集成，并利用 Kubernetes 调度来实现高可用。下面将使用 RKE 来部署三个节点的集群，并使用 Helm 安装 Rancher。</p>
<p>我们还需要设置一个负载均衡器，以将流量定向到两个节点上的 Rancher 副本。这样可以在单个节点不可用时，继续保障与 Rancher 管理面的连接。</p>
<p>在安装 Rancher 时，Rancher 系统将创建一个 Ingress 资源。该 Ingress 通知 Traefik Ingress 控制器侦听发往 Rancher 主机名的流量。Traefik Ingress 控制器在收到发往 Rancher 主机名的流量时，会将其转发到集群中正在运行的 Rancher Server Pod。</p>
<ul>
<li><strong>4 层负载均衡器</strong> 将 TCP 流量转发到节点。我们建议使用 4 层负载均衡器，将流量从 TCP / 80 端口和 TCP / 443 端口转发到 Rancher 管理面的集群节点上。集群上的 Ingress 控制器会将 HTTP 流量重定向到 HTTPS，并在 TCP / 443 端口上终止 SSL / TLS。Ingress 控制器会将流量转发到 Rancher Server Pod 的 TCP / 443 端口。</li>
</ul>
<h3 id="二-集群部署"><a href="#二-集群部署" class="headerlink" title="二  集群部署"></a>二  集群部署</h3><p>使用RKE部署集群包括四个部分</p>
<ol>
<li>准备工作，包括云主机或虚拟机硬件、软件和网络配置。部署的集群的要求，可以查看<a href="https://docs.rancher.cn/">rancher官方文档</a></li>
<li>rke部署集群, 包括安装rke，新建操作的普通用户，主节点免密登陆，集群的配置文件，启动集群。</li>
<li>部署rancher web，这里通过helm3部署，需要安装helm3, 生成自签名证书，启动rancher web服务。  </li>
<li>通过rancher server调试集群</li>
</ol>
<blockquote>
<p>什么是RKE? </p>
<p>Rancher Kubernetes Engine，简称 RKE，是一个经过 CNCF 认证的 Kubernetes 安装程序。RKE 支持多种操作系统，包括 MacOS、Linux 和 Windows，可以在裸金属服务器（BMS）和虚拟服务器（Virtualized Server）上运行。市面上的其他 Kubernetes 部署工具存在一个共性问题：在使用工具之前需要满足的先决条件比较多，例如，在使用工具前需要完成安装 kubelet、配置网络等一系列的繁琐操作。而 RKE 简化了部署 Kubernetes 集群的过程，只有一个先决条件：只要您使用的 Docker 是 RKE 支持的版本，就可以通过 RKE 安装 Kubernetes，部署和运行 Kubernetes 集群。RKE 既可以单独使用，作为创建 Kubernetes 集群的工具，也可以配合 Rancher2.x 使用，作为 Rancher2.x 的组件，在 Rancher 中部署和运行 Kubernetes 集群。</p>
</blockquote>
<h4 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h4><p><code>1.1 设置节点hostname</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx 192.168.2.40</span><br><span class="line">node1 192.168.2.51</span><br><span class="line">node2 192.168.2.52</span><br><span class="line">node3 192.168.2.53</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@nginx ~]# hostnamectl set-hostname nginx</span><br><span class="line">[root@node1 ~]# hostnamectl set-hostname node1</span><br><span class="line">[root@node2 ~]# hostnamectl set-hostname node2</span><br><span class="line">[root@node3 ~]# hostnamectl set-hostname node3</span><br></pre></td></tr></table></figure>

<p><code>1.2 主机名DNS解析</code><br>主机名DNS解析</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.2.40 nginx</span><br><span class="line">192.168.2.51 node1</span><br><span class="line">192.168.2.52 node2</span><br><span class="line">192.168.2.53 node3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p><code>1.3 关闭防火墙</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>

<p><code>1.4 关闭swap</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">swapoff -a # 临时关闭；关闭swap主要是为了性能考虑</span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab # 永久关闭</span><br></pre></td></tr></table></figure>

<p><code>1.6 关闭selinux </code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setenforce 0 # 临时关闭</span><br><span class="line">sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config # 永久关闭</span><br></pre></td></tr></table></figure>

<p><code>1.6 同步时间</code></p>
<p>这样可以防止在客户端和服务器之间因为时钟不同步而发生证书验证错误。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure>

<p><code>1.7 kernel性能调优</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; /etc/sysctl.conf&lt;&lt;EOF</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1=4096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2=6144</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3=8192</span><br><span class="line">EOF</span><br><span class="line"># 加载配置文件</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>



<p><code>1.8 安装基础软件包</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install lrzsz vim gcc glibc openssl openssl-devel net-tools wget curl</span><br></pre></td></tr></table></figure>

<h4 id="2-部署集群"><a href="#2-部署集群" class="headerlink" title="2 部署集群"></a>2 部署集群</h4><p><code>2.1 安装docker</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>安装18.09.9稳定版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7</span><br></pre></td></tr></table></figure>

<p>启动docker </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<p>配置镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;oom-score-adjust&quot;: -1000,</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://7bezldxe.mirror.aliyuncs.com/&quot;,&quot;https://kw88y6eh.mirror.aliyuncs.com&quot;],</span><br><span class="line">    &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">    &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>重启并设置自启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br><span class="line"># systemctl  status docker 查看docker状态</span><br></pre></td></tr></table></figure>



<p><code>2.2  安装ctl工具</code> </p>
<p>下载安装工具rke,kubectl </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># rke下载地址：https://github.com/rancher/rke/tags，下载v1.0.4</span><br><span class="line">chmod +x rke_linux-amd64 </span><br><span class="line">mv rke_linux-amd64 /usr/bin/rke</span><br><span class="line"></span><br><span class="line"># kubectl </span><br><span class="line">wget http://storage.googleapis.com/kubernetes-release/release/v1.17.2/bin/linux/amd64/kubectl</span><br><span class="line">chmod +x kubectl </span><br><span class="line">mv kubectl /usr/bin/kubectl</span><br></pre></td></tr></table></figure>
<p><code>2.3 设置节点免密登陆</code></p>
<p>rke不支持root用户，所以新建普通用户操作</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">useradd rancher -G docker</span><br><span class="line">echo &quot;123456&quot; | passwd --stdin rancher</span><br></pre></td></tr></table></figure>

<p>授权免密登陆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su - rancher</span><br><span class="line">cd /home/rancher</span><br><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id rancher@192.168.2.51</span><br><span class="line">ssh-copy-id rancher@192.168.2.52</span><br><span class="line">ssh-copy-id rancher@192.168.2.53</span><br></pre></td></tr></table></figure>
<p>集群配置yml文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; cluster.yml &lt;&lt; EOF</span><br><span class="line">nodes:</span><br><span class="line">  - address: 192.168.2.51</span><br><span class="line">    internal_address: 192.168.2.51</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">  - address: 192.168.2.52</span><br><span class="line">    internal_address: 192.168.2.52</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">  - address: 192.168.2.53</span><br><span class="line">    internal_address: 192.168.2.53</span><br><span class="line">    user: rancher</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">services:</span><br><span class="line">    etcd:</span><br><span class="line">      snapshot: true</span><br><span class="line">      creation: 6h</span><br><span class="line">      retention: 24h</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>创建Kubernetes集群</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 运行RKE命令创建Kubernetes集群</span><br><span class="line">rke up --config ./cluster.yml</span><br></pre></td></tr></table></figure>

<blockquote>
<p>保存kube_config_rancher-cluster.yml和rancher-cluster.yml文件的副本，后期将需要这些文件来维护和升级Rancher实例。</p>
</blockquote>
<p>配置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 切换到root用户</span><br><span class="line">su - root</span><br><span class="line">vim /etc/profile</span><br><span class="line">export KUBECONFIG=/home/rancher/kube_config_cluster.yml</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<p>查看集群状态</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/rke1.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/rke2.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/rke3.png"></p>
<p><code>2.4  配置nginx代理</code> </p>
<p>安装nginx，这里最新版本的可能出现模块错误，安装稳定版的。</p>
<p>添加nginx repo</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/yum.repos.d/nginx.repo </span><br><span class="line">[nginx-stable]</span><br><span class="line">name=nginx stable repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nginx.org/keys/nginx_signing.key</span><br><span class="line">module_hotfixes=true</span><br><span class="line">[nginx-mainline]</span><br><span class="line">name=nginx mainline repo</span><br><span class="line">baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=https://nginx.org/keys/nginx_signing.key</span><br><span class="line">module_hotfixes=true</span><br></pre></td></tr></table></figure>

<p>yum直接安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 卸载旧版 nginx #yum -y remove nginx</span><br><span class="line">yum -y install nginx-1.18.0 </span><br></pre></td></tr></table></figure>

<p>配置nginx.conf</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/nginx/nginx.conf &lt;&lt; EOF </span><br><span class="line">worker_processes 4;</span><br><span class="line">worker_rlimit_nofile 40000;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 8192;</span><br><span class="line">&#125;</span><br><span class="line">stream &#123;</span><br><span class="line">    upstream rancher_servers_http &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 192.168.2.51:80 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.2.52:80 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.2.53:80 max_fails=3 fail_timeout=5s;</span><br><span class="line">&#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        proxy_pass rancher_servers_http;</span><br><span class="line">&#125;</span><br><span class="line">    upstream rancher_servers_https &#123;</span><br><span class="line">        least_conn;</span><br><span class="line">        server 192.168.2.51:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.2.52:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">        server 192.168.2.53:443 max_fails=3 fail_timeout=5s;</span><br><span class="line">&#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen     443;</span><br><span class="line">        proxy_pass rancher_servers_https;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试 </span><br><span class="line">cat &gt; /etc/nginx/nginx.conf &lt;&lt; EOF </span><br><span class="line">worker_processes 4;</span><br><span class="line">worker_rlimit_nofile 40000;</span><br><span class="line">include /usr/share/nginx/modules/*.conf;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 8192;</span><br><span class="line">&#125;</span><br><span class="line">stream &#123;</span><br><span class="line">	upstream rancher &#123;</span><br><span class="line">        server 192.168.30.110:80;</span><br><span class="line">        server 192.168.30.129:80;</span><br><span class="line">        server 192.168.30.133:80;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    map $http_upgrade $connection_upgrade &#123;</span><br><span class="line">        default Upgrade;</span><br><span class="line">        &#x27;&#x27;      close;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 443 ssl http2;</span><br><span class="line">        server_name cf.rancher.com;</span><br><span class="line">        ssl_certificate /home/admin/certs/tls.crt;</span><br><span class="line">        ssl_certificate_key /home/admin/certs/tls.key;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_set_header Host $host;</span><br><span class="line">            proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line">            proxy_set_header X-Forwarded-Port $server_port;</span><br><span class="line">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">            proxy_pass http://rancher;</span><br><span class="line">            proxy_http_version 1.1;</span><br><span class="line">            proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">            proxy_set_header Connection $connection_upgrade;</span><br><span class="line">            # 这里将允许您在 Rancher UI 中打开命令行窗口时，窗口可以保留最多15分钟。没有这个参数时，默认值为1分钟，一分钟后在Rancher&gt;中的shell会自动关闭。</span><br><span class="line">            proxy_read_timeout 900s;</span><br><span class="line">            proxy_buffering off;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name cf.rancher.com;</span><br><span class="line">        return 301 https://$server_name$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx -t  # 测试语法是否有误</span><br><span class="line">nginx -c /etc/nginx/nginx.conf # 设置配置文件</span><br><span class="line">nginx -s reload # 加载更改的配置文件</span><br></pre></td></tr></table></figure>

<p>启动服务，设定nginx自启动服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl restart nginx.service</span><br><span class="line">systemctl enable nginx.service</span><br></pre></td></tr></table></figure>

<p><code>2.5  故障处理</code> </p>
<p>这里可能会出现几个问题： </p>
<p><code>问题1  </code> unknown directive “stream”</p>
<p>先检查nginx的配置有没有错误，或者有没有tab空格，nginx是不支持tab空格的，可以使用下面命令检查格式，对齐或者空格 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat -A  /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure>

<p>如果配置确实没有问题，也有可能是nginx版本问题, 换稳定版的nginx。 </p>
<p><code>问题2</code> 缺少 “/var/run/nginx.pid”文件</p>
<p>解决方法， 没有就新建一个</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /var/run/</span><br><span class="line">touch nginx.pid</span><br></pre></td></tr></table></figure>

<p><code>问题3</code> nginx: [error] invalid PID number “” in “/var/run/nginx.pid”</p>
<p>解决，先执行ngingx -c， 再加载配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx -c /etc/nginx/nginx.conf</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>

<p><code>问题4</code> 80/443端口被占用, 如下: </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Job for nginx.service failed because the control process exited with error code. See &quot;systemctl status nginx.service&quot; and &quot;journalctl -xe&quot; for details.</span><br><span class="line">[root@nginx ~]systemctl status nginx.service</span><br><span class="line">bind() to 0.0.0.0:80 failed (98: Address already in use)</span><br><span class="line">bind() to 0.0.0.0:443 failed (98: Address already in use)</span><br></pre></td></tr></table></figure>

<p>要先关闭服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx -s quit</span><br></pre></td></tr></table></figure>

<p>如果还是不行，可能是端口被其应用占用，就查看一下占用的进程，这里直接清理占用的进程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fuser -k 80/tcp</span><br><span class="line">fuser -k 443/tcp</span><br></pre></td></tr></table></figure>

<h4 id="3-部署rancher-server"><a href="#3-部署rancher-server" class="headerlink" title="3 部署rancher server"></a>3 部署rancher server</h4><p><code>3.1 安装helm  </code> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#helm下载地址：https://github.com/helm/helm/tags </span><br><span class="line">tar -zxf helm-v3.2.4-linux-amd64.tar.gz </span><br><span class="line">mv linux-amd64/helm /usr/bin/helm</span><br><span class="line">rm -rf helm-v3.2.4-linux-amd64.tar.gz linux-amd64</span><br></pre></td></tr></table></figure>

<blockquote>
<p>helm3与helm2不同，是不需要安装tiller的</p>
</blockquote>
<p><code>3.2 部署rancher web服务</code></p>
<p>添加Chart仓库地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用helm repo add命令添加Rancher chart仓库地址，访问Rancher tag和Chart版本</span><br><span class="line"># 替换&lt;CHART_REPO&gt;为您要使用的Helm仓库分支(即latest或stable）。</span><br><span class="line"># helm repo add rancher-stable https://releases.rancher.com/server-charts/stable</span><br><span class="line"># 国内可用镜像</span><br><span class="line"># helm repo add rancher-stable http://rancher-mirror.oss-cn-beijing.aliyuncs.com/server-charts/stable</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>

<p>Rancher Server 默认需要 SSL/TLS 配置来保证访问的安全性，这里我们选择自签名的证书</p>
<p>这里使用官方文档给的生成证书的脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir ssl</span><br><span class="line">cd ssl/</span><br><span class="line">chmod +x create_self-signed-cert.sh  # 执行权限</span><br><span class="line">#然后再用这个脚本生成ssl证书</span><br><span class="line">./create_self-signed-cert.sh --ssl-domain=my.rancher.com --ssl-trusted-ip=192.168.0.41 --ssl-size=2048 --ssl-date=3650</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#查看证书</span><br><span class="line">[root@node1 ssl]# ls</span><br><span class="line">cacerts.pem  cacerts.srl  cakey.pem  create_self-signed-cert.sh  my.rancher.com.crt  my.rancher.com.csr  my.rancher.com.key  openssl.cnf  tls.crt  tls.key</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为rancher创建命名空间</span><br><span class="line">kubectl create namespace cattle-system</span><br><span class="line"></span><br><span class="line"># 服务证书和私钥密文</span><br><span class="line">kubectl -n cattle-system create \</span><br><span class="line">    secret tls tls-rancher-ingress \</span><br><span class="line">    --cert=/home/rancher/ssl/tls.crt \</span><br><span class="line">    --key=/home/rancher/ssl/tls.key</span><br><span class="line"></span><br><span class="line"># ca证书密文</span><br><span class="line">kubectl -n cattle-system create secret \</span><br><span class="line">    generic tls-ca \</span><br><span class="line">    --from-file=/home/rancher/ssl/cacerts.pem</span><br></pre></td></tr></table></figure>

<p>安装rancher server </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">helm install rancher rancher-stable/rancher \</span><br><span class="line">    --namespace cattle-system \</span><br><span class="line">    --set hostname=my.rancher.com \</span><br><span class="line">    --set ingress.tls.source=secret \</span><br><span class="line">    --set privateCA=true</span><br><span class="line"># hostname需要与证书对应的域名匹配，否则ingress将无法代理访问Rancher。</span><br></pre></td></tr></table></figure>

<p>my.rancher.com是后面访问rancher的域名，需要在/etc/hosts文件中添加关联（所有主机）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]$ echo &quot;192.168.0.41 my.rancher.com&quot; &gt;&gt; /etc/hosts</span><br><span class="line">[root@node2 ~]$ echo &quot;192.168.0.41 my.rancher.com&quot; &gt;&gt; /etc/hosts</span><br><span class="line">[root@node3 ~]$ echo &quot;192.168.0.41 my.rancher.com&quot; &gt;&gt; /etc/hosts</span><br><span class="line">[root@nginx ~]$ echo &quot;192.168.0.41 my.rancher.com&quot; &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>

<p><code>3.4 容器配置hosts:</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl -n cattle-system patch deployments rancher --patch &#x27;&#123;</span><br><span class="line">    &quot;spec&quot;: &#123;</span><br><span class="line">        &quot;template&quot;: &#123;</span><br><span class="line">            &quot;spec&quot;: &#123;</span><br><span class="line">                &quot;hostAliases&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;hostnames&quot;:</span><br><span class="line">                        [</span><br><span class="line">                            &quot;my.rancher.com&quot;</span><br><span class="line">                        ],</span><br><span class="line">                            &quot;ip&quot;: &quot;192.168.2.40&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>

<p><code>3.5 添加本机hosts</code><br>将刚刚的域名映射关系写入到Windows主机的hosts文件中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.0.100 my.rancher.com</span><br></pre></td></tr></table></figure>

<h4 id="4-访问rancher-server"><a href="#4-访问rancher-server" class="headerlink" title="4 访问rancher server"></a>4 访问rancher server</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Happy Containering!</span><br><span class="line">[root@node1 ssl]# echo https://my.rancher.com/dashboard/?setup=$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#x27;)</span><br><span class="line">https://my.rancher.com/dashboard/?setup=</span><br><span class="line">[root@node1 ssl]# kubectl get secret --namespace cattle-system bootstrap-secret -o go-template=&#x27;&#123;&#123;.data.bootstrapPassword|base64decode&#125;&#125;&#123;&#123; &quot;\n&quot; &#125;&#125;&#x27;</span><br><span class="line">b9bwmrwrs7ndzrpvn6lnqc22hmtf7wbdpkpxh652jbrcbkhtlgxsd2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>k8s如何与pod通信</title>
    <url>/2021/11/08/2021-11-08-k8s%E5%A6%82%E4%BD%95%E4%B8%8Epod%E9%80%9A%E4%BF%A1/</url>
    <content><![CDATA[<h3 id="pod通信和服务发现"><a href="#pod通信和服务发现" class="headerlink" title="pod通信和服务发现"></a>pod通信和服务发现</h3><p>在没有k8s的世界里，系统管理员要在用户端配置文件中明确服务的精确的ip地址或主机名来配置客户端的应用，但是在k8s中并不是需要。k8s中应用运行在pod中， 而pod的高可用设计使得无法保证准确的ip, 这里总结一下pod与服务的工作方式。</p>
<h4 id="1-pod特点"><a href="#1-pod特点" class="headerlink" title="1 pod特点"></a>1 pod特点</h4><ol>
<li>pod随时可能启动或关闭，是短暂的</li>
<li>客户端不会提前知道pod的地址，</li>
<li>水平伸缩以为着pod可能会提供相同的服务，每个pod ip不同，但客户端只需要服务，不需要知道pod的地址。 </li>
</ol>
<h4 id="2-服务"><a href="#2-服务" class="headerlink" title="2 服务"></a>2 服务</h4><p>为了解决上述需要，k8s为一组功能相同的pod提供单一不变的接入点，这就是服务。服务的ip和端口不会改变。客户端通过服务被路由pod上，而不需要直接连接pod,这样单个pod被移除或新的pod被创建就不影响。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/servicepod.png"></p>
<h4 id="3-pod与服务的匹配"><a href="#3-pod与服务的匹配" class="headerlink" title="3 pod与服务的匹配"></a>3 pod与服务的匹配</h4><p>上述的过程可以看出服务创建的一个基本问题，如何把服务和一组特定功能的pod匹配起来呢？ <strong>标签选择器</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/servicepod2.png"></p>
<h4 id="4-创建服务"><a href="#4-创建服务" class="headerlink" title="4  创建服务"></a>4  创建服务</h4><ol>
<li> 创建服务之前，先使用rc创建与之连接的pod </li>
</ol>
   <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-rc.yaml &lt;&lt; EOF  </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata: </span><br><span class="line">  name: kubia</span><br><span class="line">spec: </span><br><span class="line">  replicas: 2</span><br><span class="line">  selector: </span><br><span class="line">    app: kubia </span><br><span class="line">  template: </span><br><span class="line">    metadata: </span><br><span class="line">      labels: </span><br><span class="line">        app: kubia</span><br><span class="line">    spec: </span><br><span class="line">      containers: </span><br><span class="line">      - name: kubia</span><br><span class="line">        image: luksa/kubia</span><br><span class="line">        ports: </span><br><span class="line">        - containerPort: 8080</span><br><span class="line">EOF</span><br><span class="line"># create </span><br><span class="line">kubectl create -f kubia-rc.yaml </span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@nginx test]# kubectl get po </span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kubia-66tvd   1/1     Running   0          2m31s</span><br><span class="line">kubia-v8dvv   1/1     Running   0          2m31s</span><br></pre></td></tr></table></figure>

<ol start="2">
<li> 创建服务 </li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-svc.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata: </span><br><span class="line">  name: kubia</span><br><span class="line">spec: </span><br><span class="line">  ports:</span><br><span class="line">  - port: 80 </span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: kubia </span><br><span class="line">EOF </span><br><span class="line"></span><br><span class="line"># create </span><br><span class="line">kubectl create -f kubia-svc.yaml</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@nginx test]# kubectl get svc </span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.43.0.1      &lt;none&gt;        443/TCP   16d</span><br><span class="line">kubia        ClusterIP   10.43.165.39   &lt;none&gt;        80/TCP    46s</span><br></pre></td></tr></table></figure>

<h4 id="5-为什么服务ip无法ping通-？"><a href="#5-为什么服务ip无法ping通-？" class="headerlink" title="5 为什么服务ip无法ping通 ？"></a>5 为什么服务ip无法ping通 ？</h4><p>我们发现服务curl是可以，但是无法ping通。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-node01 ~]# curl  10.43.165.39 </span><br><span class="line">You&#x27;ve hit kubia-66tvd</span><br><span class="line">[root@k8s-node01 ~]# ping 10.43.165.39 </span><br><span class="line">PING 10.43.165.39 (10.43.165.39) 56(84) bytes of data.</span><br><span class="line">^C</span><br><span class="line">--- 10.43.165.39 ping statistics ---</span><br><span class="line">2 packets transmitted, 0 received, 100% packet loss, time 999ms</span><br></pre></td></tr></table></figure>

<p>有的时候ping不通我们就认为出问题了，其实没有。这是因为集群ip是虚拟ip, 并且只有在与服务端口结合时才有意义。 所以ping不通是正常的。</p>
<h4 id="6-测试与分析"><a href="#6-测试与分析" class="headerlink" title="6 测试与分析"></a>6 测试与分析</h4><p>分配给该服务的ip是10.43.165.39， 但这是cluster-ip，也就是集群ip, 只能在集群内部可以访问。 也就是集群节点上或其他的pod可以访问。 是不是这样呢? 测试一下</p>
<ol>
<li> ssh到集群的一个节点上</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-node01 ~]# curl  10.43.165.39 </span><br><span class="line">You&#x27;ve hit kubia-66tvd </span><br><span class="line"># 服务的cluster ip 在集群内部，节点可与其通信</span><br></pre></td></tr></table></figure>

<ol start="2">
<li> 在pod中执行命令， 执行成功则说明连接</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试多次， 每次并不是同一个pod</span><br><span class="line">[root@nginx test]# kubectl exec kubia-vs2kl -- curl -s http://10.43.165.39</span><br><span class="line">You&#x27;ve hit kubia-vs2kl</span><br><span class="line"></span><br><span class="line">[root@nginx test]# kubectl exec kubia-vs2kl -- curl -s http://10.43.165.39</span><br><span class="line">You&#x27;ve hit kubia-l9w94</span><br><span class="line"></span><br><span class="line">[root@nginx test]# kubectl exec kubia-vs2kl -- curl -s http://10.43.165.39</span><br><span class="line">You&#x27;ve hit kubia-vs2kl</span><br></pre></td></tr></table></figure>

<blockquote>
<p> – 表示kubectl 命令结束，之后为在pod中执行的命令</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/servicepod3.png"></p>
<p>上图展示了事件发生的顺序</p>
<ol>
<li>在一个pod中执行命令，这个命令是发送http请求</li>
<li>pod向服务的ip发送请求 </li>
<li>由于这个服务是代理pod的，转发请求到其中一个pod上  </li>
<li>在pod2中处理请求，并返回带有pod名称的相应 </li>
<li>请求结果在主机上打印</li>
</ol>
<p>上述某一个过程出问题，都会使得上述命令失败，所以可用来测试集群网络。</p>
<h4 id="7-同一个服务暴露多个端口"><a href="#7-同一个服务暴露多个端口" class="headerlink" title="7 同一个服务暴露多个端口"></a>7 同一个服务暴露多个端口</h4><p>服务可以暴露一个端口，也可以多个端口。比如http监听8080端口，https监听8443端口。 多个端口需要指定名称, 没有设置名称的端口会在describe 时显示&lt;unset&gt; ， 如果pod中的端口也是命令的，svc中targetport可以使用其名称吗，这样在更换pod端口号的时候也不用修改服务了，因为其是根据名称匹配的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-svc.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    targetPort: 8443</span><br><span class="line">selector:</span><br><span class="line">    app: kubia</span><br><span class="line">EOF </span><br></pre></td></tr></table></figure>

<h4 id="8-发现服务"><a href="#8-发现服务" class="headerlink" title="8  发现服务"></a>8  发现服务</h4><p>创建服务后， 我们可以通过单一稳定的ip访问到pod， 不管pod如何变化都不影响。 但是在某个服务创建之后新建的pod如何知道服务的ip呢？ 难道手动查询吗? 不需要。</p>
<p>k8s为客户端提供了发现服务的ip和端口的方式——环境变量， 在pod开始运行的时候，k8s会初始化一系列的环境变量指向现在存在的服务。如下： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@nginx test]# kubectl exec kubia-vs2kl -- env</span><br><span class="line">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</span><br><span class="line">HOSTNAME=kubia-vs2kl</span><br><span class="line">KUBERNETES_PORT=tcp://10.43.0.1:443</span><br><span class="line">KUBIA_PORT_80_TCP_PORT=80</span><br><span class="line">KUBIA_PORT=tcp://10.43.165.39:80</span><br><span class="line">KUBIA_PORT_80_TCP=tcp://10.43.165.39:80</span><br><span class="line">KUBIA_PORT_80_TCP_PROTO=tcp</span><br><span class="line">KUBIA_PORT_80_TCP_ADDR=10.43.165.39</span><br><span class="line">KUBERNETES_SERVICE_PORT=443</span><br><span class="line">KUBERNETES_PORT_443_TCP_ADDR=10.43.0.1</span><br><span class="line">KUBIA_SERVICE_HOST=10.43.165.39</span><br><span class="line">KUBIA_SERVICE_PORT=80</span><br><span class="line">NPM_CONFIG_LOGLEVEL=info</span><br><span class="line">NODE_VERSION=7.9.0</span><br><span class="line">YARN_VERSION=0.22.0</span><br><span class="line">HOME=/root</span><br></pre></td></tr></table></figure>

<h4 id="9-DNS"><a href="#9-DNS" class="headerlink" title="9 DNS"></a>9 DNS</h4><p>环境变量是获取ip和端口的一种方式，也可以通过DNS获取。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@nginx test]# kubectl get po -n kube-system </span><br><span class="line">NAME                                      READY   STATUS      RESTARTS   AGE</span><br><span class="line">canal-l58m7                               2/2     Running     2          16d</span><br><span class="line">canal-s92dx                               2/2     Running     3          16d</span><br><span class="line">coredns-7c5566588d-rhdtx                  1/1     Running     1          16d</span><br><span class="line">coredns-7c5566588d-tp55c                  1/1     Running     1          16d</span><br><span class="line">coredns-autoscaler-65bfc8d47d-4mdt5       1/1     Running     1          16d</span><br><span class="line">metrics-server-6b55c64f86-zlz4l           1/1     Running     2          16d</span><br></pre></td></tr></table></figure>

<p>kube-system空间中pod有coredns，这表明在运行dns服务，在集群中的其他pod都被配置成使用作为为DNS ， 运行在pod上的进程DNS 查询都会被k8s自身的DNS服务器响应，该服务器知道系统中运行的所有服务。pod中的spec中的dnspolicy值决定是否使用DNS服务器。 </p>
<h4 id="10-endpoints"><a href="#10-endpoints" class="headerlink" title="10 endpoints"></a>10 endpoints</h4><p>我们也希望k8s将服务暴露到外部，在此之前要先介绍一下endpoint, 它是介于pod和svc之间的资源。 就是暴露服务要转发的pod的ip地址和端口的列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看endpoints</span><br><span class="line">[root@nginx test]# kubectl get endpoints  kubia </span><br><span class="line">NAME    ENDPOINTS                                                    AGE</span><br><span class="line">kubia   10.42.0.10:8443,10.42.1.10:8443,10.42.1.9:8443 + 3 more...   79m</span><br><span class="line"></span><br><span class="line"># 查看pod IP</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span><br><span class="line">kubia-66tvd   1/1     Running   0          161m   10.42.0.10   81.68.101.212   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kubia-l9w94   1/1     Running   0          128m   10.42.1.9    81.68.229.215   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kubia-vs2kl   1/1     Running   0          125m   10.42.1.10   81.68.229.215   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"># 从svc中也可以看到， endpoints就是待转发pod的IP与端口的集合</span><br><span class="line">[root@nginx test]# kubectl describe svc kubia </span><br><span class="line">Name:              kubia</span><br><span class="line">Namespace:         default</span><br><span class="line">Labels:            &lt;none&gt;</span><br><span class="line">Annotations:       &lt;none&gt;</span><br><span class="line">Selector:          app=kubia</span><br><span class="line">Type:              ClusterIP</span><br><span class="line">IP Families:       &lt;none&gt;</span><br><span class="line">IP:                10.43.7.83</span><br><span class="line">IPs:               &lt;none&gt;</span><br><span class="line">Port:              http  80/TCP</span><br><span class="line">TargetPort:        8080/TCP</span><br><span class="line">Endpoints:         10.42.0.10:8080,10.42.1.10:8080,10.42.1.9:8080</span><br><span class="line">Port:              https  443/TCP</span><br><span class="line">TargetPort:        8443/TCP</span><br><span class="line">Endpoints:         10.42.0.10:8443,10.42.1.10:8443,10.42.1.9:8443</span><br><span class="line">Session Affinity:  None</span><br><span class="line">Events:            &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>这表明服务是利用标签匹配pod， 然后建立endpoints,  将请求转发的endpoints中的一个ip: port上。 所以有的时候服务连接失败，需要查看endpoints是否存在正确。</p>
<p>了解到这一层之后，我们也可以不使用标签匹配pod，手动为服务建立endpoints，只要新建一个endpoints资源，使其与服务的名称相同即可。 </p>
<blockquote>
<p>endpoints本身就是一个资源，而不是service的一部分。</p>
</blockquote>
<h4 id="11-将服务暴露给外部"><a href="#11-将服务暴露给外部" class="headerlink" title="11 将服务暴露给外部"></a>11 将服务暴露给外部</h4><p>目前为止，讨论了集群内部pod的使用。有时我们需要将服务暴露给集群之外的网络，比如前端web服务器。有几种方式可以在外部访问服务。 </p>
<ol>
<li>nodeport型的服务，在集群的每个节点上打开一个端口，因此叫nodeport，将该端口山的流量重定向到服务上，使用集群ip:port既可以访问。 </li>
<li>loadbalance型服务，是nodeport的一种扩展， 这使得服务可以通过一个专用的负载均衡器来访问。 </li>
<li>ingress资源，这是一个完全不同的机制，通过一个ip地址公开多个服务——它运行在http层，因此可以比第四层的服务提供更多的资源。 </li>
</ol>
<p>第一种： 使用nodeport暴露服务到外部</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-svc-nodeport.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service </span><br><span class="line">metadata: </span><br><span class="line">  name: kubia-nodeport </span><br><span class="line">spec: </span><br><span class="line">  type: NodePort </span><br><span class="line">  ports: </span><br><span class="line">  - port: 80 </span><br><span class="line">    targetPort: 8080 </span><br><span class="line">    nodePort: 30123 </span><br><span class="line">  selector: </span><br><span class="line">    app: kubia </span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建</span><br><span class="line">kubectl create -f kubia-svc-nodeport.yaml</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@nginx test]# kubectl get svc kubia-nodeport -o wide </span><br><span class="line">NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span><br><span class="line">kubia-nodeport   NodePort   10.43.254.206   &lt;none&gt;        80:30123/TCP   38m   app=kubia</span><br><span class="line"></span><br><span class="line"># 测试， 本地shell连接 </span><br><span class="line">[C:\~]$ curl http://81.68.229.215:30123</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100    23    0    23    0     0     23      0 --:--:-- --:--:-- --:--:--  1533</span><br><span class="line">You&#x27;ve hit kubia-l9w94</span><br><span class="line"># 这表明外部网络可以连接到集群内部的服务，用浏览器也可以打开。</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/servicepod4.png"></p>
<p>第二种： 使用loadbalance暴露服务到外部</p>
<p>对于提供负载均衡器的云构架才可以使用loadbalancer, 如果不支持则nodebanlancer型svc将退化为nodeport。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-svc-loadbalancer.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service</span><br><span class="line">metadata: </span><br><span class="line">  name: kubia-loadbalancer</span><br><span class="line">spec: </span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports: </span><br><span class="line">  - port: 80 </span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector: </span><br><span class="line">    app: kubia</span><br><span class="line">EOF</span><br><span class="line"># 创建</span><br><span class="line">kubectl create -f kubia-svc-loadbalancer.yaml</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@nginx ~]# kubectl get svc </span><br><span class="line">NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes           ClusterIP      10.43.0.1       &lt;none&gt;        443/TCP          17d</span><br><span class="line">kubia                ClusterIP      10.43.7.83      &lt;none&gt;        80/TCP,443/TCP   18h</span><br><span class="line">kubia-loadbalancer   LoadBalancer   10.43.20.104    &lt;pending&gt;     80:31342/TCP     14m</span><br><span class="line">kubia-nodeport       NodePort       10.43.254.206   &lt;none&gt;        80:30123/TCP     16h</span><br><span class="line">nginx-service        NodePort       10.43.66.77     &lt;none&gt;        80:30080/TCP     16h</span><br><span class="line"></span><br><span class="line"># 测试， 本集群不支持loadbalancer, 所以external-ip状态为pending, 此时loadbalancer就是一个nodeport</span><br><span class="line"># 本地shell测试 node-ip:port ， 连接正常</span><br><span class="line">[C:\~]$ curl http://81.68.229.215:31342</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100    23    0    23    0     0     23      0 --:--:-- --:--:-- --:--:--   741</span><br><span class="line">You&#x27;ve hit kubia-vs2kl</span><br><span class="line"></span><br><span class="line"># 换一个腾讯云的弹性集群测试，支持负载均衡器</span><br><span class="line"># 部署同样的deployment, 然后部署loadlancer, 过程相同，省略 </span><br><span class="line"># 查看 </span><br><span class="line">[root@k8s-node02 ~]# kubectl get svc </span><br><span class="line">NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE</span><br><span class="line">kubernetes           ClusterIP      192.168.0.1     &lt;none&gt;           443/TCP        3d23h</span><br><span class="line">kubia-loadbalancer   LoadBalancer   192.168.0.201   175.27.192.232   80:30493/TCP   67s</span><br><span class="line"># 本地主机测试 </span><br><span class="line">[C:\~]$ curl http://175.27.192.232</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100    33    0    33    0     0     33      0 --:--:-- --:--:-- --:--:--   702</span><br><span class="line">You&#x27;ve hit kubia-778d98d9c-2zpl5</span><br><span class="line"></span><br><span class="line"># 成功了， 直接访问loadbalancer IP即可</span><br></pre></td></tr></table></figure>

<p>第三种: ingress </p>
<p>为什么需要ingress呢， loadbalancer服务需要独立的共有IP地址，二ingress只需要一个公网IP就可以为许多服务提供访问。 当客户向ingress发送请求时，ingress会根据请求的主机名和路径决定请求转发的服务。也就是一个ingress可以暴露多个服务。如下:</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/servicepod7.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kubia-ingress.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: extensions/v1beta1 </span><br><span class="line">kind: Ingress </span><br><span class="line">metadata: </span><br><span class="line">  name: kubia</span><br><span class="line">spec: </span><br><span class="line">  rules: </span><br><span class="line">  - host: kubia.example.com </span><br><span class="line">    http: </span><br><span class="line">      paths: </span><br><span class="line">      - path: / </span><br><span class="line">        backend: </span><br><span class="line">          serviceName: kubia-nodeport </span><br><span class="line">          servicePort: 80</span><br><span class="line">EOF</span><br><span class="line"># 创建</span><br><span class="line">kubectl create -f kubia-ingress.yaml </span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@k8s-node02 ~]# kubectl get ing </span><br><span class="line">NAME    CLASS    HOSTS               ADDRESS        PORTS   AGE</span><br><span class="line">kubia   &lt;none&gt;   kubia.example.com   119.45.3.217   80      34m</span><br><span class="line"></span><br><span class="line"># 访问， 本地要添加dns </span><br><span class="line"># windows在‪C:\Windows\System32\drivers\etc\hosts </span><br><span class="line"># 添加 </span><br><span class="line">119.45.3.217  kubia.example.com</span><br><span class="line"># 访问 </span><br><span class="line">[C:\~]$ curl http://1.13.12.141</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100    33    0    33    0     0     33      0 --:--:-- --:--:-- --:--:--   532</span><br><span class="line">You&#x27;ve hit kubia-778d98d9c-2zpl5</span><br><span class="line"></span><br><span class="line">[C:\~]$ curl http://kubia.example.com</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0</span><br><span class="line">You&#x27;ve hit kubia-778d98d9c-2zpl5</span><br></pre></td></tr></table></figure>

<blockquote>
<p> ingress意为进入或进入的行为，进入的手段和地点</p>
<p>使用ingress，访问链路为客户端——ingress——service——工作负载， 所以ingress配置的时候一定要保证service正常工作，而且serviceName为转发service的名称。</p>
</blockquote>
<p>参考资料： kubernets in action –服务：客户端发现pod并与之通信</p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>非正常关闭vi编辑器时会生成一个.swp文件</title>
    <url>/2021/11/10/2021-11-10-%E9%9D%9E%E6%AD%A3%E5%B8%B8%E5%85%B3%E9%97%ADvi%E7%BC%96%E8%BE%91%E5%99%A8%E6%97%B6%E4%BC%9A%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AA.swp%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="非正常关闭vi编辑器时会生成一个-swp文件"><a href="#非正常关闭vi编辑器时会生成一个-swp文件" class="headerlink" title="非正常关闭vi编辑器时会生成一个.swp文件"></a>非正常关闭vi编辑器时会生成一个.swp文件</h3><p>使用vim，有时看到swp这个文件,这个文件是怎么产生的呢， 当你打开一个文件，vi就会生成这么一个.(filename)swp文件, 以备不测， 如果你正常退出，那么这个这个swp文件将会自动删除 。</p>
<p>不测分为：</p>
<ol>
<li>当你用多个程序编辑同一个文件时, 此时为了避免同一个文件产生两个不同的版本（vim中的原话），还是选择readonly为好。</li>
<li>非常规退出时， 可以用vim -r filename恢复，然后再把swp文件删除, 但要确保swp文件没有用了。 </li>
</ol>
<p>你可以使用来恢复文件</p>
<blockquote>
<p>vi -r {your file name}</p>
</blockquote>
<p>也可以删除swp文件，不然每一次编辑时总是有这个提示。</p>
<blockquote>
<p>rm .{your file name}.swp</p>
</blockquote>
<p>也可以再提示的时候选择<code>R</code>恢复， 恢复后swp文件还是存在，需要删除</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">“.es-server.yaml.swp” already exists!</span><br><span class="line">[O]pen Read-Only, (E)dit anyway, (R)ecover, (Q)uit:</span><br></pre></td></tr></table></figure>

<p>选择<code>Edit anyway</code>，不能解决问题，下次打开文件的时候还是会提示。 </p>
]]></content>
  </entry>
  <entry>
    <title>openfaas v0.2文档</title>
    <url>/2021/11/11/2021-11-12-openfaas-v0.2%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="openfass-让无服务变得简单"><a href="#openfass-让无服务变得简单" class="headerlink" title="openfass  让无服务变得简单"></a>openfass  让无服务变得简单</h3><p>OpenFaaS®使开发人员可以轻松地将事件驱动函数和微服务部署到Kubernetes，而无需重复的模板代码。将您的代码或现有二进制文件打包到Docker镜像中，以获得具有自动伸缩和度量的高度可伸缩端点。</p>
<h3 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a>亮点</h3><ul>
<li>开源函数框架-在任何云上运行它，无需担心锁定</li>
<li>编写任何语言的函数，并将它们打包到Docker/ oci格式的容器中</li>
<li>易于使用的内置UI，强大的CLI和一键式安装</li>
<li>处理流量峰值，并在空闲时进行伸缩</li>
<li>活跃的社区-贡献和归属</li>
</ul>
<h3 id="在线学习"><a href="#在线学习" class="headerlink" title="在线学习"></a>在线学习</h3><p>pass</p>
<h2 id="社群"><a href="#社群" class="headerlink" title="社群"></a>社群</h2><p>pass</p>
<h1 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h1><h2 id="deployment"><a href="#deployment" class="headerlink" title="deployment"></a>deployment</h2><p>OpenFaaS可以部署到Kubernetes、OpenShift、Docker Swarm等多种容器管理工具上，也可以部署到使用faasd的单个主机上。</p>
<p>Kubernetes还是faasd ?</p>
<p>我们建议在工作中使用OpenFaaS时使用Kubernetes或OpenShift，因为它可以很好地扩展，如果您需要，OpenFaaS Ltd可以提供商业支持。一些公司已经在生产中使用了Faasd，但您应该了解其中的权衡。用户以后可以在这两种部署选项之间切换。</p>
<h2 id="PLONK-Stack"><a href="#PLONK-Stack" class="headerlink" title="PLONK Stack"></a>PLONK Stack</h2><p>PLONK是一个用于构建应用程序的云本地堆栈，它代表:</p>
<ul>
<li><p><a href="https://www.bookstack.cn/read/openfaas-0.20-en/d41d8cd98f00b204.md">Prometheus</a>-度量和时间序列</p>
</li>
<li><p>Linux/Linkerd* - OS或service mesh (Linkerd是可选的)</p>
</li>
<li><p>OpenFaaS——计算的管理和自动扩展——PaaS/FaaS, Kubernetes之上的一个开发人员友好的抽象。每个函数或微服务都构建为不可变的Docker容器或oci格式的镜像。</p>
</li>
<li><p>异步消息总线/队列</p>
</li>
<li><p>Kubernetes -声明式的、可扩展的、伸缩的、自修复的集群</p>
</li>
</ul>
<p>Kubernetes上的OpenFaaS包了NATS和Prometheus。您可以在OpenFaaS架构文档中阅读有关堆栈的内容。</p>
<h2 id="Kubernetes-推荐用于生产和工作"><a href="#Kubernetes-推荐用于生产和工作" class="headerlink" title="Kubernetes(推荐用于生产和工作)"></a>Kubernetes(推荐用于生产和工作)</h2><p>关于安全的前言</p>
<p>默认情况下，使用OpenFaaS启用身份验证，但是如果您在公共Internet上使用OpenFaaS，您还需要为您的集群获取TLS证书。免费证书可从LetsEncrypt.org获得。</p>
<p>在Kubernetes集群中安装OpenFaaS有三种推荐方法:</p>
<ul>
<li>使用我们的CLI安装程序arkade -(推荐)</li>
<li>使用Helm chart, Flux或ArgoCD (GitOps工作流)</li>
<li>或者使用静态生成的YAML文件(不推荐)</li>
</ul>
<p>了解关于每个选项以及如何将OpenFaaS部署到Kubernetes的更多信息:<a href="https://www.bookstack.cn/read/openfaas-0.20-en/34026a917156630f.md">Deploy to Kubernetes</a></p>
<h2 id="faasd-每个人的无服务"><a href="#faasd-每个人的无服务" class="headerlink" title="faasd - 每个人的无服务"></a>faasd - 每个人的无服务</h2><p>faasd是OpenFaaS，没有Kubernetes的复杂性和成本。它在要求非常低的单个主机上运行良好，可以在几分钟内部署。在内部，它使用容器和容器网络接口(CNI)以及来自主项目的相同核心OpenFaaS组件。</p>
<p>什么时候应该在Kubernetes上使用faasd over OpenFaaS ?</p>
<ul>
<li>你有一个成本敏感的项目-运行faasd在5-10美元的VPS或在你的Raspberry Pi上</li>
<li>当您只需要一些功能或微服务，而不需要集群的成本时</li>
<li>当你没有时间学习或管理Kubernetes的时候</li>
<li>在物联网和边缘用例中部署嵌入式应用</li>
<li>将应用程序压缩包装以供客户或客户使用</li>
</ul>
<p><a href="https://github.com/openfaas/faasd/">Deploy faasd</a></p>
<h2 id="OpenShift"><a href="#OpenShift" class="headerlink" title="OpenShift"></a>OpenShift</h2><p>OpenShift是由RedHat生产的Kubernetes的一个变体。</p>
<p>您可以使用我们的CLI安装程序<a href="https://www.bookstack.cn/read/openfaas-0.20-en/d41d8cd98f00b204.md">arkade</a> 或标准helm chart部署到OpenShift。</p>
<p><a href="https://www.bookstack.cn/read/openfaas-0.20-en/f81fd004e195cc7a.md">Deploy to OpenShift</a></p>
<h2 id="Docker-Swarm-弃用"><a href="#Docker-Swarm-弃用" class="headerlink" title="Docker Swarm (弃用)"></a>Docker Swarm (弃用)</h2><p>取消免费社区支持，Docker Swarm的免费社区支持已经停止。如果您在业务中运行Docker Swarm和OpenFaaS，并且需要持续的支持，那么请尽快联系支持人员。</p>
<p>为什么做出这个决定?Docker Swarm被广泛认为是“生命终结”产品。像Kubernetes这样的项目拥有更广泛的生态系统，并不断从各自的社区获得投资。</p>
<p>如果你被Docker Swarm所吸引是因为你认为它比Kubernetes更容易管理，我们建议你看看托管的Kubernetes服务，或 <a href="https://www.bookstack.cn/read/openfaas-0.20-en/d41d8cd98f00b204.md">k3s.io</a>.</p>
<p>如果你几乎不需要任何操作，那么faasd(上面)应该是你的首选。</p>
<h1 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>您可以使用curl实用程序脚本、brew或从发布页面下载二进制文件来安装CLI。安装完成后，您将获得faas-cli命令和faas别名。</p>
<h3 id="Linux-or-macOS"><a href="#Linux-or-macOS" class="headerlink" title="Linux or macOS"></a>Linux or macOS</h3><p>使用curl脚本:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl -sSL https://cli.openfaas.com | sudo -E sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>标志-E允许将任何http_proxy环境变量传递给安装bash脚本。</p>
</blockquote>
<p>使用curl将二进制文件下载到当前目录，然后打印安装说明:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ curl -sSL https://cli.openfaas.com | sh</span><br></pre></td></tr></table></figure>

<p>通过 brew</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ brew install faas-cli</span><br></pre></td></tr></table></figure>

<p>注意, brew版本可能不会运行最新的小版本，但会定期更新。</p>
<h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><p>在powershell中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$version = (Invoke-WebRequest &quot;https://api.github.com/repos/openfaas/faas-cli/releases/latest&quot; | ConvertFrom-Json)[0].tag_name</span><br><span class="line">(New-Object System.Net.WebClient).DownloadFile(&quot;https://github.com/openfaas/faas-cli/releases/download/$version/faas-cli.exe&quot;, &quot;faas-cli.exe&quot;)</span><br></pre></td></tr></table></figure>

<h3 id="覆盖环境变量"><a href="#覆盖环境变量" class="headerlink" title="覆盖环境变量"></a>覆盖环境变量</h3><p>如果set和没有设置其他命令行标志，将默认使用几个覆盖。</p>
<ul>
<li><code>OPENFAAS_TEMPLATE_URL</code> -设置获取模板的默认URL</li>
<li><code>OPENFAAS_PREFIX</code> - 当使用 <code>faas-cli new</code> - 这可以替代 <code>--prefix</code></li>
<li><code>OPENFAAS_URL</code> -来覆盖默认网关URL</li>
</ul>
<h3 id="使用sudo运行-faas-cli"><a href="#使用sudo运行-faas-cli" class="headerlink" title="使用sudo运行 faas-cli"></a>使用sudo运行 <code>faas-cli</code></h3><p>如果您使用sudo运行faas-cli，我们建议使用sudo -E来传递您可能配置的任何环境变量，如http_proxy、https_proxy或no_proxy。</p>
<h3 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h3><p>faas-cli还可以作为Docker镜像使用，这使得它可以方便地用于CI作业，如使用Jenkins管道或cron中的任务。</p>
<p><a href="https://hub.docker.com/r/openfaas/faas-cli/tags/">https://hub.docker.com/r/openfaas/faas-cli/tags/</a></p>
<p>它没有“latest”标签，请在Docker Hub的标签页中找到您想要使用的CLI版本。这些对应于GitHub的发布。</p>
<blockquote>
<p>注意:Docker映像不能用于直接执行构建，但你可以使用它来生成一个构建上下文，可以与容器构建器(如Docker, buildkit或Kaniko)在构建管道的另一部分一起使用。</p>
</blockquote>
<p>Docker映像的用例:</p>
<ul>
<li>不运行docker build - faas-cli——shrinkwrap来生成构建上下文</li>
<li>将现有映像部署到远程服务器faas-cli Deploy</li>
<li>使用faas-cli secret管理秘密</li>
<li>通过使用faas-cli调用cron调用函数</li>
<li>使用faas-cli信息检查远程网关的运行状况</li>
</ul>
<h3 id="从源代码安装"><a href="#从源代码安装" class="headerlink" title="从源代码安装"></a>从源代码安装</h3><p>该<a href="https://www.bookstack.cn/read/openfaas-0.20-en/742c32d44c647dc9.md#contribute">指南</a>提供了从源代码构建和配置Golang开发环境的说明。</p>
<ul>
<li>GitHub上的star /fork: <a href="https://github.com/openfaas/faas-cli">faas-cli</a></li>
</ul>
<h3 id="教程-学习如何使用CLI"><a href="#教程-学习如何使用CLI" class="headerlink" title="教程: 学习如何使用CLI"></a>教程: 学习如何使用CLI</h3><p><a href="https://blog.alexellis.io/quickstart-openfaas-cli/">Morning coffee with the OpenFaaS CLI</a></p>
<h2 id="创建新的函数"><a href="#创建新的函数" class="headerlink" title="创建新的函数"></a>创建新的函数</h2><h3 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h3><p>一旦你安装了<code>faas-cli</code>，你可以开始通过<code>faas-cli up</code>命令或使用单独的命令来创建和部署函数:</p>
<ul>
<li><code>faas-cli build</code>  构建映像到本地Docker库中</li>
<li><code>faas-cli push</code>  将该映像推到远程容器注册表</li>
<li><code>faas-cli deploy</code> 将函数部署到集群中</li>
</ul>
<p><code>faas-cli up</code>命令在一个命令中自动执行上述所有操作。</p>
<p>对于Raspberry Pi和ARM，你必须使用publish命令而不是build和push，或者up。</p>
<p>请看这里的注释:<a href="https://www.bookstack.cn/read/openfaas-0.20-en/094921046add2521.md">Building multi-arch images for ARM and Raspberry Pi</a></p>
<h3 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h3><p>OpenFaaS CLI有一个内置的模板引擎，可以用给定的编程语言创建新的函数。它的工作方式是从当前工作文件夹中的<code>./template</code>位置读取模板列表。</p>
<p>在创建一个新函数之前，请确保您从GitHub通过 <a href="https://github.com/openfaas/templates">templates repository</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ faas-cli template pull</span><br></pre></td></tr></table></figure>

<p>本页面展示了如何在最流行的语言中生成函数，并解释了如何管理它们的依赖关系。</p>
<h3 id="Classic-vs-of-watchdog模板"><a href="#Classic-vs-of-watchdog模板" class="headerlink" title="Classic vs. of-watchdog模板"></a>Classic vs. of-watchdog模板</h3><p>经典模板保存在 <a href="https://github.com/openfaas/templates">openfaas/templates</a>存储库中，并且基于使用STDIO与函数通信的<em>Classic Watchdog</em>。watchdog使用HTTP与函数进行通信，它的大多数模板都可以在GitHub上的<a href="https://github.com/openfaas-incubator/">openfaas-incubator</a> 组织和商店中获得。</p>
<p>如何选择： </p>
<ul>
<li>如果你正在开始或遵循教程或指南，请使用<em>Classic Watchdog</em></li>
<li>如果您需要更高的性能或需要完全控制HTTP响应，请使用of-watchdog</li>
</ul>
<p>参考：  <a href="https://www.bookstack.cn/read/openfaas-0.20-en/e9ae346d3d971482.md">watchdog design</a></p>
<h3 id="存储过程注册模板"><a href="#存储过程注册模板" class="headerlink" title="存储过程注册模板"></a>存储过程注册模板</h3><p>您可以从官方商店浏览模板，或者创建自己的商店并在那里添加自己的模板。要查看哪些模板是可用的类型<code>faas-cli template store list</code>，你应该在终端中看到以下内容:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ faas-cli template store list</span><br><span class="line">NAME                    SOURCE             DESCRIPTION</span><br><span class="line">csharp                  openfaas           Official C# template</span><br><span class="line">dockerfile              openfaas           Official Dockerfile template</span><br><span class="line">...</span><br><span class="line">node10-express          openfaas-incubator NodeJS 10 Express template</span><br><span class="line">ruby-http               openfaas-incubator Ruby 2.4 HTTP template</span><br><span class="line">golang-middleware       openfaas-incubator Golang Middleware template</span><br><span class="line">csharp-httprequest      distantcam         C# HTTP template</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>选择一个模板并使用命令在本地检索它:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ faas-cli template store pull node10-express</span><br></pre></td></tr></table></figure>

<p>下载后，您选择的模板和存储在同一存储库中的其他模板将可用:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ faas-cli new --list</span><br><span class="line">Languages available as templates:</span><br><span class="line">- node10-express</span><br></pre></td></tr></table></figure>

<p>您可以通过为这两个命令指定<code>——url</code>标志来拉出并列出自定义模板存储，从而添加自己的存储。</p>
<p>经典模板保存在 <a href="https://github.com/openfaas/templates">openfaas/templates</a> 存储库中。</p>
<h3 id="获取模板"><a href="#获取模板" class="headerlink" title="获取模板"></a>获取模板</h3><p>下面列出了几个可用的Golang模板。</p>
<table>
<thead>
<tr>
<th align="left">Name</th>
<th align="left">Style</th>
<th align="left">Watchdog</th>
<th align="left">Dependencies</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>go</code></td>
<td align="left">Function</td>
<td align="left">classic</td>
<td align="left"><code>dep</code></td>
</tr>
<tr>
<td align="left"><code>golang-middleware</code></td>
<td align="left">Microservice</td>
<td align="left">of-watchdog</td>
<td align="left"><code>dep</code> or Go modules</td>
</tr>
<tr>
<td align="left"><code>golang-http</code></td>
<td align="left">Function</td>
<td align="left">of-watchdog</td>
<td align="left"><code>dep</code> or Go modules</td>
</tr>
</tbody></table>
<p>所有的模板都可以通过<code>faas-cli template store list/pull</code></p>
<h3 id="Go-golang-http-（of-watchdog-template）"><a href="#Go-golang-http-（of-watchdog-template）" class="headerlink" title="Go golang-http （of-watchdog template）"></a>Go <code>golang-http</code> （of-watchdog template）</h3><p><a href="https://github.com/openfaas-incubator/golang-http-template">Read the README for golang-http</a>此模板具有与AWS Lambda类似的API。</p>
<p>Golang模块通过 <code>--build-arg</code> 使用 <code> GO111MODULE=1</code> 或者<code>GO111MODULE=auto</code></p>
<h4 id="Go-golang-middleware-of-watchdog-template"><a href="#Go-golang-middleware-of-watchdog-template" class="headerlink" title="Go golang-middleware - (of-watchdog template)"></a>Go <code>golang-middleware</code> - (of-watchdog template)</h4>]]></content>
  </entry>
  <entry>
    <title>什么是serverless</title>
    <url>/2021/11/12/2021-11-12-%E4%BB%80%E4%B9%88%E6%98%AFserverless/</url>
    <content><![CDATA[<h1 id="1-什么是severless"><a href="#1-什么是severless" class="headerlink" title="1 什么是severless ?"></a>1 什么是severless ?</h1><p>Serverless（无服务器架构）是指服务端逻辑由开发者实现，运行在无状态的计算容器中，由事件触发，完全被第三方管理，其业务层面的状态则存储在数据库或其他介质中。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%8F%91%E5%B1%95.png"></p>
<p>纵观云原生技术的发展过程， 体现出的一条脉络就是对底层实现、基础设施关心的越来越少，而把重心放在业务逻辑上。</p>
<p>那么serverless到底是什么呢？ 下引用[serverless handbook](<a href="https://www.bookstack.cn/read/serverless-handbook/concepts-what-is-serverless.md">什么是 Serverless - Serverless 的定义 - 《无服务架构实践手册（Serverless Handbook）》 - 书栈网 · BookStack</a>)给出通俗易懂和具体的定义。</p>
<ul>
<li> 简单版：Serverless（无服务器架构）指的是服务端逻辑由开发者实现，运行在无状态的计算容器中，由事件触发，完全被第三方管理，而业务层面的状态则记录在数据库或存储资源中。</li>
<li> <strong>进阶定义</strong>:  Serverless是由事件（event）驱动（例如 HTTP、pub/sub）的全托管计算服务。用户无需管理服务器等基础设施，只需编写代码和选择触发器（trigger)，比如 RPC 请求、定时器等并上传，其余的工作（如实例选择、扩缩容、部署、容灾、监控、日志、安全补丁等）全部由 serverless 系统托管。用户只需要为代码实际运行消耗的资源付费——代码未运行则不产生费用。</li>
</ul>
<blockquote>
<p> 就像无线互联网实际有的地方也需要用到有线连接一样，无服务器架构仍然在某处有服务器。开发者无需关注服务器，只需关注代码。erverless 相对于 serverful，对业务用户强调 noserver（serverless 并不是说没有服务器，只是业务人员无需关注服务器了，代码仍然是运行在真实存在的服务器上）的运维理念，业务人员只需要聚焦业务逻辑代码。</p>
</blockquote>
<h1 id="2-有服务到无服务构架有哪些变化？"><a href="#2-有服务到无服务构架有哪些变化？" class="headerlink" title="2 有服务到无服务构架有哪些变化？"></a>2 有服务到无服务构架有哪些变化？</h1><ol>
<li><strong>弱化了存储和计算之间的联系。</strong>服务的储存和计算被分开部署和收费，存储不再是服务本身的一部分，而是演变成了独立的云服务，这使得计算变得无状态化，更容易调度和扩缩容，同时也降低了数据丢失的风险。</li>
<li><strong>代码的执行不再需要手动分配资源。</strong>不需要为服务的运行指定需要的资源（比如使用几台机器、多大的带宽、多大的磁盘等），只需要提供一份代码，剩下的交由 serverless 平台去处理就行了。当前阶段的实现平台分配资源时还需要用户方提供一些策略，例如单个实例的规格和最大并发数，单实例的最大 CPU 使用率。理想的情况是通过某些学习算法来进行完全自动的自适应分配。</li>
<li><strong>按使用量计费。</strong>Serverless按照服务的使用量（调用次数、时长等）计费，而不是像传统的 serverful 服务那样，按照使用的资源（ECS 实例、VM 的规格等）计费。</li>
</ol>
<p>云改变了我们对操作系统的认知，原来一个系统的计算资源、存储和网络是可以分离配置的，而且还可以弹性扩展，但是长久以来，我们在开发应用时始终没有摆脱的服务器的束缚（或者说认知），应用必须运行在不论是实体还是虚拟的服务器上，必须经过部署、配置、初始化才可以运行，还需要对服务器和应用进行监控和管理，还需要保证数据的安全性，这些云能够帮我们简化吗？<strong>让我们只要关注自己代码的逻辑就好了，其它的东西让云帮我实现就好了。</strong></p>
<h1 id="3-serverless发展历史"><a href="#3-serverless发展历史" class="headerlink" title="3 serverless发展历史"></a>3 serverless发展历史</h1><p>serverless是云化的延伸，为了更好的理解, 回顾一下云计算的发展过程</p>
<ul>
<li>LaaS, 2006 年 AWS 推出 EC2（Elastic Compute Cloud），作为第一代 IaaS（Infrastructure as a Service），用户可以通过 AWS 快速的申请到计算资源，并在上面部署自己的互联网服务。IaaS 从本质上讲是服务器租赁并提供基础设施外包服务。<strong>就比如我们用的水和电一样</strong>，我们不会自己去引入自来水和发电，而是直接从自来水公司和电网公司购入，并根据实际使用付费。这使得极大降低了基础设施的成本，而且具有很好扩展性。 </li>
<li>PaaS（Platform as a Service）是构建在 IaaS 之上的一种平台服务，提供操作系统安装、监控和服务发现等功能，用户只需要部署自己的应用即可。</li>
<li>历史上第一个 Serverless 平台可以追溯到 2006 年，名为 Zimki，这个平台提供服务端 JavaScript 应用，虽然他们没有使用Serverless 这个名词，但是他们是第一个“按照实际调用付费”的平台。第一个使用 Serverless 名词的是 <a href="https://iron.io/">iron.io</a>。</li>
<li>Serverless 实际发展已经有 10 年之久，而随着以 Kubernetes 为基础的的云原生应用平台的兴起，serverless 再度成为人民追逐的焦点。</li>
</ul>
<h1 id="4-severless-分类"><a href="#4-severless-分类" class="headerlink" title="4 severless 分类"></a>4 severless 分类</h1><p>serverless通常分为两个领域，BaaS（Backend as a Service）和 FaaS（Function as a Service)。 </p>
<ul>
<li><p>BaaS（Backend as a Service）后端即服务，一般是一个个的 API 调用后端或别人已经实现好的程序逻辑，比如身份验证服务 Auth0，这些 BaaS 通常会用来管理数据，还有很多公有云上提供的我们常用的开源软件的商用服务，比如亚马逊的 RDS 可以替代我们自己部署的 MySQL，还有各种其它数据库和存储服务。</p>
</li>
<li><p>FaaS（Functions as a Service）函数即服务，FaaS 是无服务器计算的一种形式，当前使用最广泛的是 AWS 的 Lambada。</p>
</li>
</ul>
<p>FaaS 本质上是一种事件驱动的由消息触发的服务，FaaS 供应商一般会集成各种同步和异步的事件源，通过订阅这些事件源，可以突发或者定期的触发函数运行。传统的服务器端软件不同是经应用程序部署到拥有操作系统的虚拟机或者容器中，一般需要长时间驻留在操作系统中运行，而 FaaS 是直接将程序部署上到平台上即可，当有事件到来时触发执行，执行完了就可以卸载掉。</p>
<h1 id="5-severles优缺点"><a href="#5-severles优缺点" class="headerlink" title="5 severles优缺点"></a>5 severles优缺点</h1><h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><ul>
<li><p> 降低运营成本， Serverless 是非常简单的外包解决方案。它可以让您委托服务提供商管理服务器、数据库和应用程序甚至逻辑，否则您就不得不自己来维护。由于这个服务使用者的数量会非常庞大，于是就会产生规模经济效应。在降低成本上包含了两个方面，即基础设施的成本和人员（运营/开发）的成本。</p>
</li>
<li><p>降低开发成本， aaS 和 PaaS 存在的前提是，服务器和操作系统管理可以商品化。Serverless 作为另一种服务的结果是整个应用程序组件被商品化。</p>
</li>
<li><p>扩展能力，Serverless 架构一个显而易见的优点即“横向扩展是完全自动的、有弹性的、且由服务提供者所管理”。从基本的基础设施方面受益最大的好处是，用户只需支付所需要的计算能力。</p>
</li>
<li><p>更简单的管理，Serverless 架构明显比其他架构更简单。更少的组件，就意味着您的管理开销会更少。</p>
</li>
<li><p>绿色的计算， 按照《福布斯》杂志的统计，在商业和企业数据中心的典型服务器仅提供 5%～15% 的平均最大处理能力的输出。这无疑是一种资源的巨大浪费。随着Serverless架构的出现，让服务提供商提供我们的计算能力最大限度满足实时需求。这将使我们更有效地利用计算资源。</p>
<p>在上面我们提到了使用 IaaS给 我们带来了五点好处，FaaS 当然也包括了这些好处，但是它给我们带来的最大的好处就是<strong>多快好省</strong>。减少从概念原型到实施的等待时间，比自己维护服务更省钱。</p>
</li>
<li><p>降低人力成本，不需要再自己维护服务器，操心服务器的各种性能指标和资源利用率，而是关心应用程序本身的状态和逻辑。而且 serverless 应用本身的部署也十分容易，我们只要上传基本的代码但愿，例如 Javascript 或 Python 的源代码的 zip 文件，以及基于JVM的语言的纯 JAR 文件。不需使用 Puppet、Chef、Ansible 或 Docker 来进行配置管理，降低了运维成本。同时，对于运维来说，也不再需要监控那些更底层的如磁盘使用量、CPU 使用率等底层和长期的指标信息，而是监控应用程序本身的度量，这将更加直观和有效。</p>
</li>
<li><p>降低风险，对于组件越多越复杂的系统，出故障的风险就越大。我们使用 BaaS 或 FaaS 将它们外包出去，让专业人员来处理这些故障，有时候比我们自己来修复更可靠，利用专业人员的知识来降低停机的风险，缩短故障修复的时间，让我们的系统稳定性更高。</p>
</li>
<li><p>减少资源开销，我们在申请主机资源一般会评估一个峰值最大开销来申请资源，往往导致过度的配置，这意味着即使在主机闲置的状态下也要始终支付峰值容量的开销。对于某些应用来说这是不得已的做法，比如数据库这种很难扩展的应用，而对于普通应用这就显得不太合理了，虽然我们都觉得即使浪费了资源也比当峰值到来时应用程序因为资源不足而挂掉好。解决这个问题的一个办法就是，不计划到底需要使用多少资源，而是根据实际需要来请求资源，当然前提必须是整个资源池是充足的（公有云显然更适合）。根据使用时间来付费，根据每次申请的计算资源来付费，让计费的粒度更小，将更有利于降低资源的开销。这是对应用程序本身的优化，例如让每次请求耗时更短，让每次消耗的资源更少将能够显著节省成本。</p>
</li>
<li><p>增加缩放的灵活性， 以 AWS Lamba 为例，当平台接收到第一个触发函数的事件时，它将启动一个容器来运行你的代码。如果此时收到了新的事件，而第一个容器仍在处理上一个事件，平台将启动第二个代码实例来处理第二个事件。AWS lambad 的这种自动的零管理水平缩放，将持续到有足够的代码实例来处理所有的工作负载。但是，AWS 仍然只会向您收取代码的执行时间，无论它需要启动多少个容器实例要满足你的负载请求。例如，假设所有事件的总执行时间是相同的，在一个容器中按顺序调用Lambda 100 次与在 100 个不同容器中同时调用 100 次 Lambda 的成本是 一样的。当然 AWS Lambada 也不会无限制的扩展实例个数，如果有人对你发起了 DDos 攻击怎么办，那么不就会产生高昂的成本吗？AWS 是有默认限制的，默认执行 Lambada 函数最大并发数是 1000。</p>
</li>
<li><p>缩短创新周期，小团队的开发人员正可以在几天之内从头开始开发应用程序并部署到生产。使用短而简单的函数和事件来粘合强大的驱动数据存储和服务的 API。完成的应用程序具有高度可用性和可扩展性，利用率高，成本低，部署速度快。以 Docker 为代表的容器技术仅仅是缩短了应用程序的迭代周期，而 serverless 技术是直接缩短了创新周期，从概念到最小可行性部署的时间，让初级开发人员也能在很短的时间内完成以前通常要经验丰富的工程师才能完成的项目。</p>
</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li> 状态管理， 要实现自由的缩放，无状态是必须的，而对于有状态的服务，使用serverless这就是丧失了灵活性，有状态服务需要与存储交互就不可避免的增加了延迟和复杂性。</li>
<li>延迟，应用程序中不同组件的访问延迟是一个大问题，我们可以通过使用专有的网络协议、RPC 调用、数据格式来优化，或者是将实例放在同一个机架内或同一个主机实例上来优化以减少延迟。而 serverless 应用程序是高度分布式、低耦合的，这就意味着延迟将始终是一个问题，单纯使用 serverless 的应用程序是不太现实的。</li>
<li>本地测试，Serverless 应用的本地测试困难是一个很棘手的问题。虽然可以在测试环境下使用各种数据库和消息队列来模拟生产环境，但是对于无服务应用的集成或者端到端测试尤其困难，很难在本地模拟应用程序的各种连接，并与性能和缩放的特性结合起来测试，并且 serverless 应用本身也是分布式的，简单的将无数的 FaaS 和 BaaS 组件粘合起来也是有挑战性的。</li>
</ul>
<h1 id="5-serverless使用场景"><a href="#5-serverless使用场景" class="headerlink" title="5 serverless使用场景"></a>5 serverless使用场景</h1><p>了解Severless的应用优劣之后，我们看一下severless比较适合的场景。 </p>
<ul>
<li>异步的并发，组件可独立部署和扩展</li>
<li>应对突发或服务使用量不可预测（主要是为了节约成本，因为 Serverless 应用在不运行时不收费）</li>
<li>短暂、无状态的应用，对冷启动时间不敏感</li>
<li>需要快速开发迭代的业务（因为无需提前申请资源，因此可以加快业务上线速度）</li>
</ul>
<p>Serverless 的使用场景示例如：</p>
<ul>
<li>ETL</li>
<li>机器学习及 AI 模型处理</li>
<li>图片处理</li>
<li>IoT 传感器数据分析</li>
<li>流处理</li>
<li>聊天机器人</li>
</ul>
<p>示例： </p>
<p>我们以一个游戏应用为例，来说明什么是 serverless 应用。</p>
<p>一款移动端游戏至少包含如下几个特性：</p>
<ul>
<li>移动端友好的用户体验</li>
<li>用户管理和权限认证</li>
<li>关卡、升级等游戏逻辑，游戏排行，玩家的等级、任务等信息</li>
</ul>
<p>传统的应用程序架构可能是这样的：</p>
<p><img src="https://static.sitestack.cn/projects/serverless-handbook/aa9eaf9b461ca39ea6b4bf01fc5f129b.jpeg" alt="传统应用程序架构"></p>
<ul>
<li>一个 app 前端，iOS 或者安卓</li>
<li>用 Java 写的后端，使用 JBoss 或者 Tomcat 做 server 运行</li>
<li>使用关系型数据库存储用户数据，如 MySQL</li>
</ul>
<p>这样的架构可以让前端十分轻便，不需要做什么应用逻辑，只是负责渲染用户界面，将请求通过 HTTP 发送给后端，而所有的数据操作都是有由后端的 Java 程序来完成的。</p>
<p>这样的架构开发起来比较容易，但是维护起来确十分复杂，前端开发、后端的开发都需要十分专业的人员、环境的配置，还要有人专门维护数据库、应用的更新和升级。</p>
<p><img src="https://static.sitestack.cn/projects/serverless-handbook/37377bea471dae7039d9335f7b232a8e.jpeg" alt="Serverless 架构"></p>
<p>而在 serverless 架构中，我们不再需要在服务器端代码中存储任何会话状态，而是直接将它们存储在 NoSQL 中，这样将使应用程序无状态，有助于弹性扩展。前端可以直接利用 BaaS 而减少后端的编码需求，这样架构的本质上是减少了应用程序开发的人力成本，降低了自己维护基础设施的风险，而且利用云的能力更便于扩展和快速迭代。</p>
<h1 id="6-serverless核心技术"><a href="#6-serverless核心技术" class="headerlink" title="6 serverless核心技术"></a>6 serverless核心技术</h1><p>Serverless 是由事件驱动的全托管计算服务，它的核心技术包括：</p>
<ul>
<li>函数的规范定义</li>
<li>函数部署流水线</li>
<li>Workflow 设置</li>
<li>0-m-n 扩缩容</li>
<li>快速冷启动</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>云原生经过这么多年的发展，已经逐渐变成到用户仅需关注业务和所需的资源。比如，通过K8S这类编排工具，用户只要关注自己的计算和需要的资源（CPU、内存等）就行了，不需要操心到机器这一层。serverless的发展这条路走的越来越远，因为这极大的提高了资源的使用效率，降低了成本。这就是生产力的体现。 Serverless架构让人们不再操心运行所需的资源，只需关注自己的业务逻辑，并且为实际消耗的资源付费。任何新概念新技术的落地，本质上都是要和具体业务去结合，去真正解决具体问题。虽然Serverless很多地方不成熟，亟待完善。不过Serverless自身的特性，对于开发者来说，吸引力是巨大的。</p>
<blockquote>
<p>参考文献： severless handbook </p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>k8s部署小游戏</title>
    <url>/2021/11/14/2021-11-14-k8s%E9%83%A8%E7%BD%B2%E5%B0%8F%E6%B8%B8%E6%88%8F/</url>
    <content><![CDATA[<h3 id="k8s部署小游戏"><a href="#k8s部署小游戏" class="headerlink" title="k8s部署小游戏"></a>k8s部署小游戏</h3><p>k8s部署小游戏非常简单，比js前端部署方便多了。下面试一试玩一玩<br><code>1 查看镜像</code><br>docker hub里已经有其他人上传的游戏镜像了，我们可以直接拿来用，这就是镜像仓库的优势，可以直接使用别人造好的轮子。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-node02 ~]# docker search 2048 </span><br><span class="line">NAME                    DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">quchaonet/2048          项目:[2048游戏]-一个经典的网页小游戏-镜像定…                     6                                       </span><br><span class="line">blackicebird/2048       2048 with logging                               4                                       </span><br><span class="line">amigoscode/2048                                                         1                                       </span><br><span class="line">ponsfrilus/2048nginx    A nginx containter wich run 2048                1                                       [OK]</span><br></pre></td></tr></table></figure>
<p><code>2 部署pod</code><br>使用k8s编排容器，部署一个deploy, 还能高可用 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; game-deploy.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: game-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: game</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: game</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: game</span><br><span class="line">        image: blackicebird/2048</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">EOF</span><br><span class="line"># 刚才查到的star多的镜像写上去  </span><br><span class="line">kubectl create -f game-deploy.yaml</span><br></pre></td></tr></table></figure>
<p><code>部署路由，外部访问</code><br>起一个loadbalancer服务，让客户端可以访问到pod, 注意标签对应deploy的标签， targetPort端口是pod的端口.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; game-loadbalancer.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service</span><br><span class="line">metadata: </span><br><span class="line">  name: game-loadbalancer</span><br><span class="line">spec: </span><br><span class="line">  type: LoadBalancer</span><br><span class="line">  ports: </span><br><span class="line">  - port: 80 </span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector: </span><br><span class="line">    app: game</span><br><span class="line">EOF</span><br><span class="line"># 启动</span><br><span class="line">kubectl create -f game-loadbalancer.yaml</span><br></pre></td></tr></table></figure>
<p><code>查看</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@k8s-node02 ~]# kubectl get po </span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">game-deployment-84bf68885d-bwctb   1/1     Running   0          21m</span><br><span class="line">game-deployment-84bf68885d-j9qq9   1/1     Running   0          21m</span><br><span class="line">[root@k8s-node02 ~]# kubectl get svc </span><br><span class="line">NAME                TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE</span><br><span class="line">game-loadbalancer   LoadBalancer   192.168.0.117   175.27.183.90   80:31382/TCP   18m</span><br><span class="line">kubernetes          ClusterIP      192.168.0.1     &lt;none&gt;          443/TCP        9d</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>访问</code></p>
<p>打开游览器, EXTERNAL-IP:<port></p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/2048-.png"></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>vim进阶使用</title>
    <url>/2021/11/15/2021-11-15-vim%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>用了一段时间vim感觉其确实是很强的编辑器，前提是熟悉vim的使用。如果只会切换模式、输入，可能vim感觉并不是很好用，所以说vim入门难。从我的使用经验来看，vim的灵活性上限很高，想要融汇贯通，随心输入，必须先熟悉基本的操作，然后在每次使用vim的时候，任何操作，即使是简单的操作也要求自己使用最方便的方法，不知道可以去查，然后记录并多多练习，开始一段时间按会很痛苦，但是会进步很快。为了系统地掌握vim的命令，加深记忆并方便查找，这里总结vim用法。</p>
<h3 id="1-光标移动"><a href="#1-光标移动" class="headerlink" title="1 光标移动"></a>1 光标移动</h3><h4 id="1-1-最小的移动单元"><a href="#1-1-最小的移动单元" class="headerlink" title="1.1 最小的移动单元"></a>1.1 最小的移动单元</h4><ul>
<li>h 左 </li>
<li>j 下</li>
<li>k 上</li>
<li>l 右</li>
</ul>
<p>不是很好记，但用的多了就熟悉了，总的来说hjkl四个键可移动光标，左边的h就是向左，右边l向右。j像一个向下钩子，为向下。剩下的k向上。</p>
<h4 id="1-2-以单词为单位的光标移动"><a href="#1-2-以单词为单位的光标移动" class="headerlink" title="1.2 以单词为单位的光标移动"></a>1.2 以单词为单位的光标移动</h4><p>w， W向右移动到下一个单词开头。</p>
<p>e,    E向右移动到单词结尾 。</p>
<p>b,   B向左移动到单词开头。</p>
<h4 id="1-3-更大的移动方法"><a href="#1-3-更大的移动方法" class="headerlink" title="1.3 更大的移动方法"></a>1.3 更大的移动方法</h4>]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>EFK日志管理框架部署</title>
    <url>/2021/11/16/2021-11-16-EFK%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<h1 id="1-工具介绍"><a href="#1-工具介绍" class="headerlink" title="1 工具介绍"></a>1 工具介绍</h1><p>Kubernetes 中比较流行的日志收集解决方案是 <code>Elasticsearch</code>、<code>Fluentd</code> 和 <code>Kibana</code>（EFK）技术栈，也是官方现在比较推荐的一种方案。 </p>
<p><code>Elasticsearch</code> 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于<strong>索引和搜索大量日志数据</strong>，也可用于搜索许多不同类型的文档。</p>
<p><code>Kibana</code> 是一个功能强大的数<strong>据可视化 Dashboard</strong>，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。</p>
<p><code>Fluentd</code>是一个流行的开源<strong>数据收集器</strong>，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。</p>
<p><img src="E:\blogpic\efk.png"></p>
<h1 id="2-配置-Elasticsearch-集群"><a href="#2-配置-Elasticsearch-集群" class="headerlink" title="2 配置 Elasticsearch 集群"></a>2 配置 Elasticsearch 集群</h1><p>2.1 命名空间 </p>
<p>创建集群之前，我们先建立一个日志管理的命名空间，用来存放日志分析的所有资源，方便查看和管理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl create namespace logging</span><br></pre></td></tr></table></figure>

<p> 2.2 创建es服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; elasticsearch-svc.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: elasticsearch</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    app: elasticsearch</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: elasticsearch</span><br><span class="line">  clusterIP: None</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9200</span><br><span class="line">      name: rest</span><br><span class="line">    - port: 9300</span><br><span class="line">      name: inter-node</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl create -f elasticsearch-svc.yaml</span><br><span class="line"># 查看 </span><br><span class="line">kubectl get svc --namespace=logging</span><br></pre></td></tr></table></figure>

<p>2.3 statfulset </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; elasticsearch-storageclass.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: es-cluster</span><br><span class="line">  namespace: logging</span><br><span class="line">spec:</span><br><span class="line">  serviceName: elasticsearch</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: elasticsearch</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: elasticsearch</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: elasticsearch</span><br><span class="line">        image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.4.3</span><br><span class="line">        resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 1000m</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 100m</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9200</span><br><span class="line">          name: rest</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9300</span><br><span class="line">          name: inter-node</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: /usr/share/elasticsearch/data</span><br><span class="line">        env:</span><br><span class="line">          - name: cluster.name</span><br><span class="line">            value: k8s-logs</span><br><span class="line">          - name: node.name</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: metadata.name</span><br><span class="line">          - name: discovery.zen.ping.unicast.hosts</span><br><span class="line">            value: &quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot;</span><br><span class="line">          - name: discovery.zen.minimum_master_nodes</span><br><span class="line">            value: &quot;2&quot;</span><br><span class="line">          - name: ES_JAVA_OPTS</span><br><span class="line">            value: &quot;-Xms512m -Xmx512m&quot;</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: fix-permissions</span><br><span class="line">        image: busybox</span><br><span class="line">        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;]</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: data</span><br><span class="line">          mountPath: /usr/share/elasticsearch/data</span><br><span class="line">      - name: increase-vm-max-map</span><br><span class="line">        image: busybox</span><br><span class="line">        command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;]</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">      - name: increase-fd-ulimit</span><br><span class="line">        image: busybox</span><br><span class="line">        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;]</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: data</span><br><span class="line">      labels:</span><br><span class="line">        app: elasticsearch</span><br><span class="line">    spec:</span><br><span class="line">      accessModes: [ &quot;ReadWriteOnce&quot; ]</span><br><span class="line">      storageClassName: es-data-db</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 20Gi</span><br><span class="line">EOF </span><br></pre></td></tr></table></figure>

<p>2.4 部署es-storageclass </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;  elasticsearch-storageclass.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: es-data-db</span><br><span class="line">provisioner: fuseim.pri/ifs </span><br><span class="line">EOF</span><br><span class="line"># 该值需要和 provisioner 配置的保持一致</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 部署es-storageclass </span><br><span class="line">kubectl create -f elasticsearch-storageclass.yaml</span><br><span class="line">storageclass.storage.k8s.io &quot;es-data-db&quot; created</span><br><span class="line"></span><br><span class="line"># 部署es-statefulset</span><br><span class="line">kubectl create -f elasticsearch-statefulset.yaml</span><br><span class="line">statefulset.apps/es-cluster created</span><br><span class="line"></span><br><span class="line"># 查看 </span><br><span class="line">kubectl get sts -n logging</span><br><span class="line"></span><br><span class="line">kubectl get pods -n logging</span><br></pre></td></tr></table></figure>

<p>Pods 部署完成后，我们可以通过请求一个 REST API 来检查 Elasticsearch 集群是否正常运行。使用下面的命令将本地端口9200转发到 Elasticsearch 节点（如es-cluster-0）对应的端口：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl port-forward es-cluster-0 9200:9200 --namespace=logging</span><br><span class="line">Forwarding from 127.0.0.1:9200 -&gt; 9200</span><br><span class="line">Forwarding from [::1]:9200 -&gt; 9200</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://localhost:9200/_cluster/state?pretty</span><br></pre></td></tr></table></figure>

<h1 id="3-kibana部署"><a href="#3-kibana部署" class="headerlink" title="3 kibana部署"></a>3 kibana部署</h1><p>Elasticsearch 集群启动成功了，接下来我们可以来部署 Kibana 服务，新建一个名为 kibana.yaml 的文件，对应的文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; kibana.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    app: kibana</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 5601</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: kibana</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kibana</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    app: kibana</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: kibana</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: kibana</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: kibana</span><br><span class="line">        image: docker.elastic.co/kibana/kibana-oss:6.4.3</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 1000m</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">        env:</span><br><span class="line">          - name: ELASTICSEARCH_URL</span><br><span class="line">            value: http://elasticsearch:9200</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 5601</span><br><span class="line">EOF </span><br></pre></td></tr></table></figure>

<p>上面我们定义了两个资源对象，一个 Service 和 Deployment，为了测试方便，我们将 Service 设置为了 NodePort 类型，Kibana Pod 中配置都比较简单，唯一需要注意的是我们使用 ELASTICSEARCH_URL 这个环境变量来设置Elasticsearch 集群的端点和端口，直接使用 Kubernetes DNS 即可，此端点对应服务名称为 elasticsearch，由于是一个 headless service，所以该域将解析为3个 Elasticsearch Pod 的 IP 地址列表。</p>
<p>配置完成后，直接使用 kubectl 工具创建：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f kibana.yaml</span><br><span class="line"></span><br><span class="line">service/kibana created</span><br><span class="line">deployment.apps/kibana created</span><br></pre></td></tr></table></figure>

<p>创建完成后，可以查看 Kibana Pod 的运行状态：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods --namespace=logging</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          20h</span><br><span class="line">es-cluster-1              1/1       Running   0          20h</span><br><span class="line">es-cluster-2              1/1       Running   0          20h</span><br><span class="line">kibana-7558d4dc4d-5mqdz   1/1       Running   0          20h</span><br><span class="line">$ kubectl get svc --namespace=logging</span><br><span class="line">NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">elasticsearch   ClusterIP   None             &lt;none&gt;        9200/TCP,9300/TCP   20h</span><br><span class="line">kibana          NodePort    10.105.208.253   &lt;none&gt;        5601:31816/TCP      20h</span><br></pre></td></tr></table></figure>

<p>如果 Pod 已经是 Running 状态了，证明应用已经部署成功了，然后可以通过 NodePort 来访问 Kibana 这个服务，在浏览器中打开<code>http://&lt;任意节点IP&gt;:31816</code>即可，如果看到如下欢迎界面证明 Kibana 已经成功部署到了 Kubernetes集群之中。</p>
<h1 id="4-部署-Fluentd"><a href="#4-部署-Fluentd" class="headerlink" title="4 部署 Fluentd"></a>4 部署 Fluentd</h1><p>要收集 Kubernetes 集群的日志，直接用 DasemonSet 控制器来部署 Fluentd 应用，这样，它就可以从 Kubernetes 节点上采集日志，确保在集群中的每个节点上始终运行一个 Fluentd 容器。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; fluentd-configmap.yaml &lt;&lt; EOF </span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-config</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">data:</span><br><span class="line">  system.conf: |-</span><br><span class="line">    &lt;system&gt;</span><br><span class="line">      root_dir /tmp/fluentd-buffers/</span><br><span class="line">    &lt;/system&gt;</span><br><span class="line">  containers.input.conf: |-</span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      @id fluentd-containers.log</span><br><span class="line">      @type tail</span><br><span class="line">      path /var/log/containers/*.log</span><br><span class="line">      pos_file /var/log/es-containers.log.pos</span><br><span class="line">      time_format %Y-%m-%dT%H:%M:%S.%NZ</span><br><span class="line">      localtime</span><br><span class="line">      tag raw.kubernetes.*</span><br><span class="line">      format json</span><br><span class="line">      read_from_head true</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line">    # Detect exceptions in the log output and forward them as one log entry.</span><br><span class="line">    &lt;match raw.kubernetes.**&gt;</span><br><span class="line">      @id raw.kubernetes</span><br><span class="line">      @type detect_exceptions</span><br><span class="line">      remove_tag_prefix raw</span><br><span class="line">      message log</span><br><span class="line">      stream stream</span><br><span class="line">      multiline_flush_interval 5</span><br><span class="line">      max_bytes 500000</span><br><span class="line">      max_lines 1000</span><br><span class="line">    &lt;/match&gt;</span><br><span class="line">  system.input.conf: |-</span><br><span class="line">    # Logs from systemd-journal for interesting services.</span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      @id journald-docker</span><br><span class="line">      @type systemd</span><br><span class="line">      filters [&#123; &quot;_SYSTEMD_UNIT&quot;: &quot;docker.service&quot; &#125;]</span><br><span class="line">      &lt;storage&gt;</span><br><span class="line">        @type local</span><br><span class="line">        persistent true</span><br><span class="line">      &lt;/storage&gt;</span><br><span class="line">      read_from_head true</span><br><span class="line">      tag docker</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      @id journald-kubelet</span><br><span class="line">      @type systemd</span><br><span class="line">      filters [&#123; &quot;_SYSTEMD_UNIT&quot;: &quot;kubelet.service&quot; &#125;]</span><br><span class="line">      &lt;storage&gt;</span><br><span class="line">        @type local</span><br><span class="line">        persistent true</span><br><span class="line">      &lt;/storage&gt;</span><br><span class="line">      read_from_head true</span><br><span class="line">      tag kubelet</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line">  forward.input.conf: |-</span><br><span class="line">    # Takes the messages sent over TCP</span><br><span class="line">    &lt;source&gt;</span><br><span class="line">      @type forward</span><br><span class="line">    &lt;/source&gt;</span><br><span class="line">  output.conf: |-</span><br><span class="line">    # Enriches records with Kubernetes metadata</span><br><span class="line">    &lt;filter kubernetes.**&gt;</span><br><span class="line">      @type kubernetes_metadata</span><br><span class="line">    &lt;/filter&gt;</span><br><span class="line">    &lt;match **&gt;</span><br><span class="line">      @id elasticsearch</span><br><span class="line">      @type elasticsearch</span><br><span class="line">      @log_level info</span><br><span class="line">      include_tag_key true</span><br><span class="line">      host elasticsearch</span><br><span class="line">      port 9200</span><br><span class="line">      logstash_format true</span><br><span class="line">      request_timeout    30s</span><br><span class="line">      &lt;buffer&gt;</span><br><span class="line">        @type file</span><br><span class="line">        path /var/log/fluentd-buffers/kubernetes.system.buffer</span><br><span class="line">        flush_mode interval</span><br><span class="line">        retry_type exponential_backoff</span><br><span class="line">        flush_thread_count 2</span><br><span class="line">        flush_interval 5s</span><br><span class="line">        retry_forever</span><br><span class="line">        retry_max_interval 30</span><br><span class="line">        chunk_limit_size 2M</span><br><span class="line">        queue_limit_length 8</span><br><span class="line">        overflow_action block</span><br><span class="line">      &lt;/buffer&gt;</span><br><span class="line">    &lt;/match&gt;</span><br><span class="line">EOF </span><br></pre></td></tr></table></figure>

<p>上面配置文件中我们配置了 docker 容器日志目录以及 docker、kubelet 应用的日志的收集，收集到数据经过处理后发送到 elasticsearch:9200 服务。</p>
<p>然后新建一个 fluentd-daemonset.yaml 的文件，文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - &quot;namespaces&quot;</span><br><span class="line">  - &quot;pods&quot;</span><br><span class="line">  verbs:</span><br><span class="line">  - &quot;get&quot;</span><br><span class="line">  - &quot;watch&quot;</span><br><span class="line">  - &quot;list&quot;</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  namespace: logging</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd-es</span><br><span class="line">  namespace: logging</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: fluentd-es</span><br><span class="line">    version: v2.0.4</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: fluentd-es</span><br><span class="line">      version: v2.0.4</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: fluentd-es</span><br><span class="line">        kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">        version: v2.0.4</span><br><span class="line">      # This annotation ensures that fluentd does not get evicted if the node</span><br><span class="line">      # supports critical pod annotation based priority scheme.</span><br><span class="line">      # Note that this does not guarantee admission on the nodes (#40573).</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: &#x27;&#x27;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      serviceAccountName: fluentd-es</span><br><span class="line">      containers:</span><br><span class="line">      - name: fluentd-es</span><br><span class="line">        image: cnych/fluentd-elasticsearch:v2.0.4</span><br><span class="line">        env:</span><br><span class="line">        - name: FLUENTD_ARGS</span><br><span class="line">          value: --no-supervisor -q</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 500Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: varlog</span><br><span class="line">          mountPath: /var/log</span><br><span class="line">        - name: varlibdockercontainers</span><br><span class="line">          mountPath: /data/docker/containers</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/fluent/config.d</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/fluentd-ds-ready: &quot;true&quot;</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: node-role.kubernetes.io/master</span><br><span class="line">        operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: varlog</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /var/log</span><br><span class="line">      - name: varlibdockercontainers</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/docker/containers</span><br><span class="line">      - name: config-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: fluentd-config</span><br></pre></td></tr></table></figure>

<p>我们将上面创建的 fluentd-config 这个 ConfigMap 对象通过 volumes 挂载到了 Fluentd 容器中.</p>
<p>创建完成后，查看对应的 Pods 列表，检查是否部署成功：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods -n logging</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">es-cluster-0              1/1       Running   0          1d</span><br><span class="line">es-cluster-1              1/1       Running   0          1d</span><br><span class="line">es-cluster-2              1/1       Running   0          1d</span><br><span class="line">fluentd-es-2z9jg          1/1       Running   1          35s</span><br><span class="line">fluentd-es-6dfdd          1/1       Running   0          35s</span><br><span class="line">fluentd-es-bfkg7          1/1       Running   0          35s</span><br><span class="line">kibana-7558d4dc4d-5mqdz   1/1       Running   0          1d</span><br></pre></td></tr></table></figure>

<p>Fluentd 启动成功后，我们可以前往 Kibana 的 Dashboard 页面中，点击左侧的<code>Discover</code>，可以看到如下配置页面：</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>kubepray 搭建集群</title>
    <url>/2021/11/16/2021-11-16-kubepray-%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h1 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1 环境准备"></a>1 环境准备</h1><p>1）所以的主机都需要关闭selinux，执行的命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setenforce 0``sed -i --follow-symlinks ``&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;` `/etc/sysconfig/selinux</span><br></pre></td></tr></table></figure>

<p>2）防火墙（可选）和网络设置，所有的主机都执行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld &amp; systemctl disable firewalld``modprobe br_netfilter``echo ``&#x27;1&#x27;` `&gt; /proc/sys/net/bridge/bridge-nf-call-iptables``sysctl -w net.ipv4.ip_forward=1</span><br></pre></td></tr></table></figure>

<p>3）#设置内核参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/security/limits.conf``* soft nofile 32768``* hard nofile 65535``* soft nproc 32768``* hadr nproc 65535</span><br></pre></td></tr></table></figure>

<p>4）设置k8s内核参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/sysctl.d/k8s.conf``net.bridge.bridge-nf-call-ip6tables = 1``net.bridge.bridge-nf-call-iptables = 1``net.ipv4.ip_nonlocal_bind = 1``net.ipv4.ip_forward = 1``vm.swappiness=0</span><br></pre></td></tr></table></figure>

<p>5）重新加载生效</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo sysctl --system``sudo sysctl -p</span><br></pre></td></tr></table></figure>

<p>\6) 安装 python 及 epel (<strong>在Ansible主机上安装并配置好与各node的免秘钥登录)</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y epel-release python36 python36-pip git</span><br><span class="line">pip3 install --upgrade pip</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id rancher@192.168.2.51</span><br><span class="line">ssh-copy-id rancher@192.168.2.52</span><br><span class="line">ssh-copy-id rancher@192.168.2.53</span><br></pre></td></tr></table></figure>



<h1 id="2-部署k8s集群"><a href="#2-部署k8s集群" class="headerlink" title="2 部署k8s集群"></a>2 部署k8s集群</h1><p>1）#克隆项目</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https:``//github.com/kubernetes-sigs/kubespray/archive/v2.12.4.tar.gz </span><br><span class="line">tar -zxf v2.12.4.tar.gz </span><br></pre></td></tr></table></figure>

<p>2）# Install dependencies from <code>requirements.txt</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo /usr/bin/pip3.6 install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>3）# Copy <code>inventory/sample</code> as <code>inventory/mycluster</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp -rfp inventory/sample inventory/mycluster</span><br></pre></td></tr></table></figure>

<p>4）# Update Ansible inventory file with inventory builder</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">declare -a IPS=(10.10.1.3 10.10.1.4 10.10.1.5)`CONFIG_FILE=inventory/mycluster/hosts.yaml /usr/bin/python3.6 contrib/inventory_builder/inventory.py $&#123;IPS[@]&#125;</span><br></pre></td></tr></table></figure>

<p>5）# Review and change parameters under <code>inventory/mycluster/group_vars</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat inventory/mycluster/group_vars/all/all.yml` `cat inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.yml</span><br></pre></td></tr></table></figure>

<p>6）# Deploy Kubespray with Ansible Playbook - run the playbook as root</p>
<p># The option <code>--become</code> is required, as for example writing SSL keys in /etc/,</p>
<p># installing packages and interacting with various systemd daemons.</p>
<p># Without –become the playbook will fail to run!</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>shell中$*的用法</title>
    <url>/2021/11/26/2021-11-16-shell%E4%B8%AD$%E7%9A%84%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<h3 id="一、Shell脚本中-0、-、-、-、-、-、-等用法"><a href="#一、Shell脚本中-0、-、-、-、-、-、-等用法" class="headerlink" title="一、Shell脚本中$0、$?、$!、$$、$*、$#、$@等用法"></a>一、Shell脚本中$0、$?、$!、$$、$*、$#、$@等用法</h3><ul>
<li><p>$$    Shell本身的PID（ProcessID，即脚本运行的当前进程ID号）</p>
</li>
<li><p>$!     Shell最后运行的后台Process的PID(后台运行的最后一个进程的[进程ID]</p>
</li>
<li><p>$?  最后运行的命令的结束代码（返回值）即执行上一个指令的返回值 (显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误)</p>
</li>
<li><p>$$  显示shell使用的当前选项，与set命令功能相同</p>
</li>
<li><p>$* 所有参数列表。如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数，此选项参数可超过9个。</p>
</li>
<li><p>$@ 所有参数列表。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。</p>
</li>
<li><p>$* 跟$@类似，但是可以当作数组用</p>
</li>
<li><p>$# 添加到Shell的参数个数</p>
</li>
<li><p>$0 Shell本身的文件名</p>
</li>
<li><p>$1～$n 添加到Shell的各参数值。$1是第1参数、$2是第2参数…</p>
</li>
</ul>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>使用kubeadm快速部署一个k8s集群</title>
    <url>/2021/12/16/2021-11-16-%E4%BD%BF%E7%94%A8kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAk8s%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p>
<p>这个工具能通过两条指令完成一个kubernetes集群的部署：</p>
<h2 id="1-安装要求"><a href="#1-安装要求" class="headerlink" title="1. 安装要求"></a>1. 安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p>
<ul>
<li>一台或多台机器，操作系统 CentOS7.x-86_x64</li>
<li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</li>
<li>可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点</li>
<li>禁止swap分区</li>
</ul>
<h2 id="2-准备环境"><a href="#2-准备环境" class="headerlink" title="2. 准备环境"></a>2. 准备环境</h2><table>
<thead>
<tr>
<th>角色</th>
<th>IP</th>
</tr>
</thead>
<tbody><tr>
<td>master</td>
<td>192.168.1.11</td>
</tr>
<tr>
<td>node1</td>
<td>192.168.1.12</td>
</tr>
<tr>
<td>node2</td>
<td>192.168.1.13</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 关闭防火墙</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line"></span><br><span class="line"># 关闭selinux</span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config  # 永久</span><br><span class="line">setenforce 0  # 临时</span><br><span class="line"></span><br><span class="line"># 关闭swap</span><br><span class="line">swapoff -a  # 临时</span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab    # 永久</span><br><span class="line"></span><br><span class="line"># 根据规划设置主机名</span><br><span class="line">hostnamectl set-hostname &lt;hostname&gt;</span><br><span class="line"></span><br><span class="line"># 在master添加hosts</span><br><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.2.13 k8smaster</span><br><span class="line">192.168.2.10 k8snode1</span><br><span class="line">192.168.2.11 k8snode2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 将桥接的IPv4流量传递到iptables的链</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"># 生效</span><br><span class="line">sysctl --system  </span><br><span class="line"></span><br><span class="line"># 时间同步</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure>

<h2 id="3-所有节点安装Docker-kubeadm-kubelet"><a href="#3-所有节点安装Docker-kubeadm-kubelet" class="headerlink" title="3. 所有节点安装Docker/kubeadm/kubelet"></a>3. 所有节点安装Docker/kubeadm/kubelet</h2><p>Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。</p>
<h3 id="3-1-安装Docker"><a href="#3-1-安装Docker" class="headerlink" title="3.1 安装Docker"></a>3.1 安装Docker</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#安装wget</span><br><span class="line">yum install wget </span><br><span class="line">#下载docker包</span><br><span class="line">wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br><span class="line"># 安装docker</span><br><span class="line">yum -y install docker-ce-18.06.1.ce-3.el7</span><br><span class="line"># 设置docker自启动</span><br><span class="line">ystemctl enable docker </span><br><span class="line"># 启动docker</span><br><span class="line">systemctl start docker</span><br><span class="line"># 检查docker是否安装成功</span><br><span class="line">docker --version</span><br><span class="line">Docker version 18.06.1-ce, build e68fc7a</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置docker阿里云镜像 </span><br><span class="line">$ cat &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"># 重启docker </span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="3-2-添加阿里云yum软件源"><a href="#3-2-添加阿里云yum软件源" class="headerlink" title="3.2 添加阿里云yum软件源"></a>3.2 添加阿里云yum软件源</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="3-3-安装kubeadm，kubelet和kubectl"><a href="#3-3-安装kubeadm，kubelet和kubectl" class="headerlink" title="3.3 安装kubeadm，kubelet和kubectl"></a>3.3 安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure>

<h2 id="4-部署Kubernetes-Master"><a href="#4-部署Kubernetes-Master" class="headerlink" title="4. 部署Kubernetes Master"></a>4. 部署Kubernetes Master</h2><p>在192.168.2.13（Master）执行。由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubeadm init --apiserver-advertise-address=192.168.2.13 </span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers </span><br><span class="line">  --kubernetes-version v1.18.0 </span><br><span class="line">  --service-cidr=10.96.0.0/12 </span><br><span class="line">  --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure>

<p>结果如下即成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.2.13:6443 --token tb681z.zr2l20onx60p0rlc \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:eb0df9f6cdf57a160187b61f45b7465f85a3f9cdfb84077c8754fc0ad8c8d8b6 </span><br></pre></td></tr></table></figure>

<p>使用kubectl工具：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>

<h2 id="5-加入Kubernetes-Node"><a href="#5-加入Kubernetes-Node" class="headerlink" title="5. 加入Kubernetes Node"></a>5. 加入Kubernetes Node</h2><p>在192.168.1.10/11（Node）执行。</p>
<p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.2.13:6443 --token tb681z.zr2l20onx60p0rlc \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:eb0df9f6cdf57a160187b61f45b7465f85a3f9cdfb84077c8754fc0ad8c8d8b6</span><br></pre></td></tr></table></figure>

<p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure>

<h2 id="6-部署CNI网络插件"><a href="#6-部署CNI网络插件" class="headerlink" title="6. 部署CNI网络插件"></a>6. 部署CNI网络插件</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 镜像地址可能无法访问，先添加/etc/hosts</span><br><span class="line">199.232.68.133 raw.githubusercontent.com</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 安装kube-flannel</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line">kubectl get pods -n kube-system</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-flannel-ds-amd64-2pc95   1/1     Running   0          72s</span><br></pre></td></tr></table></figure>

<h2 id="7-测试kubernetes集群"><a href="#7-测试kubernetes集群" class="headerlink" title="7. 测试kubernetes集群"></a>7. 测试kubernetes集群</h2><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubectl create deployment nginx --image=nginx</span><br><span class="line">$ kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">$ kubectl get pod,svc</span><br></pre></td></tr></table></figure>

<p>访问地址：<a href="http://NodeIP:Port">http://NodeIP:Port</a>  </p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>xshell字符间隔修改</title>
    <url>/2021/11/19/2021-11-19-xshell%E5%AD%97%E7%AC%A6%E9%97%B4%E9%9A%94%E4%BF%AE%E6%94%B9/</url>
    <content><![CDATA[<p>好像点到了一个设置，shell的字符间隔变得很大，看起来巨难受，</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/shell.png"><br>在<code>默认会话设置</code> 中改了外观，没什么用，查了一下，可以在default配置文件中改。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/shell%E9%85%8D%E7%BD%AE.png"></p>
<p>将LineSpace，CharSpace改为1就改回来了。 </p>
<p>原来shell会话很多设置都可以在default中配置。</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>root权限时修改文档却反馈cannot open file for writing</title>
    <url>/2021/11/23/2021-11-23-root%E6%9D%83%E9%99%90%E6%97%B6%E4%BF%AE%E6%94%B9%E6%96%87%E6%A1%A3%E5%8D%B4%E5%8F%8D%E9%A6%88cannot-open-file-for-writing/</url>
    <content><![CDATA[<p>vim打开文件编辑界面后,输入文件内容,输完点击esc,然后:wq!,居然报错了,主要的错误提示是:</p>
<p><code>Can&#39;t open file for writing</code></p>
<p>迅速寻找解决办法,网上说两种可能:</p>
<p>1.当前用户的权限不足</p>
<p>2.此文件可能正被其他程序或用户使用.</p>
<p>根据我的情况分析,该文件都还不存在呢,第二种情况肯定不可能, 那就是第一种情况咯,可是仔细一想也不会,我当前操作的用户身份是root,权限不足,问题出在哪里呢?</p>
<p>最后我查到还有第三种的可能，就是我直接在多层目录下写文件，这个目录不存在，我测试一下，果然是这个问题，直接输入:cd /XXXX/XXXXX/</p>
<p>系统提示:没有那个文件或目录。、</p>
<p>知道问题出在哪，解决就简单了，直接创建目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p /XXXX/XXXXX/</span><br></pre></td></tr></table></figure>

<p>然后在使用vim写入，发现保存成功了。 </p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>使用cat EOF时内容含有$需要处理</title>
    <url>/2021/11/22/2021-11-23-%E4%BD%BF%E7%94%A8cat-EOF%E6%97%B6%E5%86%85%E5%AE%B9%E5%90%AB%E6%9C%89$%E9%9C%80%E8%A6%81%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>在使用cat EOF内容中若出现$变量通常会直接被执行，则与想要输入的内容不一致。若想保持$变量不变需要使用 \ 符进行注释 。比如下面：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/nginx.repo &lt;&lt; EOF</span><br><span class="line">vim /etc/yum.repos.d/nginx.repo </span><br><span class="line">[nginx-stable]</span><br><span class="line">name=nginx stable repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nginx.org/keys/nginx_signing.key</span><br><span class="line">module_hotfixes=true</span><br><span class="line">[nginx-mainline]</span><br><span class="line">name=nginx mainline repo</span><br><span class="line">baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=https://nginx.org/keys/nginx_signing.key</span><br><span class="line">module_hotfixes=true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>执行时发现，输入的内容不正确， 因为输入的内容中含有$, 会当成命令执行， 要使用转义符\换成普通字符$ .</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/xshell5.png"><br> 在linux shell脚本中我们经常见到类似于cat &lt;&lt; EOF的语句，问题是EOF好像是文件的结束符，用在这里起到什么作用？<br>首先必要说明的是EOF在这里没有特殊的含义，你可以使用FOE或OOO等（当然也不限制在三个字符或大写字符)<br>下面是几种常见的使用方式及其作用：<br>1、cat&lt;&lt;EOF，以EOF输入字符为标准输入结束：<br>2、cat&gt;filename，创建文件，并把标准输入输出到filename文件中，以ctrl+d作为输入结束,输入时是没有’&gt;’的。<br>3、cat&gt;filename&lt;&lt;EOF，以EOF作为输入结束，和ctrl+d的作用一样</p>
<blockquote>
<p>注意，结束后必须和前面一样是EOF， 前面有空格都不可以。有时无法结束，检查有没有空格.<br>意，结束后必须和前面一样是EOF， 前面有空格都不可以。有时无法结束，检查有没有空格.</p>
</blockquote>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>脚本一键部署k8s集群</title>
    <url>/2021/11/29/2021-11-29-%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4-%E9%80%9A%E8%BF%87RKE/</url>
    <content><![CDATA[<p>使用rke部署集群时，虽然已经很方便了，但是如果节点个数较多，每个节点要手动配置，防火墙，selinux, iptables等等。还是挺麻烦的， 这些配置每个节点都一样，完全可以通过脚本批量配置。 </p>
<p>过程参考<a href="%5BRKE%E9%83%A8%E7%BD%B2K8S_%E4%BA%8C%E9%83%8E%E9%93%B6%E7%9A%84%E5%8D%9A%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2%5D(https://blog.csdn.net/weixin_43705953/article/details/120879544)">RKE部署K8S</a> </p>
<p><strong>脚本主要分为四个部分</strong>： </p>
<ol>
<li> 批量配置服务器环境</li>
<li> 配置免密登录 </li>
<li> 自动生成cluster.yml文件</li>
<li> 下载安装RKE,部署集群。 </li>
</ol>
<p>主要使用的工具就是expecet, 关于expcet的使用参考<a href="https://www.cnblogs.com/iloveyoucc/archive/2012/05/11/2496433.html">expect用法 </a></p>
<p>在配置固定时， 我们只需要了解，节点的ip, 账号及密码。 先将这些信息写入ip.txt</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-16-15-centos ~]# cat ip.txt </span><br><span class="line">10.206.16.8 root 123456</span><br><span class="line">10.206.16.4 root 123456</span><br><span class="line">10.206.16.7 root 123456</span><br><span class="line">10.206.16.9 root 123456</span><br><span class="line">10.206.16.2 root 123456</span><br></pre></td></tr></table></figure>

<p><strong>脚本如下</strong>： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">help ()</span><br><span class="line">&#123;</span><br><span class="line">    echo  &#x27; ================================================================ &#x27;</span><br><span class="line">    echo  &#x27; 脚本没有参数，请在ip.txt中写入ip地址，用户及其密码&#x27;</span><br><span class="line">    echo  &#x27; 如果rke或kubectl下载失败请手动下载或者翻墙或者国外节点&#x27;</span><br><span class="line">    echo  &#x27; ================================================================&#x27;</span><br><span class="line">&#125;</span><br><span class="line">case &quot;$1&quot; in</span><br><span class="line">    -h|--help) help; exit;;</span><br><span class="line">esac</span><br><span class="line">if [[ $1 == &#x27;&#x27; ]];then</span><br><span class="line">    help;</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line">rke_user=&quot;rke&quot;</span><br><span class="line">rpm -qa | grep &quot;expect&quot; </span><br><span class="line">if [ $? -eq 0 ]</span><br><span class="line">then</span><br><span class="line">  echo &quot;expect installed&quot;</span><br><span class="line">else</span><br><span class="line">  yum install -y expect</span><br><span class="line">fi</span><br><span class="line">cat ip.txt | while read line  #使用while命令循环登录主机进行配置</span><br><span class="line">do</span><br><span class="line">  ip=`echo $&#123;line&#125;|awk  &#x27;&#123;print $1&#125;&#x27;`  #ip地址</span><br><span class="line">  user=`echo $&#123;line&#125;|awk  &#x27;&#123;print $2&#125;&#x27;`</span><br><span class="line">  passwd=`echo $&#123;line&#125;|awk  &#x27;&#123;print $3&#125;&#x27;`</span><br><span class="line">  set timeout 30</span><br><span class="line">  expect &lt;&lt; EOF </span><br><span class="line">    spawn ssh $user@$ip</span><br><span class="line">    expect &#123;</span><br><span class="line">        &quot;yes/no&quot; &#123; send &quot;yes\r&quot;;exp_continue &#125;</span><br><span class="line">        &quot;password&quot; &#123; send &quot;$passwd\r&quot;;exp_continue &#125;</span><br><span class="line">        &quot;already installed&quot; &#123; send &quot;\r&quot;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    # expect &quot;yes/no&quot;; send &quot;yes\r&quot;</span><br><span class="line">    # expect &quot;password&quot;; send &quot;$passwd\r&quot;</span><br><span class="line">    # 基本配置 </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;hostnamectl set-hostname node$&#123;ip: 6&#125;\r&quot; </span><br><span class="line">     # 配置hostname，缺一个计数器  </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;systemctl stop firewalld\r&quot; </span><br><span class="line">     # 关闭防火墙 </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;systemctl disable firewalld\r&quot;  </span><br><span class="line">     # 关闭防火墙自启动</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \`date +\&quot;%Y-%m-%d %H:%M:%S\&quot;\` firewalld diabled &gt; /root/.k8s.log\r&quot;   </span><br><span class="line">     # 日志</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;swapoff -a\r&quot; </span><br><span class="line">      # 关闭swap  </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab\r&quot;  </span><br><span class="line">     # 永久关闭swap   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \`date +\&quot;%Y-%m-%d %H:%M:%S\&quot;\` swap diabled &gt;&gt; /root/.k8s.log\r&quot;   </span><br><span class="line">     # 日志</span><br><span class="line">    </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;setenforce 0\r&quot; </span><br><span class="line">     #  关闭selinux</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config\r&quot; </span><br><span class="line">      # 永久关闭selinux  </span><br><span class="line">    # expect &quot;*root&quot; ; send  &quot;yum install ntpdate -y\r &quot;  # 安装ntpdate  </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;ntpdate time.windows.com\r&quot; </span><br><span class="line">     # 时间同步   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;cat &gt;&gt; /etc/sysctl.conf&lt;&lt;EOF</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1=4096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2=6144</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3=8192</span><br><span class="line">EOF\r&quot;</span><br><span class="line">      # kernel性能调优</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;cp /etc/sysctl.conf /etc/sysctl.conf_copy\r&quot;</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;sort -n /etc/sysctl.conf_copy | uniq &gt;/etc/sysctl.conf\r&quot;</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;rm -f /etc/sysctl.conf_copy\r&quot;</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;sysctl -p\r&quot; </span><br><span class="line">     # 加载配置文件   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;yum -y install lrzsz\r&quot;</span><br><span class="line">    # expect &quot;*root&quot; ; send  &quot;yum -y install lrzsz vim gcc glibc openssl openssl-devel net-tools wget curl\r&quot;</span><br><span class="line">      # 安装基础软件包</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \&quot;test soft\&quot; &gt;&gt; test.txt\r&quot;   </span><br><span class="line">    # 安装docker </span><br><span class="line">    </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;install -y yum-utils device-mapper-persistent-data lvm2\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;systemctl start docker\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  \&quot;oom-score-adjust\&quot;: -1000,</span><br><span class="line">  \&quot;registry-mirrors\&quot;: \[\&quot;https://7bezldxe.mirror.aliyuncs.com/\&quot;,\&quot;https://kw88y6eh.mirror.aliyuncs.com\&quot;\],</span><br><span class="line">  \&quot;storage-driver\&quot;: \&quot;overlay2\&quot;,</span><br><span class="line">  \&quot;storage-opts\&quot;: \[\&quot;overlay2.override_kernel_check=true\&quot;\]</span><br><span class="line">&#125;</span><br><span class="line">EOF\r&quot;</span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \`date +\&quot;%Y-%m-%d %H:%M:%S\&quot;\` docker installed &gt;&gt; /root/.k8s.log\r&quot;   </span><br><span class="line">    # 日志</span><br><span class="line">    # 创建rke用户  </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;useradd $rke_user -G docker\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \&quot;123456\&quot; | passwd --stdin $rke_user\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;echo \`date +\&quot;%Y-%m-%d %H:%M:%S\&quot;\`  user $rke_user created &gt;&gt; /root/.k8s.log\r&quot;   </span><br><span class="line">    expect &quot;*root&quot; ; send  &quot;exit\r&quot;   </span><br><span class="line">    expect eof</span><br><span class="line">EOF</span><br><span class="line">done</span><br><span class="line"># 判断id_rsa密钥文件是否存在， 没有则创建</span><br><span class="line">rke_user=&quot;rke&quot;</span><br><span class="line"></span><br><span class="line">if [ ! -e /home/$rke_user/.ssh ];then </span><br><span class="line">  runuser -l $rke_user -c &quot;mkdir /home/$rke_user/.ssh&quot;</span><br><span class="line">fi </span><br><span class="line">if [ ! -f /home/$rke_user/.ssh/id_rsa ];then</span><br><span class="line">  runuser -l $rke_user -c &quot;ssh-keygen -t rsa -P \&quot;\&quot; -f /home/$rke_user/.ssh/id_rsa&quot;</span><br><span class="line">else</span><br><span class="line"> echo &quot;id_rsa has created ...&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#密钥分发到各个节点</span><br><span class="line">while read line</span><br><span class="line">  do</span><br><span class="line">    ip=`echo $line | cut -d &quot; &quot; -f 1`</span><br><span class="line">    expect &lt;&lt;EOF</span><br><span class="line">      set timeout 30</span><br><span class="line">      spawn su rke</span><br><span class="line">        expect &quot;rke&quot;; send &quot;ssh-copy-id -i /home/$rke_user/.ssh/id_rsa.pub $rke_user@$ip\r&quot;</span><br><span class="line">        expect &#123;</span><br><span class="line">          &quot;yes/no&quot; &#123; send &quot;yes\r&quot;;exp_continue &#125;</span><br><span class="line">          &quot;password&quot; &#123; send &quot;123456\r&quot;;exp_continue &#125;</span><br><span class="line">          &quot;WARNING&quot; &#123;send &quot;exit\r&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">EOF</span><br><span class="line">  done &lt;  ip.txt</span><br><span class="line"></span><br><span class="line"># 创建cluster.yml</span><br><span class="line">path_cluster_yml=&quot;/home/$rke_user/cluster.yml&quot;</span><br><span class="line">if [ ! -e $path_cluster_yml ]</span><br><span class="line">then</span><br><span class="line">  cat &gt; $path_cluster_yml &lt;&lt; EOF</span><br><span class="line">nodes:</span><br><span class="line">EOF</span><br><span class="line">  while read line </span><br><span class="line">    do</span><br><span class="line">    ip=`echo $line | cut -d &quot; &quot; -f 1`</span><br><span class="line">    cat &gt;&gt; $path_cluster_yml &lt;&lt; EOF</span><br><span class="line">  - address: $ip</span><br><span class="line">    internal_address: $ip</span><br><span class="line">    user: $rke_user</span><br><span class="line">    role: [controlplane,worker,etcd]</span><br><span class="line">EOF</span><br><span class="line">  done &lt; ip.txt</span><br><span class="line"></span><br><span class="line">  cat &gt;&gt; $path_cluster_yml &lt;&lt; EOF</span><br><span class="line">services:</span><br><span class="line">  etcd:</span><br><span class="line">    snapshot: true</span><br><span class="line">    creation: 6h</span><br><span class="line">    retention: 24h</span><br><span class="line">EOF</span><br><span class="line">fi</span><br><span class="line"># 安装rke </span><br><span class="line">if [ -e /usr/bin/rke ]</span><br><span class="line">then</span><br><span class="line">  echo &quot;rke already installed&quot;</span><br><span class="line">else</span><br><span class="line">  wget https://github.com/rancher/rke/releases/download/v1.3.0/rke_linux-amd64</span><br><span class="line">  chmod +x rke_linux-amd64 </span><br><span class="line">  mv rke_linux-amd64 /usr/bin/rke </span><br><span class="line">fi</span><br><span class="line"># 安装kubectl </span><br><span class="line">if [ -e /usr/local/bin/kubectl ]</span><br><span class="line">then </span><br><span class="line">  echo &quot;kubectl already installed&quot;</span><br><span class="line">else </span><br><span class="line">  wget http://rancher-mirror.cnrancher.com/kubectl/v1.21.4/linux-amd64-v1.21.4-kubectl</span><br><span class="line">  mv linux-amd64-v1.21.4-kubectl /usr/local/bin/kubectl</span><br><span class="line">  chmod +x /usr/local/bin/kubectl</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 部署集群</span><br><span class="line">runuser -l $rke_user -c &quot;rke up --config /home/$rke_user/cluster.yml&quot;</span><br><span class="line">export KUBECONFIG=/home/$rke_user/kube_config_cluster.yml</span><br><span class="line">echo &quot;cluster nodes:&quot; </span><br><span class="line">kubectl get no </span><br></pre></td></tr></table></figure>

<p><strong>使用方法</strong>，登录其中一个节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod +x ./main.sh </span><br><span class="line"># ip.txt在同一个目录下</span><br><span class="line">./main.sh </span><br></pre></td></tr></table></figure>

<p><strong>然后等待</strong>， 结果： </p>
<p><img src="https://img-blog.csdnimg.cn/820d0db593d24029ab523e916e02a52f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LqM6YOO6ZO2,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/49ecdcd52ba84a46a05e34f04a813ad6.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong>脚本缺点</strong>：</p>
<p>上面的脚本只是简单实现了功能， 并没有深入去写，存在一些问题。 比如：</p>
<ol>
<li> 异常处理并没有怎么做。 如果更进一步改进，可以加ip.txt文件的检查，格式检查，docker等软件是否安装的检查，环境配置检查等。  </li>
<li>脚本安装rke的下载链接并不稳定，我没找到国内的rke安装包镜像， 可能下载的很慢。 没有下载成功需要手动下载安装rke。</li>
</ol>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>部署zabbix</title>
    <url>/2022/02/21/2021-12-03-%E9%83%A8%E7%BD%B2zabbix/</url>
    <content><![CDATA[<p>Zabbix是当前主流开源的企业级分布式监控系统。Zabbix特点是：安装部署较简单，且默认自带了多种监控告警模板。也具备较强的仪表盘展示功能；提供API接口，支持脚本调用；支持自定义编写插件以及监控模板。 </p>
<p>这里记一下zabbix部署方法。 主要是以下几步。 </p>
<ol>
<li> 环境配置</li>
<li> yum安装 </li>
<li>mariadb配置zabbix表结构数据 </li>
<li> 配置zabbix  </li>
<li> 登陆zabbix web </li>
</ol>
<h3 id="1-基础配置"><a href="#1-基础配置" class="headerlink" title="1 基础配置"></a>1 基础配置</h3><p>确保zabbix可用， 测试的时候最好关闭firewalld、selinux  </p>
<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2 安装"></a>2 安装</h3><p>yum安装也很方便，只是先要添加yum源。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm </span><br><span class="line">yum install epel-release </span><br></pre></td></tr></table></figure>

<blockquote>
<p>EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install zabbix-* </span><br></pre></td></tr></table></figure>

<h3 id="3-数据库中导入zabbix表结构数据"><a href="#3-数据库中导入zabbix表结构数据" class="headerlink" title="3 数据库中导入zabbix表结构数据"></a>3 数据库中导入zabbix表结构数据</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 安装zabbix  </span><br><span class="line">yum -y install mariadb-* </span><br><span class="line"># 开机自启动给</span><br><span class="line">systemctl enable mariadb</span><br><span class="line"># 启动mariadb </span><br><span class="line">systemctl start mariadb  </span><br></pre></td></tr></table></figure>

<p>mariadb启动之后， 进入数据库，mariadb和mysql用法一样 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -u root </span><br></pre></td></tr></table></figure>

<p>配置 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create database zabbix character set utf8 collate utf8_bin;</span><br><span class="line">grant all privileges on zabbix.* to &#x27;zabbix&#x27;@&#x27;localhost&#x27; identified by &#x27;zabbix@123&#x27;;</span><br><span class="line">flush privileges;</span><br><span class="line">quit; </span><br></pre></td></tr></table></figure>

<blockquote>
<p>sql需要冒号结尾</p>
</blockquote>
<p>导入数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcat /usr/share/doc/zabbix-server-mysql-*/create.sql.gz |mysql -uzabbix -p&#x27;zabbix@123&#x27; -b zabbix </span><br></pre></td></tr></table></figure>

<p>4 修改zabbix_server.conf配置 </p>
<p>先保存一份默认配置备用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp /etc/zabbix/zabbix_server.conf /etc/zabbix/zabbix_server.conf.source</span><br></pre></td></tr></table></figure>

<p>修改配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/zabbix/zabbix_server.conf &lt;&lt; EOF</span><br><span class="line">LogFile=/var/log/zabbix/zabbix_server.log</span><br><span class="line">LogFileSize=0</span><br><span class="line">DebugLevel=3</span><br><span class="line">PidFile=/var/run/zabbix/zabbix_server.pid</span><br><span class="line">SocketDir=/var/run/zabbix</span><br><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=zabbix@123</span><br><span class="line">StartPollers=16</span><br><span class="line">StartPollersUnreachable=4</span><br><span class="line">StartTrappers=10</span><br><span class="line">StartPingers=8</span><br><span class="line">SNMPTrapperFile=/var/log/snmptrap/snmptrap.log</span><br><span class="line">CacheSize=1024M</span><br><span class="line">StartDBSyncers=8</span><br><span class="line">HistoryCacheSize=1024M</span><br><span class="line">HistoryIndexCacheSize=256M</span><br><span class="line">TrendCacheSize=1024M</span><br><span class="line">Timeout=4</span><br><span class="line">AlertScriptsPath=/usr/lib/zabbix/alertscripts</span><br><span class="line">ExternalScripts=/usr/lib/zabbix/externalscripts</span><br><span class="line">LogSlowQueries=3000</span><br><span class="line">StatsAllowedIP=127.0.0.1 </span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># systemctl enable zabbix-server</span><br><span class="line"># systemctl start zabbix-server </span><br></pre></td></tr></table></figure>

<p>配置nginx </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/nginx/conf.d/zabbix.conf  </span><br><span class="line"># 修改端口 和 server_name ,取消注释</span><br><span class="line">listen          8080;</span><br><span class="line">server_name     monitor.com; </span><br><span class="line"></span><br><span class="line"># 修改时区</span><br><span class="line">echo &quot;php_value[date.timezone] = Asia/Shanghai&quot; &gt;&gt;  /etc/php-fpm.d/zabbix.conf </span><br></pre></td></tr></table></figure>

<p>启动 php-fpm和nginx </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl enable php-fpm</span><br><span class="line">systemctl restart php-fpm</span><br><span class="line"></span><br><span class="line">systemctl enable nginx</span><br><span class="line">systemctl start nginx </span><br></pre></td></tr></table></figure>

<h3 id="访问登陆"><a href="#访问登陆" class="headerlink" title="访问登陆"></a>访问登陆</h3><p>最后访问 <a href="http://ip:8080/">http://ip:8080</a> </p>
<p>按照提示登陆即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/zabbix.png"></p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>grafana部署与离线插件下载</title>
    <url>/2021/12/06/2021-12-06-grafana%E9%83%A8%E7%BD%B2%E4%B8%8E%E7%A6%BB%E7%BA%BF%E6%8F%92%E4%BB%B6%E4%B8%8B%E8%BD%BD/</url>
    <content><![CDATA[<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>grafana使用yum下载非常方便</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># wget https://dl.grafana.com/oss/release/grafana-6.7.1-1.x86_64.rpm</span><br><span class="line"># yum -y install grafana-6.7.1-1.x86_64.rpm</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">启动grafana并设置开机自启动</span><br><span class="line"># systemctl restart grafana-server.service</span><br><span class="line"># systemctl enable grafana-server.service </span><br></pre></td></tr></table></figure>

<p>默认3000端口，<a href="http://ip:3000即可访问，默认用户密码为admin。">http://ip:3000即可访问，默认用户密码为admin。</a> </p>
<h3 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h3><p>grafana插件下载都是外站，有时网络不稳定下载不了，采用离线下载的方式也不麻烦。</p>
<p>以grafana-cli plugins install alexanderzobnin-zabbix-app 为例。</p>
<p>使用命令grafana-cli plugins install </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grafana-cli plugins install alexanderzobnin-zabbix-app </span><br></pre></td></tr></table></figure>

<p>若超时，就手动下载吧。 </p>
<p>先去官网下载安装包，<a href="https://grafana.com/grafana/plugins?orderBy=weight&amp;direction=asc">https://grafana.com/grafana/plugins?orderBy=weight&amp;direction=asc</a> </p>
<p>搜索需要的插件，选好与grafana版本匹配的版本。 </p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/grafana.png"></p>
<p>可点击download the .zip file下载，也可wget直接下载。</p>
<p>获取下载地址，<a href="https://grafana.com/api/plugins/alexanderzobnin-zabbix-app/versions/3.12.0/download">https://grafana.com/api/plugins/alexanderzobnin-zabbix-app/versions/3.12.0/download</a> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># wget获取</span><br><span class="line">wget https://grafana.com/api/plugins/alexanderzobnin-zabbix-app/versions/3.12.0/download  -O zabbix.zip </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压 </span><br><span class="line">unzip zabbix.zip</span><br><span class="line"># 移动到plugins 文件夹中 </span><br><span class="line">mv alexanderzobnin-grafana-zabbix-d0e8319/  /var/lib/grafana/plugins/</span><br><span class="line"># 重启grafana-server使生效。 </span><br><span class="line"> systemctl restart grafana-server </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>node.js linux安装</title>
    <url>/2022/02/21/2021-12-06-node.js-linux%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h4 id="node-js-linux安装"><a href="#node-js-linux安装" class="headerlink" title="node.js linux安装"></a>node.js linux安装</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建文件夹</span><br><span class="line">mkdir nodejs</span><br><span class="line">cd nodejs/</span><br><span class="line"># 下载官方编译好的node.js下载</span><br><span class="line">wget https://nodejs.org/dist/v12.14.0/node-v12.14.0-linux-x64.tar.xz</span><br><span class="line"># 解压</span><br><span class="line">xz -d node-v12.14.0-linux-x64.tar.xz </span><br><span class="line">tar -xf node-v12.14.0-linux-x64.tar </span><br><span class="line"># 移动文件夹</span><br><span class="line">mv node-v12.14.0-linux-x64/* /usr/local/nodejs/</span><br><span class="line"># 软链接</span><br><span class="line">ln -s /usr/local/nodejs/bin/node /usr/local/bin</span><br><span class="line">ln -s /usr/local/nodejs/bin/npm /usr/local/bin</span><br><span class="line"># 测试</span><br><span class="line">[root@monitor01 nodejs]# node -v </span><br><span class="line">v12.14.0</span><br></pre></td></tr></table></figure>

<p>记录备查</p>
]]></content>
  </entry>
  <entry>
    <title>通过kubeconfig文件管理集群</title>
    <url>/2021/12/06/2021-12-06-%E9%80%9A%E8%BF%87kubeconfig%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>kubeconfig是与集群交互的身份认证，有集群的kubeconfig文件即可与其交互。 </p>
<h3 id="安装kubectl"><a href="#安装kubectl" class="headerlink" title="安装kubectl"></a>安装kubectl</h3><p>交互的工具就是kubectl</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://rancher-mirror.cnrancher.com/kubectl/v1.21.4/linux-amd64-v1.21.4-kubectl</span><br><span class="line">mv linux-amd64-v1.21.4-kubectl /usr/local/bin/kubectl</span><br><span class="line">chmod +x /usr/local/bin/kubectl</span><br></pre></td></tr></table></figure>

<h3 id="下载或者写入kubeconfig文件"><a href="#下载或者写入kubeconfig文件" class="headerlink" title="下载或者写入kubeconfig文件"></a>下载或者写入kubeconfig文件</h3><p>这里我是从腾讯云TKE起的集群，直接下载集群的kubeconfig文件。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@monitor01 ~]# ll</span><br><span class="line">-rw-r--r-- 1 root root    4675 Dec  6 17:09 mytest_kubeconfig</span><br></pre></td></tr></table></figure>

<h3 id="配置-kube-config"><a href="#配置-kube-config" class="headerlink" title="配置~/.kube/config"></a>配置~/.kube/config</h3><p>如果当前kubectl没有管理的集群，那么没有~/.kube/config文件，则新建一个，如果有，省略这一步。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch ~/.kube/config</span><br></pre></td></tr></table></figure>

<p>若当前访问客户端已配置了其他集群的访问凭证，可并执行以下指令以合并多个集群的 config</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">KUBECONFIG=~/.kube/config:~/mytest_kubeconfig kubectl config view --merge --flatten &gt; ~/.kube/config</span><br><span class="line">export KUBECONFIG=~/.kube/config</span><br></pre></td></tr></table></figure>

<blockquote>
<p>其中，~/mytest_kubeconfig为集群的 kubeconfig 的文件路径，请替换为下载至本地后的实际路径。</p>
</blockquote>
<h3 id="访问-Kubernetes-集群"><a href="#访问-Kubernetes-集群" class="headerlink" title="访问 Kubernetes 集群"></a>访问 Kubernetes 集群</h3><p>完成 kubeconfig 配置后，执行以下指令查看并切换 context 以访问本集群：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@monitor root]# kubectl config get-contexts</span><br><span class="line">CURRENT   NAME                   CLUSTER                AUTHINFO   NAMESPACE</span><br><span class="line">*         test1                  test1                  test1  </span><br><span class="line">[root@monitor root]# kubectl config use-context &quot;test1&quot;</span><br><span class="line">Switched to context &quot;test1&quot;.</span><br></pre></td></tr></table></figure>

<blockquote>
<p>test1 为集群名称</p>
</blockquote>
<p>而后可执行 kubectl get node 测试是否可正常访问集群。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@monitor01 root]# kubectl get node</span><br><span class="line">NAME             STATUS   ROLES                      AGE   VERSION</span><br><span class="line">k8s-node01       Ready    controlplane,etcd,worker   81m   v1.19.15</span><br><span class="line">k8s-node02       Ready    controlplane,etcd,worker   85m   v1.19.15</span><br><span class="line">k8s-node03       Ready    controlplane,etcd,worker   81m   v1.19.15</span><br><span class="line">k8s-node04       Ready    controlplane,etcd,worker   85m   v1.19.15</span><br></pre></td></tr></table></figure>

<p>可以访问了。</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>curl k8s部署服务</title>
    <url>/2021/12/08/2021-12-08-curl-k8s%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p>curl –insecure -sfL <a href="https://1.13.14.236/v3/import/c2mpgqvfmt8xfx2qss2qqvtrb9jh77f7d4x4tq8vxshk9t4jwbwbdg.yaml">https://1.13.14.236/v3/import/c2mpgqvfmt8xfx2qss2qqvtrb9jh77f7d4x4tq8vxshk9t4jwbwbdg.yaml</a> | kubectl apply -f -</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>promQL</title>
    <url>/2021/12/09/2021-12-09-promQL/</url>
    <content><![CDATA[<p>Prometheus的自定义查询语言PromQL(promtheus query language) 。通过PromQL用户可以非常方便地对监控样本数据进行统计分析，PromQL支持常见的运算操作符，同时PromQL中还提供了大量的内置函数可以实现对数据的高级处理。PromQL作为Prometheus的核心能力除了实现数据的对外查询和展现，同时告警监控也是依赖PromQL实现的。</p>
<p>promql本质上和sql没什么不同，根据不同的标签查询数据麻。只是promtheus是时序性数据库，使其和关系性数据库有区别。所系我们需要先了解Prometheus的样本数据模型。</p>
<h3 id="1-prometheus样本数据模型"><a href="#1-prometheus样本数据模型" class="headerlink" title="1 prometheus样本数据模型"></a>1 prometheus样本数据模型</h3><p>Prometheus会将所有采集到的样本数据以时间序列（time-series）的方式保存在内存数据库中，并且定时保存到硬盘上。</p>
<p>在time-series中的每一个点称为一个样本（sample），样本由以下三部分组成：</p>
<ul>
<li>指标(metric)：metric name和描述当前样本特征的labelsets;</li>
<li>时间戳(timestamp)：一个精确到毫秒的时间戳;</li>
<li>样本值(value)： 一个float64的浮点型数据表示当前样本的值。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;--------------- metric ---------------------&gt;&lt;-timestamp -&gt;&lt;-value-&gt;</span><br><span class="line">http_request_total&#123;status=&quot;200&quot;, method=&quot;GET&quot;&#125;@1434417560938 =&gt; 94355</span><br><span class="line">http_request_total&#123;status=&quot;200&quot;, method=&quot;GET&quot;&#125;@1434417561287 =&gt; 94334</span><br><span class="line"></span><br><span class="line">http_request_total&#123;status=&quot;404&quot;, method=&quot;GET&quot;&#125;@1434417560938 =&gt; 38473</span><br><span class="line">http_request_total&#123;status=&quot;404&quot;, method=&quot;GET&quot;&#125;@1434417561287 =&gt; 38544</span><br><span class="line"></span><br><span class="line">http_request_total&#123;status=&quot;200&quot;, method=&quot;POST&quot;&#125;@1434417560938 =&gt; 4748</span><br><span class="line">http_request_total&#123;status=&quot;200&quot;, method=&quot;POST&quot;&#125;@1434417561287 =&gt; 4785</span><br></pre></td></tr></table></figure>

<p>样本点的集合成为集合(vector)</p>
<h3 id="2-指标-metric"><a href="#2-指标-metric" class="headerlink" title="2 指标(metric)"></a>2 指标(metric)</h3><p>在形式上，所有的指标(Metric)都通过如下格式标示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;</span><br></pre></td></tr></table></figure>

<p>指标的名称(metric name)可以反映被监控样本的含义（比如，<code>http_request_total</code> - 表示当前系统接收到的HTTP请求总量）。</p>
<p>标签(label)反映了当前样本的特征维度，通过这些维度Prometheus可以对样本数据进行过滤，聚合等。</p>
<p>在Prometheus的存储实现上所有的监控样本都是以time-series的形式保存在Prometheus内存的TSDB（时序数据库）中，而time-series所对应的监控指标(metric)也是通过labelset进行唯一命名的。</p>
<p>从存储上来讲所有的监控指标metric都是相同的，但是根据不同的展示需求，可以讲metric分为不同的类型。</p>
<p>Prometheus定义了4中不同的指标类型(metric type)：Counter（计数器）、Gauge（仪表盘）、Histogram（直方图）、Summary（摘要）。如果要看累计的值，比如访问总量就是Counter。看瞬时的值比如当前内存剩余就是gauge。而histogram</p>
<p>在Exporter返回的样本数据中，其注释中也包含了该样本的类型。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># HELP node_cpu Seconds the cpus spent in each mode.</span><br><span class="line"># TYPE node_cpu counter</span><br><span class="line">node_cpu&#123;cpu=&quot;cpu0&quot;,mode=&quot;idle&quot;&#125; 362812.7890625</span><br></pre></td></tr></table></figure>

<h4 id="Counter：只增不减的计数器"><a href="#Counter：只增不减的计数器" class="headerlink" title="Counter：只增不减的计数器"></a>Counter：只增不减的计数器</h4><p>Counter类型的指标其工作方式和计数器一样，只增不减（除非系统发生重置）。常见的监控指标，如http_requests_total，node_cpu都是Counter类型的监控指标。 一般在定义Counter类型指标的名称时推荐使用_total作为后缀。</p>
<p>Counter是一个简单但有强大的工具，例如我们可以在应用程序中记录某些事件发生的次数，通过以时序的形式存储这些数据，我们可以轻松的了解该事件产生速率的变化。 PromQL内置的聚合操作和函数可以让用户对这些数据进行进一步的分析：</p>
<p>例如，通过rate()函数获取HTTP请求量的增长率：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rate(http_requests_total[5m])</span><br></pre></td></tr></table></figure>

<p>查询当前系统中，访问量前10的HTTP地址：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">topk(10, http_requests_total)</span><br></pre></td></tr></table></figure>

<h4 id="Gauge：可增可减的仪表盘"><a href="#Gauge：可增可减的仪表盘" class="headerlink" title="Gauge：可增可减的仪表盘"></a>Gauge：可增可减的仪表盘</h4><p>与Counter不同，Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。</p>
<p>通过Gauge指标，用户可以直接查看系统的当前状态：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node_memory_MemFree</span><br></pre></td></tr></table></figure>

<p>对于Gauge类型的监控指标，通过PromQL内置函数delta()可以获取样本在一段时间返回内的变化情况。例如，计算CPU温度在两个小时内的差异：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delta(cpu_temp_celsius&#123;host=&quot;zeus&quot;&#125;[2h])</span><br></pre></td></tr></table></figure>

<p>还可以使用deriv()计算样本的线性回归模型，甚至是直接使用predict_linear()对数据的变化趋势进行预测。例如，预测系统磁盘空间在4个小时之后的剩余情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">predict_linear(node_filesystem_free&#123;job=&quot;node&quot;&#125;[1h], 4 * 3600)</span><br></pre></td></tr></table></figure>

<h4 id="分布情况——Histogram和Summary"><a href="#分布情况——Histogram和Summary" class="headerlink" title="分布情况——Histogram和Summary"></a>分布情况——Histogram和Summary</h4><p>除了Counter和Gauge类型的监控指标以外，Prometheus还定义了Histogram和Summary的指标类型。Histogram和Summary主用用于统计和分析样本的分布情况。</p>
<p>在大多数情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，而这种现象被称为长尾问题。</p>
<p>为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在0<del>10ms之间的请求数有多少而10</del>20ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。</p>
<p>例如，指标prometheus_tsdb_wal_fsync_duration_seconds的指标类型为Summary。 它记录了Prometheus Server中wal_fsync处理的处理时间，通过访问Prometheus Server的/metrics地址，可以获取到以下监控样本数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync.</span><br><span class="line"># TYPE prometheus_tsdb_wal_fsync_duration_seconds summary</span><br><span class="line">prometheus_tsdb_wal_fsync_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 0.012352463</span><br><span class="line">prometheus_tsdb_wal_fsync_duration_seconds&#123;quantile=&quot;0.9&quot;&#125; 0.014458005</span><br><span class="line">prometheus_tsdb_wal_fsync_duration_seconds&#123;quantile=&quot;0.99&quot;&#125; 0.017316173</span><br><span class="line">prometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002</span><br><span class="line">prometheus_tsdb_wal_fsync_duration_seconds_count 216</span><br></pre></td></tr></table></figure>

<p>从上面的样本中可以得知当前Prometheus Server进行wal_fsync操作的总次数为216次，耗时2.888716127000002s。其中中位数（quantile=0.5）的耗时为0.012352463，9分位数（quantile=0.9）的耗时为0.014458005s。</p>
<p>在Prometheus Server自身返回的样本数据中，我们还能找到类型为Histogram的监控指标prometheus_tsdb_compaction_chunk_range_bucket。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction</span><br><span class="line"># TYPE prometheus_tsdb_compaction_chunk_range histogram</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;100&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;400&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1600&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6400&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;25600&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;102400&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;409600&quot;&#125; 0</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1.6384e+06&quot;&#125; 260</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6.5536e+06&quot;&#125; 780</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;2.62144e+07&quot;&#125; 780</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;+Inf&quot;&#125; 780</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_sum 1.1540798e+09</span><br><span class="line">prometheus_tsdb_compaction_chunk_range_count 780</span><br></pre></td></tr></table></figure>

<p>与Summary类型的指标相似之处在于Histogram类型的样本同样会反应当前指标的记录的总数(以_count作为后缀)以及其值的总量（以_sum作为后缀）。不同在于Histogram指标直接反应了在不同区间内样本的个数，区间通过标签len进行定义。</p>
<p>同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。不同在于Histogram通过histogram_quantile函数是在服务器端计算的分位数。 而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。</p>
<h3 id="3-promQL"><a href="#3-promQL" class="headerlink" title="3 promQL"></a>3 promQL</h3><p>Prometheus通过指标名称（metrics name）以及对应的一组标签（labelset）唯一定义一条时间序列。指标名称反映了监控样本的基本标识，而label则在这个基本特征上为采集到的数据提供了多种特征维度。用户可以基于这些特征维度过滤，聚合，统计从而产生新的计算后的一条时间序列。</p>
<p>PromQL是Prometheus内置的数据查询语言，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。并且被广泛应用在Prometheus的日常应用当中，包括对数据查询、可视化、告警处理当中。</p>
<h4 id="查询时间序列"><a href="#查询时间序列" class="headerlink" title="查询时间序列"></a>查询时间序列</h4><p>当Prometheus通过Exporter采集到相应的监控指标样本数据后，我们就可以通过PromQL对监控样本数据进行查询。</p>
<p>当我们直接使用监控指标名称查询时，可以查询该指标下的所有时间序列。如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total</span><br></pre></td></tr></table></figure>

<p>等同于：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>该表达式会返回指标名称为http_requests_total的所有时间序列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;&#125;=(20889@1518096812.326)</span><br><span class="line">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;graph&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;&#125;=(21287@1518096812.326)</span><br></pre></td></tr></table></figure>

<p>PromQL还支持用户根据时间序列的标签匹配模式来对时间序列进行过滤，目前主要支持两种匹配模式：完全匹配和正则匹配。</p>
<p>PromQL支持使用<code>=</code>和<code>!=</code>两种完全匹配模式：</p>
<ul>
<li>通过使用<code>label=value</code>可以选择那些标签满足表达式定义的时间序列；</li>
<li>反之使用<code>label!=value</code>则可以根据标签匹配排除时间序列；</li>
</ul>
<p>例如，如果我们只需要查询所有http_requests_total时间序列中满足标签instance为localhost:9090的时间序列，则可以使用如下表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;instance=&quot;localhost:9090&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>反之使用<code>instance!=&quot;localhost:9090&quot;</code>则可以排除这些时间序列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;instance!=&quot;localhost:9090&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>除了使用完全匹配的方式对时间序列进行过滤以外，PromQL还可以支持使用正则表达式作为匹配条件，多个表达式之间使用<code>|</code>进行分离：</p>
<ul>
<li>使用<code>label=~regx</code>表示选择那些标签符合正则表达式定义的时间序列；</li>
<li>反之使用<code>label!~regx</code>进行排除；</li>
</ul>
<p>例如，如果想查询多个环节下的时间序列序列可以使用如下表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;environment=~&quot;staging|testing|development&quot;,method!=&quot;GET&quot;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h2><p>直接通过类似于PromQL表达式http*requests*total查询时间序列时，返回值中只会包含该时间序列中的最新的一个样本值，这样的返回结果我们称之为<strong>瞬时向量</strong>。而相应的这样的表达式称之为__瞬时向量表达式**。</p>
<p>而如果我们想过去一段时间范围内的样本数据时，我们则需要使用<strong>区间向量表达式</strong>。区间向量表达式和瞬时向量表达式之间的差异在于在区间向量表达式中我们需要定义时间选择的范围，时间范围通过时间范围选择器<code>[]</code>进行定义。例如，通过以下表达式可以选择最近5分钟内的所有样本数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_request_total&#123;&#125;[5m]</span><br></pre></td></tr></table></figure>

<p>该表达式将会返回查询到的时间序列中最近5分钟的所有样本数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;&#125;=[</span><br><span class="line">    1@1518096812.326</span><br><span class="line">    1@1518096817.326</span><br><span class="line">    1@1518096822.326</span><br><span class="line">    1@1518096827.326</span><br><span class="line">    1@1518096832.326</span><br><span class="line">    1@1518096837.325</span><br><span class="line">]</span><br><span class="line">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;graph&quot;,instance=&quot;localhost:9090&quot;,job=&quot;prometheus&quot;,method=&quot;get&quot;&#125;=[</span><br><span class="line">    4 @1518096812.326</span><br><span class="line">    4@1518096817.326</span><br><span class="line">    4@1518096822.326</span><br><span class="line">    4@1518096827.326</span><br><span class="line">    4@1518096832.326</span><br><span class="line">    4@1518096837.325</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>通过区间向量表达式查询到的结果我们称为<strong>区间向量</strong>。</p>
<p>除了使用m表示分钟以外，PromQL的时间范围选择器支持其它时间单位：</p>
<ul>
<li>s - 秒</li>
<li>m - 分钟</li>
<li>h - 小时</li>
<li>d - 天</li>
<li>w - 周</li>
<li>y - 年</li>
</ul>
<h2 id="时间位移操作"><a href="#时间位移操作" class="headerlink" title="时间位移操作"></a>时间位移操作</h2><p>在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_request_total&#123;&#125; # 瞬时向量表达式，选择当前最新的数据</span><br><span class="line">http_request_total&#123;&#125;[5m] # 区间向量表达式，选择以当前时间为基准，5分钟内的数据</span><br></pre></td></tr></table></figure>

<p>而如果我们想查询，5分钟前的瞬时样本数据，或昨天一天的区间内的样本数据呢? 这个时候我们就可以使用位移操作，位移操作的关键字为<strong>offset</strong>。</p>
<p>可以使用offset时间位移操作：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_request_total&#123;&#125; offset 5m</span><br><span class="line">http_request_total&#123;&#125;[1d] offset 1d</span><br></pre></td></tr></table></figure>

<h2 id="使用聚合操作"><a href="#使用聚合操作" class="headerlink" title="使用聚合操作"></a>使用聚合操作</h2><p>一般来说，如果描述样本特征的标签(label)在并非唯一的情况下，通过PromQL查询数据，会返回多条满足这些特征维度的时间序列。而PromQL提供的聚合操作可以用来对这些时间序列进行处理，形成一条新的时间序列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查询系统所有http请求的总量</span><br><span class="line">sum(http_request_total)</span><br><span class="line"></span><br><span class="line"># 按照mode计算主机CPU的平均使用时间</span><br><span class="line">avg(node_cpu) by (mode)</span><br><span class="line"></span><br><span class="line"># 按照主机查询各个主机的CPU使用率</span><br><span class="line">sum(sum(irate(node_cpu&#123;mode!=&#x27;idle&#x27;&#125;[5m]))  / sum(irate(node_cpu[5m]))) by (instance)</span><br></pre></td></tr></table></figure>

<h2 id="标量和字符串"><a href="#标量和字符串" class="headerlink" title="标量和字符串"></a>标量和字符串</h2><p>除了使用瞬时向量表达式和区间向量表达式以外，PromQL还直接支持用户使用标量(Scalar)和字符串(String)。</p>
<h3 id="标量（Scalar）：一个浮点型的数字值"><a href="#标量（Scalar）：一个浮点型的数字值" class="headerlink" title="标量（Scalar）：一个浮点型的数字值"></a>标量（Scalar）：一个浮点型的数字值</h3><p>标量只有一个数字，没有时序。</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10</span><br></pre></td></tr></table></figure>

<blockquote>
<p>需要注意的是，当使用表达式count(http_requests_total)，返回的数据类型，依然是瞬时向量。用户可以通过内置函数scalar()将单个瞬时向量转换为标量。</p>
</blockquote>
<h3 id="字符串（String）：一个简单的字符串值"><a href="#字符串（String）：一个简单的字符串值" class="headerlink" title="字符串（String）：一个简单的字符串值"></a>字符串（String）：一个简单的字符串值</h3><p>直接使用字符串，作为PromQL表达式，则会直接返回字符串。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;this is a string&quot;</span><br><span class="line">&#x27;these are unescaped: \n \\ \t&#x27;</span><br><span class="line">`these are not unescaped: \n &#x27; &quot; \t`</span><br></pre></td></tr></table></figure>

<h2 id="合法的PromQL表达式"><a href="#合法的PromQL表达式" class="headerlink" title="合法的PromQL表达式"></a>合法的PromQL表达式</h2><p>所有的PromQL表达式都必须至少包含一个指标名称(例如http_request_total)，或者一个不会匹配到空字符串的标签过滤器(例如{code=”200”})。</p>
<p>因此以下两种方式，均为合法的表达式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http_request_total # 合法</span><br><span class="line">http_request_total&#123;&#125; # 合法</span><br><span class="line">&#123;method=&quot;get&quot;&#125; # 合法</span><br></pre></td></tr></table></figure>

<p>而如下表达式，则不合法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;job=~&quot;.*&quot;&#125; # 不合法</span><br></pre></td></tr></table></figure>

<p>同时，除了使用<code>&lt;metric name&gt;&#123;label=value&#125;</code>的形式以外，我们还可以使用内置的<code>__name__</code>标签来指定监控指标名称：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;__name__=~&quot;http_request_total&quot;&#125; # 合法</span><br><span class="line">&#123;__name__=~&quot;node_disk_bytes_read|node_disk_bytes_written&quot;&#125; # 合法</span><br></pre></td></tr></table></figure>

<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>224a31b93706e3592cb8961318638e3dca071f41</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>linux常用快捷键</title>
    <url>/2021/12/10/2021-12-10-linux%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<p>linux中常用的快捷键，总结备查</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tab # 命令或路径等的补全键，linux用的最多的一个快捷键 </span><br><span class="line"># 光标移动</span><br><span class="line">ctrl+a # 光标回到行首 </span><br><span class="line">ctrl+e # 光标回到行尾</span><br><span class="line">ctrl+f # 光标向右移动一个字符 forwards</span><br><span class="line">ctrl+b # 光标向左移动一个字符 behind</span><br><span class="line">esc+. # 注意那个&quot;.“ 意思是获取上一条命令的(以空格为分隔符)最后的部分</span><br><span class="line">esc+b # 移动到当前单词的开头</span><br><span class="line">esc+f # 移动到当前单词的结尾</span><br><span class="line"># 剪切 </span><br><span class="line">ctrl+u # 剪切光标处到行首的所有字符, 也就是删除</span><br><span class="line">ctrl+k # 剪切光标处到行尾的所有字符</span><br><span class="line">ctrl+w # 剪切光标前的一个单词(word)</span><br><span class="line">ctrl+h # 删除光标前的一个字符（相当于退格键）</span><br><span class="line"># 粘贴</span><br><span class="line">ctrl+y # 粘贴 ctrl+k、ctrl+u、ctrl+w 删除的字符</span><br><span class="line"># 中断</span><br><span class="line">ctrl+c # 中断终端正在执行的任务并开启一个新的一行</span><br><span class="line">ctrl+z # 暂停在终端运行的任务,使用&quot;fg&quot;命令可以使暂停恢复</span><br><span class="line">ctrl+d # 退出当前shell命令行，如果是切换过来的用户，则执行这个命令回退到原用户</span><br><span class="line"># 清空</span><br><span class="line">ctrl+l # 清空屏幕所有的内容，并开启一个新的一行，等价于clear,似乎比clear快一点</span><br><span class="line"># 锁定</span><br><span class="line">ctrl+s # 锁定终端，使之任何人无法输入</span><br><span class="line">ctrl+q # 解锁ctrl+s的锁定状态</span><br><span class="line"># 历史命令</span><br><span class="line">ctrl+r # 搜索命令行使用过的历史命令记录，比history好用一点</span><br><span class="line">ctrl+g # 从ctrl+r的搜索历史命令模式中退出</span><br><span class="line">!! # 执行上一条命令 </span><br><span class="line">!commdand # 这是一个例子，是执行以ommdand开头的命令，这里的ommdand可以换成任何已经执行过的字符</span><br><span class="line">!commdand:p # 这是一个例子，是仅打印以commdand开头的命令，但不执行，最后的那个“p”是命令固定字符</span><br></pre></td></tr></table></figure>

<blockquote>
<p>以上命令不区分大小写，如ctrl+a与ctrl+A效果相同</p>
</blockquote>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>promethus联邦+ 远程持久化存储+ 可视化</title>
    <url>/2021/12/13/2021-12-13-promethus%E8%81%94%E9%82%A6+-%E8%BF%9C%E7%A8%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8+-%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<h3 id="联邦集群"><a href="#联邦集群" class="headerlink" title="联邦集群"></a>联邦集群</h3><p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/%E8%81%94%E9%82%A6%E9%9B%86%E7%BE%A4.png">    </p>
<h3 id="实验架构"><a href="#实验架构" class="headerlink" title="实验架构"></a>实验架构</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 两个集群</span><br><span class="line"># prometheus_cluster1</span><br><span class="line"># prometheus_cluster2 </span><br><span class="line"># 一个主机承担 </span><br><span class="line"># prometheus_master + influxdb + grafana</span><br></pre></td></tr></table></figure>

<h3 id="实验操作"><a href="#实验操作" class="headerlink" title="实验操作"></a>实验操作</h3><h4 id="1-集群部署prometheus"><a href="#1-集群部署prometheus" class="headerlink" title="1 集群部署prometheus"></a>1 集群部署prometheus</h4><p>集群部署文件存在gitee/k8s仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://gitee.com/yuanwl/k8s.git</span><br><span class="line">cd  k8s/pig</span><br><span class="line"># 新建一个监控namespace</span><br><span class="line">kubectl apply -f monitor.ns.yml</span><br><span class="line">cd prometheus</span><br><span class="line"># 启动prometheus监控</span><br><span class="line">kubectl apply -f  </span><br><span class="line"># 测试可以访问</span><br><span class="line">http://&lt;node_ip&gt;/graph</span><br></pre></td></tr></table></figure>

<ol>
<li>多个k8s集群，这里两个集群，并且已经配置prometheus服务，接口分别是: </li>
</ol>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- &#x27;1.13.92.201:30003&#x27;</span><br><span class="line">- &#x27;1.13.102.83:30003&#x27;</span><br><span class="line"># 测试http://1.13.102.83:30003/graph 可查当前数据中心数据即可</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>一个主机 main </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.117.61.155 centOS 7.6 2C4G</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="主机main配置"><a href="#主机main配置" class="headerlink" title="主机main配置"></a>主机main配置</h3><h4 id="1-配置influxdb"><a href="#1-配置influxdb" class="headerlink" title="1 配置influxdb"></a>1 配置influxdb</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget https://dl.influxdata.com/influxdb/releases/influxdb-1.8.1.x86_64.rpm </span><br><span class="line"># 安装</span><br><span class="line">yum -y localinstall influxdb-1.8.1.x86_64.rpm </span><br><span class="line"># 配置/etc/influxdb/influxdb.conf 开启http </span><br><span class="line"># 新建一个database </span><br><span class="line">curl -XPOST http://localhost:8086/query --data-urlencode &quot;q=CREATE DATABASE prometheus&quot;</span><br></pre></td></tr></table></figure>

<p>也可以docker启动influxdb </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#使用docker-compose定义并启动Influxdb数据库服务，docker-compose.yml定义如下：</span><br><span class="line"></span><br><span class="line">version: &#x27;2&#x27;</span><br><span class="line">services:</span><br><span class="line">  influxdb:</span><br><span class="line">    image: influxdb:1.3.5</span><br><span class="line">    command: -config /etc/influxdb/influxdb.conf</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;8086:8086&quot;</span><br><span class="line">    environment:</span><br><span class="line">      - INFLUXDB_DB=prometheus</span><br><span class="line">      - INFLUXDB_ADMIN_ENABLED=true</span><br><span class="line">      - INFLUXDB_ADMIN_USER=admin</span><br><span class="line">      - INFLUXDB_ADMIN_PASSWORD=admin</span><br><span class="line">      - INFLUXDB_USER=prom</span><br><span class="line">      - INFLUXDB_USER_PASSWORD=prom</span><br><span class="line"># 启动influxdb服务</span><br><span class="line">docker-compose up -d</span><br><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">795d0ead87a1        influxdb:1.3.5      &quot;/entrypoint.sh -c...&quot;   3 hours ago         Up 3 hours          0.0.0.0:8086-&gt;8086/tcp   localhost_influxdb_1</span><br><span class="line"># 获取并启动Prometheus提供的Remote Storage Adapter：</span><br><span class="line"># 先配置golang , 官方下载安装包，再添加路径</span><br><span class="line"># go get 下载并编译</span><br><span class="line">go get github.com/prometheus/prometheus/documentation/examples/remote_storage/remote_storage_adapter</span><br><span class="line"># 获取remote_storage_adapter源码后，go会自动把相关的源码编译成可执行文件，并且保存在$GOPATH/bin/目录下。</span><br><span class="line"></span><br><span class="line"># 启动remote_storage_adapter并且设置Influxdb相关的认证信息：</span><br><span class="line"></span><br><span class="line">INFLUXDB_PW=prom $GOPATH/bin/remote_storage_adapter -influxdb-url=http://localhost:8086 -influxdb.username=prom -influxdb.database=prometheus -influxdb.retention-policy=autogen</span><br></pre></td></tr></table></figure>



<h4 id="2-配置prometheus"><a href="#2-配置prometheus" class="headerlink" title="2 配置prometheus"></a>2 配置prometheus</h4><p>使用docker或者安装包部署prometheus都可以，这里使用安装包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1 下载安装包prometheus-1.6.2.linux-amd64.tar.gz</span><br><span class="line">https://github.com/prometheus/prometheus/releases/tag/v1.6.2</span><br><span class="line"># 2 解压</span><br><span class="line">tar -xvf prometheus-1.6.2.linux-amd64.tar.gz</span><br><span class="line">cd prometheus-1.6.2.linux-amd64</span><br><span class="line"># 3 配置prometheus.yml， 配置prometheus联邦，拉取两个cluster的数据。</span><br><span class="line"></span><br><span class="line">cat &gt; prometheus.yml &lt;&lt; EOF</span><br><span class="line"># my global config</span><br><span class="line">global:</span><br><span class="line">  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</span><br><span class="line">  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</span><br><span class="line">  # scrape_timeout is set to the global default (10s).</span><br><span class="line"></span><br><span class="line">  # Attach these labels to any time series or alerts when communicating with</span><br><span class="line">  # external systems (federation, remote storage, Alertmanager).</span><br><span class="line">  external_labels:</span><br><span class="line">      monitor: &#x27;codelab-monitor&#x27;</span><br><span class="line"></span><br><span class="line"># Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.</span><br><span class="line">rule_files:</span><br><span class="line">  # - &quot;first.rules&quot;</span><br><span class="line">  # - &quot;second.rules&quot;</span><br><span class="line"></span><br><span class="line"># A scrape configuration containing exactly one endpoint to scrape:</span><br><span class="line"># Here it&#x27;s Prometheus itself.</span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;federate&#x27;</span><br><span class="line">    scrape_interval: 15s</span><br><span class="line"></span><br><span class="line">    honor_labels: true</span><br><span class="line">    metrics_path: &#x27;/federate&#x27;</span><br><span class="line"># 联邦集群</span><br><span class="line">    params:</span><br><span class="line">      &#x27;match[]&#x27;:</span><br><span class="line">        - &#x27;&#123;job=&quot;prometheus&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-apiservers&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-nodes&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-cadvisor&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-service-endpoints&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-services&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-ingresses&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;job=&quot;kubernetes-pods&quot;&#125;&#x27;</span><br><span class="line">        - &#x27;&#123;__name__=~&quot;job:.*&quot;&#125;&#x27;</span><br><span class="line"># 这里抓的matrics与集群prometheus服务中的job匹配</span><br><span class="line">#    static_configs:</span><br><span class="line">#      - targets:</span><br><span class="line">#        - &#x27;1.13.92.201:30003&#x27;</span><br><span class="line">#        - &#x27;1.13.102.83:30003&#x27;</span><br><span class="line"># 配置数据中心， 集群任意节点加nodeport端口 </span><br><span class="line"># 为了在展示中心展示数据中心的名称， 可在grafanaz主机添加host,然后通过名称导入</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - &#x27;cluster1:30003&#x27;</span><br><span class="line">        - &#x27;cluster2:30003&#x27;</span><br><span class="line"># 使用名称后需要加个数据中心的标签重写， 并加入正则匹配数据中心</span><br><span class="line">    relabel_configs:</span><br><span class="line">      - source_labels:  [&quot;__address__&quot;]</span><br><span class="line">        target_label: &quot;data_center&quot;</span><br><span class="line">        regex: (.+):\d*</span><br><span class="line"># 远程读写</span><br><span class="line">#remote_write:</span><br><span class="line"># - url: &quot;http://localhost:8086/api/v1/prom/write?db=prometheus&quot;       </span><br><span class="line">EOF</span><br><span class="line"># /etc/hosts配置</span><br><span class="line">cluster1 1.13.92.201</span><br><span class="line">cluster2 11.13.102.83</span><br><span class="line"># 4 启动</span><br><span class="line">nohup ./prometheus -config.file=prometheus.yml &gt; myout.file  2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"># 5 WEB页面访问http://1.117.61.155:9090/ ，可以看到两个数据中心</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/prom.png"></p>
<h4 id="3-配置grafana"><a href="#3-配置grafana" class="headerlink" title="3 配置grafana"></a>3 配置grafana</h4><p>面配置grafana展示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1 下载 </span><br><span class="line">wget https://dl.grafana.com/oss/release/grafana-6.7.1-1.x86_64.rpm</span><br><span class="line"># 2 安装</span><br><span class="line">yum -y install grafana-6.7.1-1.x86_64.rpm</span><br><span class="line"># 3 启动服务， 默认配置即可</span><br><span class="line">systemctl restart grafana-server.service</span><br><span class="line">systemctl enable grafana-server.service  </span><br><span class="line"># 4 默认端口3000 </span><br><span class="line">http://&lt;ip&gt;:3000 访问</span><br><span class="line"># 5 配置数据源为promethues, http://1.117.61.155:9090/ </span><br></pre></td></tr></table></figure>

<p>数据源配置具体部分省略，也已经同步到influxdb仓库中。 </p>
<p>grafana的面板配置在k8s/grafana中，可直接导入json生成面板。</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>influxdb</title>
    <url>/2021/12/15/2021-12-14-influxdb/</url>
    <content><![CDATA[<p>97  2021-12-10 16:05:20 wget  <a href="https://dl.influxdata.com/influxdb/releases/influxdb-1.8.0.x86_64.rpm">https://dl.influxdata.com/influxdb/releases/influxdb-1.8.0.x86_64.rpm</a><br>   98  2021-12-10 16:06:43 yum localinstall -y influxdb-1.8.0.x86_64.rpm</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>git版本控制的常规用法</title>
    <url>/2021/12/15/2021-12-15-git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%9A%84%E5%B8%B8%E8%A7%84%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<p>[TOC]</p>
<p>最近在改服务器上改代码的时候，每次都要在本地备份，有时在本地改完还要同步，搞多个版本把我自己都搞乱了，是时候使用git了。 我的需求之一就是在多台机器上操作，能够同步，在服务器上能下载最新的版本， 更改后再更新到仓库，git可以解决我的需求，github作为仓库，有的时候网络不稳定，gitee更快一点，所以就选择gitee作为远程仓库。</p>
<h3 id="gitee"><a href="#gitee" class="headerlink" title="gitee"></a>gitee</h3><p>首先要创建gitee账户，再新建仓库。 </p>
<h3 id="linux系统"><a href="#linux系统" class="headerlink" title="linux系统"></a>linux系统</h3><p>安装git , 配置密钥，然后就可以拉取或者更新。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 源里有git，直接yum安装即可</span><br><span class="line">yum -y install git</span><br><span class="line"># 新建一个文件夹，作为gitee仓库交互的仓库</span><br><span class="line">mkdir gitee &amp;&amp; cd gitee </span><br><span class="line"># git 初始化</span><br><span class="line">git init </span><br><span class="line"># 初始化一个.git文件，是一个工作目录， 保存status, 克隆是不需要的.git的, 查找.git顺序， 同级目录，上级目录。</span><br><span class="line"># 配置用户</span><br><span class="line">git config --global user.name &quot;yuanwl&quot;</span><br><span class="line">git config --global user.email &quot;yuan.wanli@qq.com&quot;</span><br><span class="line"># 配置远端地址 - 目标远程仓库的下载链接 #origin 远端仓库本地名称</span><br><span class="line">git remote add origin https://gitee.com/yuanwl/k8s.git</span><br><span class="line"># 会生成一些配置文件，看一下</span><br><span class="line">[root@node61 gitee]# ll -a</span><br><span class="line">drwxr-xr-x   8 root root 4096 Dec 15 15:39 .git</span><br><span class="line">[root@node61 gitee]# ll -a .git/</span><br><span class="line">total 60</span><br><span class="line">drwxr-xr-x  2 root root 4096 Dec 15 10:39 branches </span><br><span class="line"># 分支</span><br><span class="line">-rw-r--r--  1 root root    5 Dec 15 15:31 COMMIT_EDITMSG</span><br><span class="line"># commit 信息  </span><br><span class="line">-rw-r--r--  1 root root  352 Dec 15 15:39 config  ---远端配置文件在这里</span><br><span class="line"># 配置文件</span><br><span class="line">-rw-r--r--  1 root root   73 Dec 15 10:39 description</span><br><span class="line">-rw-r--r--  1 root root   82 Dec 15 14:35 FETCH_HEAD</span><br><span class="line">-rw-r--r--  1 root root   23 Dec 15 10:39 HEAD</span><br><span class="line">drwxr-xr-x  2 root root 4096 Dec 15 10:39 hooks</span><br><span class="line"># 命令</span><br><span class="line">-rw-r--r--  1 root root 1241 Dec 15 15:30 index</span><br><span class="line">drwxr-xr-x  2 root root 4096 Dec 15 10:39 info </span><br><span class="line">drwxr-xr-x  3 root root 4096 Dec 15 10:45 logs</span><br><span class="line"># 日志</span><br><span class="line">drwxr-xr-x 55 root root 4096 Dec 15 14:56 objects </span><br><span class="line">-rw-r--r--  1 root root   41 Dec 15 14:35 ORIG_HEAD</span><br><span class="line">drwxr-xr-x  5 root root 4096 Dec 15 14:36 refs </span><br><span class="line"># 许多文件也不清楚作用， 但应该git配置和操作的信息都在这</span><br></pre></td></tr></table></figure>

<p>git配置后之后，已经可以和gitee或其他线上仓库交互了，比如拉取一个仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone origin https://gitee.com/yuanwl/k8s.git</span><br><span class="line"># 或者</span><br><span class="line">git pull origin https://gitee.com/yuanwl/k8s.git</span><br></pre></td></tr></table></figure>

<p>可以在本地修改同步到远程仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 例如刚修改了 README.md, 提交到暂存区</span><br><span class="line">git add README.md </span><br><span class="line"># 这就告诉了git, 做了哪些修改</span><br><span class="line">git commit -m &quot;test&quot;</span><br><span class="line"># commit就是确认提交到了本地仓库， -m 的参数是这次提交的注释，虽然写注释有点麻烦，但是写一下还是有用的，知道是提交了什么 </span><br><span class="line">git push  </span><br><span class="line"># 之后会提示输入用户和密码，然后就可以提交了</span><br></pre></td></tr></table></figure>

<p>这是一个变更同步到仓库的过程，第一次接触可能会疑问，为什么不能一步到位，要三个命令才能同步呢？这是因为git的工作台机制，为了版本控制。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/git.drawio.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试</span><br><span class="line">[root@node61 k8s]#echo &quot;this is a test &quot;work stage&quot;&quot; &gt;&gt; test.md </span><br><span class="line"># 更改后查看状态， not staged </span><br><span class="line">[root@node61 k8s]# git status  </span><br><span class="line"># On branch master</span><br><span class="line"># Changes not staged for commit:</span><br><span class="line">#   (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">#   (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)</span><br><span class="line">#</span><br><span class="line">#	modified:   test.md</span><br><span class="line">#</span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br><span class="line">[root@node61 k8s]# git add test.md</span><br><span class="line"># add后查看状态， not commited </span><br><span class="line">[root@node61 k8s]# git status </span><br><span class="line"># On branch master</span><br><span class="line"># Changes to be committed:</span><br><span class="line">#   (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)</span><br><span class="line">#</span><br><span class="line">#	modified:   test.md</span><br><span class="line">#</span><br><span class="line">[root@node61 k8s]# git commit -m &quot;1&quot;</span><br><span class="line">[master 31f1e76] 1</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br><span class="line"> # commit后查看状态， 没有push</span><br><span class="line">[root@node61 k8s]# git status</span><br><span class="line"># On branch master</span><br><span class="line"># Your branch is ahead of &#x27;origin/master&#x27; by 1 commit.</span><br><span class="line">#   (use &quot;git push&quot; to publish your local commits)</span><br><span class="line">#</span><br><span class="line">nothing to commit, working directory clean</span><br><span class="line">[root@node61 k8s]# git push </span><br><span class="line">Counting objects: 5, done.</span><br><span class="line">Compressing objects: 100% (2/2), done.</span><br><span class="line">Writing objects: 100% (3/3), 271 bytes | 0 bytes/s, done.</span><br><span class="line">Total 3 (delta 1), reused 0 (delta 0)</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.2]</span><br><span class="line">To https://gitee.com/yuanwl/k8s.git</span><br><span class="line">   d664e8f..31f1e76  master -&gt; master</span><br><span class="line"># push之后，工作台干净了</span><br><span class="line">[root@node61 k8s]# git status</span><br><span class="line"># On branch master</span><br><span class="line">nothing to commit, working directory clean</span><br></pre></td></tr></table></figure>

<p>这样搞清了每一步要干啥，但麻烦的是每次都要输入账号密码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 可以配置记住密码</span><br><span class="line">git config --global credential.helper store</span><br><span class="line"># 产生一个文件 /root/.gitconfig</span><br><span class="line">[root@VM-4-15-centos ~]# cat .gitconfig </span><br><span class="line">[credential]</span><br><span class="line">	helper = store</span><br><span class="line">[user]</span><br><span class="line">	email = yuan.wanli@qq.com</span><br><span class="line">	name = yuanwl</span><br><span class="line"># 记录了账号与用户 </span><br><span class="line"># 然后执行git pull 之后， 就会记住密码，存在/root/.git-credentials以后就不用输入了</span><br><span class="line">[root@VM-4-15-centos ~]# cat .git-credentials </span><br><span class="line">https://yuanwl:123456789@gitee.com</span><br><span class="line"># 这问题明显了，密码明文可见，一点都不安全，平时自己用用测试是可以的</span><br></pre></td></tr></table></figure>

<p>ssh免密登陆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 删除原有的通信方式 # 可选</span><br><span class="line">git remote rm origin </span><br><span class="line"># 生成密钥</span><br><span class="line">ssh-keygen </span><br><span class="line"># 将公钥~/.ssh/id_rsa.pub放在gitee公钥上，设置--ssh公钥--添加</span><br><span class="line"># 添加ssh路径，git开头，和http路径不同 </span><br><span class="line">git init git remote add origin </span><br><span class="line">git remote add origin git@gitee.com:uxpi/zsites.git</span><br><span class="line"># 测试 </span><br><span class="line">[root@node61 ~]# ssh -T git@gitee.com</span><br><span class="line">Hi yuanwanli! You&#x27;ve successfully authenticated, but GITEE.COM does not provide shell access. </span><br><span class="line"># 然后就可以免密提交了</span><br></pre></td></tr></table></figure>

<h3 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h3><p>我很多时候是在window多台主机上做修改。windows中在官网<a href="https://www.git-scm.com/download/win">Git - Downloading Package (git-scm.com)</a>下载git应用，安装一路next即可。 </p>
<p>新建同步文件夹之后，右键选择 git bash here. 之后操作就和linux一样了。 </p>
<h3 id="进一步使用"><a href="#进一步使用" class="headerlink" title="进一步使用"></a>进一步使用</h3><p><strong>删除文件</strong>， 如果删除了一个文件， 就不能git add filename ，可以使用 <code>git rm</code>确认删除了，然后commit.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -f test.md </span><br><span class="line">git rm test.md </span><br><span class="line"># 这样可能比较麻烦，有时也会忘，也没有关系。 如果在add 的时候提示： </span><br><span class="line">warning: You ran &#x27;git add&#x27; with neither &#x27;-A (--all)&#x27; or &#x27;--ignore-removal&#x27;,</span><br><span class="line">whose behaviour will change in Git 2.0 with respect to paths you removed.</span><br><span class="line">Paths like &#x27;test.md&#x27; that are</span><br><span class="line">removed from your working tree are ignored with this version of Git.</span><br><span class="line"></span><br><span class="line">* &#x27;git add --ignore-removal &lt;pathspec&gt;&#x27;, which is the current default,</span><br><span class="line">  ignores paths you removed from your working tree.</span><br><span class="line"></span><br><span class="line">* &#x27;git add --all &lt;pathspec&gt;&#x27; will let you also record the removals.</span><br><span class="line"># 这时候再使用， git add -A 或者 git add --ignore-removal 也可以。</span><br><span class="line"># 也可以直接用git rm test.md</span><br></pre></td></tr></table></figure>

<p>另一种情况是， 如果是<strong>误删</strong>呢？ 也可有恢复<code>checkout</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node61 k8s]# git checkout -- test.md</span><br><span class="line">[root@node61 k8s]# ls </span><br><span class="line">-rw-r--r-- 1 root root  320 Dec 16 16:04  test.md</span><br><span class="line"># 文件回来了, 但只有commit之后才能恢复，没有commit的东西git根本不知道，也无法恢复。</span><br></pre></td></tr></table></figure>

<p>如果我第二天不知道自己昨天改了什么呢？<code>git diff</code> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node61 k8s]# git diff test.md</span><br><span class="line">diff --git a/test.md b/test.md</span><br><span class="line">index 90bfcb5..2178a28 100644</span><br><span class="line">--- a/test.md</span><br><span class="line">+++ b/test.md</span><br><span class="line">@@ -1 +1,2 @@</span><br><span class="line"> this is a test</span><br><span class="line">+this is a test</span><br></pre></td></tr></table></figure>
<p>如果我不知道现在改的文件有没有提交怎么办呢？<code>git status</code> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node61 k8s]# git status test.md</span><br><span class="line"># On branch master</span><br><span class="line"># Your branch is ahead of &#x27;origin/master&#x27; by 1 commit.</span><br><span class="line">#   (use &quot;git push&quot; to publish your local commits)</span><br><span class="line">#</span><br><span class="line"># Changes not staged for commit:</span><br><span class="line">#   (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">#   (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory)</span><br><span class="line">#</span><br><span class="line">#	modified:   test.md</span><br><span class="line">#</span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br></pre></td></tr></table></figure>

<p>当然了，在实际工作中，我们脑子里怎么可能记得一个几千行的文件每次都改了什么内容，不然要版本控制系统干什么。版本控制系统肯定有某个命令可以告诉我们<strong>历史记录</strong>，在Git中，我们用<code>git log</code>可以查看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node61 k8s]# git log</span><br><span class="line">commit 088a4167f946247ced6766c58ffd0568369ce69d</span><br><span class="line">Author: yuanwl &lt;yuan.wanli@qq.com&gt;</span><br><span class="line">Date:   Thu Dec 16 11:41:56 2021 +0800</span><br><span class="line">    first commit </span><br><span class="line">commit ca0ffde7153d0f4eee8473cfa23797835ed74ae9</span><br><span class="line">Merge: e72ac3d 259e9bf</span><br><span class="line"># 可以看最近三次的提交日志 </span><br></pre></td></tr></table></figure>

<p><strong>版本回退</strong>，如果我提交了错误的修改，可以回退到上个版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node61 k8s]# git reset --hard HEAD^</span><br><span class="line">HEAD is now at 818a7ff test</span><br><span class="line"># 也可以根据版本commit 版本号回退， git reflog</span><br><span class="line">[root@node61 k8s]# git reflog</span><br><span class="line">d664e8f HEAD@&#123;0&#125;: pull: Fast-forward</span><br><span class="line">818a7ff HEAD@&#123;1&#125;: reset: moving to HEAD^</span><br><span class="line">d664e8f HEAD@&#123;2&#125;: pull: Fast-forward</span><br><span class="line">818a7ff HEAD@&#123;3&#125;: commit: test</span><br><span class="line">088a416 HEAD@&#123;4&#125;: clone: from https://gitee.com/yuanwl/k8s.git</span><br><span class="line">[root@node61 k8s]# git reset HEAD 818a7ff</span><br></pre></td></tr></table></figure>

<h3 id="分支合并"><a href="#分支合并" class="headerlink" title="分支合并"></a>分支合并</h3><p>分支合并是git中最核心的操作， 开始的时候只有一条分支master, 这样的问题是如果多人一起开发，那么可能出现每次push都会遇到别人修改的仓库。每个人一个分支, 在本地修改好再同步到master， 保证master是稳定的，其余分支是工作的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/gitbranch.drawio.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建分支 </span><br><span class="line">git branch lenovo </span><br><span class="line"># 切换分支  </span><br><span class="line">git checkout lenovo </span><br><span class="line"># pull 特定分支</span><br><span class="line">git pull -b main url</span><br><span class="line"># 切换到一个新的分支 git checkout -b levono </span><br><span class="line"># 查看分支 , 当前的分支前有星号 </span><br><span class="line">$ git branch</span><br><span class="line">* lenovo</span><br><span class="line">  master</span><br><span class="line"># 在levono分支修改后，切换回master分支是看不到修改内容的，需要同步一下。 </span><br><span class="line">git merge lenovo </span><br><span class="line"># 同步有两种情况： </span><br><span class="line"># 1 lenovo只是新增了内容， 没有冲突， 可以快速合并 </span><br><span class="line"># 2 lenovo上修改了内容，两条分支内容有冲突， 所以需要手动确认内容。 下面是冲突的情况</span><br><span class="line"># lenovo 中 tesk.md 如下： </span><br><span class="line">$ cat test.md</span><br><span class="line">which is the stable branch?</span><br><span class="line">lenovo</span><br><span class="line"></span><br><span class="line"># master 中tesk.md 如下：</span><br><span class="line">$ cat test.md</span><br><span class="line">which is the stable branch?</span><br><span class="line">master</span><br><span class="line"></span><br><span class="line"># 这是两个分支是有冲突的， git merge之后回提示需要手动解决冲突，冲突会在test.md文档中标记</span><br><span class="line">$ cat test.md</span><br><span class="line">which is the stable branch?</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD   # 当前指向 </span><br><span class="line">master</span><br><span class="line">=======</span><br><span class="line">lenovo</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; lenovo  # lenovo分支内容  </span><br><span class="line"></span><br><span class="line"># 需要手动修改文档成最终我们需要的内容,然后commit就同步了 </span><br><span class="line">$ cat test.md</span><br><span class="line">which is the stable branch?</span><br><span class="line">master</span><br><span class="line"></span><br><span class="line"># 删除分支 </span><br><span class="line">git checkout -d lenovo </span><br><span class="line"></span><br><span class="line"># 本地lenovo分支推送远程master分支 </span><br><span class="line">git push origin lenovo:master</span><br><span class="line"></span><br><span class="line"># 拉取远程master到本地lenovo分子</span><br><span class="line">git pull origin master:lenovo</span><br><span class="line"># 总结就是 git push/pull origin  &lt;源仓库名称&gt;:&lt;目标仓库名称&gt;</span><br></pre></td></tr></table></figure>

<h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><p>tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起。 发布一个版本时，我们通常先在版本库中打一个标签（tag），这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 标签是commit的称呼，所以先看commit </span><br><span class="line">$ git log --abbrev-commit</span><br><span class="line">commit 0e8c272 (HEAD -&gt; master, tag: v3.0)</span><br><span class="line">Author: yuanwanli &lt;yuan.wanli@qq.com&gt;</span><br><span class="line">Date:   Sun Dec 19 10:52:18 2021 +0800</span><br><span class="line"></span><br><span class="line">    add C 10.53</span><br><span class="line"></span><br><span class="line">commit 98ea6fb</span><br><span class="line">Author: yuanwanli &lt;yuan.wanli@qq.com&gt;</span><br><span class="line">Date:   Sun Dec 19 10:51:54 2021 +0800</span><br><span class="line"></span><br><span class="line">    add b 10.52</span><br><span class="line"></span><br><span class="line">commit 8350365</span><br><span class="line">Author: yuanwanli &lt;yuan.wanli@qq.com&gt;</span><br><span class="line">Date:   Sun Dec 19 10:51:22 2021 +0800</span><br><span class="line"></span><br><span class="line">    add a 10.51</span><br><span class="line"># 给最近的修改加标签 </span><br><span class="line">$ git ag v3.0 0e8c272</span><br><span class="line">$ git tag v2.0 98ea6fb</span><br><span class="line"></span><br><span class="line"># 查看标签列表 </span><br><span class="line">$ git tag</span><br><span class="line">v2.0</span><br><span class="line">v3.0</span><br><span class="line"></span><br><span class="line"># 查看标签明细</span><br><span class="line">$ git show v3.0</span><br><span class="line">commit 0e8c272709f6ac07155849fd7d0d3727161bf1f6 (HEAD -&gt; master, tag: v3.0)</span><br><span class="line">Author: yuanwanli &lt;yuan.wanli@qq.com&gt;</span><br><span class="line">Date:   Sun Dec 19 10:52:18 2021 +0800</span><br><span class="line"></span><br><span class="line">    add C 10.53</span><br><span class="line"></span><br><span class="line">diff --git a/test.md b/test.md</span><br><span class="line">index 422c2b7..de98044 100644</span><br><span class="line">--- a/test.md</span><br><span class="line">+++ b/test.md</span><br><span class="line">@@ -1,2 +1,3 @@</span><br><span class="line"> a</span><br><span class="line"> b</span><br><span class="line">+c</span><br><span class="line"></span><br><span class="line"># 标签推送，讲v3.0推送到远端仓库</span><br><span class="line">$ git push origin v3.0</span><br><span class="line">Enumerating objects: 18, done.</span><br><span class="line">Counting objects: 100% (18/18), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (11/11), done.</span><br><span class="line">Writing objects: 100% (16/16), 1.20 KiB | 204.00 KiB/s, done.</span><br><span class="line">Total 16 (delta 7), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.2]</span><br><span class="line">To https://gitee.com/yuanwl/k8s.git</span><br><span class="line"> * [new tag]         v3.0 -&gt; v3.0</span><br><span class="line"></span><br><span class="line"># 标签删除</span><br><span class="line">$ git tag -d v2.0</span><br><span class="line">Deleted tag &#x27;v2.0&#x27; (was 98ea6fb)</span><br></pre></td></tr></table></figure>

<h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>在push的时候遇到这样一个错误</p>
<p>error: failed to push some refs to ‘<a href="https://gitee.com/yuanwl/k8s.git&#39;">https://gitee.com/yuanwl/k8s.git&#39;</a><br>Updates were rejected because the remote contains work that you do<br>not have locally. This is usually caused by another repository pushing<br>to the same ref. You may want to first merge the remote changes (e.g.,<br>hint: ‘git pull’) before pushing again.</p>
<p>就是线上的仓库在上次我clone之后有了改动(是我删了一个文件)， 这样不能直接commit, </p>
<p>git会记下上次pull的版本，如果pull之后远程又做了修改，无法直接push, 这也很好理解，git不知道如何处理远程仓库的改动。</p>
<p>可以使用git pull同步。</p>
<h3 id="简易git"><a href="#简易git" class="headerlink" title="简易git"></a>简易git</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">简易的命令行入门教程:</span><br><span class="line">Git 全局设置:</span><br><span class="line"></span><br><span class="line">git config --global user.name &quot;yuanwanli&quot;</span><br><span class="line">git config --global user.email &quot;yuan.wanli@qq.com&quot;</span><br><span class="line">创建 git 仓库:</span><br><span class="line"></span><br><span class="line">mkdir autoblog</span><br><span class="line">cd autoblog</span><br><span class="line">git init </span><br><span class="line">touch README.md</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line">git remote add origin https://gitee.com/yuanwl/autoblog.git</span><br><span class="line">git push -u origin &quot;master&quot;</span><br><span class="line">已有仓库?</span><br><span class="line"></span><br><span class="line">cd existing_git_repo</span><br><span class="line">git remote add origin https://gitee.com/yuanwl/autoblog.git</span><br><span class="line">git push -u origin &quot;master&quot;</span><br></pre></td></tr></table></figure>





<h3 id="gitsubmodule"><a href="#gitsubmodule" class="headerlink" title="gitsubmodule"></a>gitsubmodule</h3><p>面对比较复杂的项目，我们有可能会将代码根据功能拆解成不同的子模块。主项目对子模块有依赖关系，却又并不关心子模块的内部开发流程细节。</p>
<p>这种情况下，通常不会把所有源码都放在同一个 Git 仓库中。</p>
<p>有一种比较简单的方式，是在当前工作目录下，将子模块文件夹加入到 <code>.gitignore</code> 文件内容中，这样主项目就能够无视子项目的存在。这样做有一个弊端就是，使用主项目的人需要有一个先验知识：需要在当前目录下放置一份某版本的子模块代码。</p>
<p>.gitignore是始终忽略这些文件，也不上传。</p>
<p>还有另外一种方式可供借鉴，可以使用 Git 的 <code>submodule</code> 功能，实际上 Git 工具的 <code>submodule</code> 功能就是建立了当前项目与子模块之间的依赖关系：<code>子模块路径</code>、<code>子模块的远程仓库</code>、<code>子模块的版本号</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建子项目</span><br><span class="line">git submodule add &lt;submodule_url&gt;  </span><br><span class="line"></span><br><span class="line">drwxr-xr-x 9 root root 4096 Feb 15 17:26 .git</span><br><span class="line">-rw-r--r-- 1 root root   67 Feb 15 17:25 .gitmodules</span><br><span class="line">drwxr-xr-x 2 root root 4096 Feb 15 17:25 md</span><br><span class="line">多了三个文件</span><br><span class="line">git add </span><br><span class="line">git commit -m &#x27;add sub module &#x27; </span><br><span class="line"></span><br><span class="line"># 获取子项目代码</span><br><span class="line">pull  --recurse-submodules</span><br><span class="line">#</span><br><span class="line">git submodule init</span><br><span class="line">git submodule update </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>项目-rancher多集群汇总展示</title>
    <url>/2021/12/20/2021-12-20-%E9%A1%B9%E7%9B%AE-rancher%E5%A4%9A%E9%9B%86%E7%BE%A4%E6%B1%87%E6%80%BB%E5%B1%95%E7%A4%BA/</url>
    <content><![CDATA[<h1 id="rancher多集群汇总展示"><a href="#rancher多集群汇总展示" class="headerlink" title="rancher多集群汇总展示"></a>rancher多集群汇总展示</h1><h2 id="1-需求"><a href="#1-需求" class="headerlink" title="1 需求"></a>1 需求</h2><p> rancher管理集群越来越多， 而rancher自己提供的可视化只能提供单个集群的状态可视化，集群过多时，看起来过于麻烦，如何快速把握所有集群的状态呢？我们想做一个集群汇总的可视化，可以看到 所有集群或者重点集群的信息汇总，如果总的cpu, 储存，pod数等。组件状态等。</p>
<h2 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2 解决方案"></a>2 解决方案</h2><h4 id="1-rancher-api"><a href="#1-rancher-api" class="headerlink" title="1 rancher api"></a>1 rancher api</h4><p>通过Rancher提供的api，抓取所有集群的数据，导入到时序数据库,如influxDB，在通过grafana导入数据，展示数据。 </p>
<p><strong>问题</strong>:<br>1 rancher api数据为json格式， 数据项较多， 需要筛选，且木有找到类似的解决方法，重新造轮子，工作量较大。<br>2 依赖rancher稳定性，单节点rancher不太适用</p>
<p><strong>优势</strong><br>1 搭建好之后，后续的工作量可能较小，只要rancher导入rancher管理，那么就可以监控到。</p>
<h4 id="2-多prometheus-grafana"><a href="#2-多prometheus-grafana" class="headerlink" title="2 多prometheus+grafana"></a>2 多prometheus+grafana</h4><p>搭建1套独立的grafana，配置所有集群的prometheus数据源，load重点监控的json文件，例如overview，以集群为单位，进行展示。</p>
<p><strong>优势</strong><br>1 promethus，grafana是成熟的解决方法，做起来简单，<strong>工作重点</strong>在于不同数据源的数据如何汇总展示。<br>2 直接从集群获取数据，不依赖rancher的稳定性<br><strong>问题</strong><br>1 每个集群都需要额外部署服务，这样比较麻烦。</p>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h4 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h4><p>由于没有方案可以参考，需要选择数据库和可视化组件。<br>数据可选的有graphite, openTSDB, influxDB<br>可视化组件可选 grafana, dataV</p>
<p>rancher api 获得的数据是json格式， 如何存储json格式的数据，</p>
<p>学习了第一套架构。<br>Telegraf+InfluxDB+Grafana自动化运维<br>influxdb 用起来并不复查，用法跟sql差不多，解决了存储的问题。<br>现在的问题<br>1.怎么把rancher api 的数据导入数据库。<br>2。多设备监控如何汇总 </p>
<p>转存数据，学习数据结构含义， 以及数据查询都是问题。 </p>
<h4 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h4><p>经过实测，多个prometheus + influxdb + grafana ， 每个都是成熟的组件， 之间无缝连接。</p>
<p>现在依然存在的问题： </p>
<ol>
<li>  官方的exporter default 的collectors太多了，有很多我们需要的数据。  </li>
</ol>
<p>解决， node exporter的github上面看到可以配置不需要的collectors.  如下：</p>
<h3 id="Filtering-enabled-collectors"><a href="#Filtering-enabled-collectors" class="headerlink" title="Filtering enabled collectors"></a>Filtering enabled collectors</h3><p>The <code>node_exporter</code> will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.</p>
<p>For advanced use the <code>node_exporter</code> can be passed an optional list of collectors to filter metrics. The <code>collect[]</code> parameter may be used multiple times. In Prometheus configuration you can use this syntax under the <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#">scrape config</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">params:</span><br><span class="line">  collect[]:</span><br><span class="line">    - foo</span><br><span class="line">    - bar</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>  每个集群都配置一套prometheus，会极大增加集群负担。 看看能不能只部署expoter, 理论上是可以的，还没有尝试。</li>
</ol>
<p>   解决： 可以， exporter 暴露http接口， prometheus抓取数据。    </p>
<ol start="3">
<li> 每个数据中心自定义标签问题，否则无法安装集群来展示。</li>
</ol>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h2><p>1.网络<br>2..存储<br>3.主机数<br>4pod数<br>sum(kubelet_running_pod_count{}) </p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>vscode--XHR failed</title>
    <url>/2021/12/27/2021-12-27-vscode--XHR-failed/</url>
    <content><![CDATA[<p>问题： vscode 安装拓展失败， 报错<code> XHR failed</code></p>
<p>查了一通，是公司网络的原因， 另一台机器切换网络就可以了。 有一台机器网络固定的。</p>
<p>既然直接装不了，也可以离线装。 </p>
<ol>
<li>先到拓展仓库下载 </li>
</ol>
<p><a href="https://marketplace.visualstudio.com/vscode">https://marketplace.visualstudio.com/vscode</a></p>
<ol start="2">
<li><p>extensions 更多选择从VSIX安装</p>
<p>要注意选择版本</p>
</li>
</ol>
<p>解决！</p>
]]></content>
  </entry>
  <entry>
    <title>python中函数默认值参数的一个&quot;bug&quot;</title>
    <url>/2021/12/29/2021-12-29-python%E4%B8%AD%E5%87%BD%E6%95%B0%E9%BB%98%E8%AE%A4%E5%80%BC%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E4%B8%AAbug/</url>
    <content><![CDATA[<p>python定义函数时默认值参数可能会出现不符合我们的情况。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add_to(x, target=[1]):</span><br><span class="line">    target.append(x)</span><br><span class="line">    return target</span><br><span class="line"></span><br><span class="line">print(add_to(2))</span><br><span class="line">print(add_to(3))</span><br><span class="line"></span><br><span class="line"># 这里预期应该是：</span><br><span class="line">[1, 2]</span><br><span class="line">[1, 3]</span><br><span class="line"></span><br><span class="line"># 而实际返回：</span><br><span class="line">[1, 2]</span><br><span class="line">[1, 2, 3]</span><br></pre></td></tr></table></figure>

<p>也就是第一次调用add_to函数初始化的target变量，再重新调用函数的时候保留了， 再次调用的时候target这个变量在函数空间已经存在了，只要与default的值类型相同，那么target=[1]这个默认值就不会重新初始化。  类型不同的会重新初始化。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add_to(x, target=&#123;1&#125;):</span><br><span class="line">    if  target ==&#123;1&#125;: # 若空</span><br><span class="line">        target = [1]</span><br><span class="line">    target.append(x)</span><br><span class="line">    return target</span><br><span class="line"></span><br><span class="line">print(add_to(2))</span><br><span class="line">print(add_to(3))</span><br><span class="line"></span><br><span class="line"># 返回</span><br><span class="line">[1, 2]</span><br><span class="line">[1, 3]</span><br></pre></td></tr></table></figure>

<p>也就是说default参数在非首次调用只起到类型检查的作用。</p>
<p>想要每次都重新运算，稳妥点可以这么写：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add_to(x, target=None):</span><br><span class="line">    if target is None:</span><br><span class="line">        target = [1]</span><br><span class="line">    target.append(x)</span><br><span class="line">    return target</span><br><span class="line"></span><br><span class="line">print(add_to(2))</span><br><span class="line">print(add_to(3))</span><br><span class="line"></span><br><span class="line"># 返回</span><br><span class="line">[1, 2]</span><br><span class="line">[1, 3]</span><br></pre></td></tr></table></figure>

<p>None和所有类型都不同，可保证每次都重新赋值。 </p>
<p>由于python是基于值的内存管理， target若是不可变类型， 那么改变它就会指向另一个值，也会重新初始化。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add_to(x, target=1):</span><br><span class="line">    print(id(target))</span><br><span class="line">    target = x + target</span><br><span class="line">    print(id(target))</span><br><span class="line">    return target</span><br><span class="line">    </span><br><span class="line">print(add_to(1))</span><br><span class="line">print(add_to(2))</span><br><span class="line"># 返回</span><br><span class="line">140716483181632</span><br><span class="line">140716483181664</span><br><span class="line">2</span><br><span class="line">140716483181632</span><br><span class="line">140716483181696</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>tornado</title>
    <url>/2021/12/29/2021-12-29-tornado/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>harbor api</title>
    <url>/2021/12/30/2021-12-30-harbor-api/</url>
    <content><![CDATA[<p>curl -k -u “admin:Harbor12345”  -X  ‘GET’   ‘<a href="https://81.68.101.212/api/v2.0/systeminfo/volumes&#39;">https://81.68.101.212/api/v2.0/systeminfo/volumes&#39;</a> </p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>linux源码获取</title>
    <url>/2022/01/12/2022-01-12-linux%E6%BA%90%E7%A0%81%E8%8E%B7%E5%8F%96/</url>
    <content><![CDATA[<p>如何获取linux源码？ </p>
<p>直接到<a href="https://vault.centos.org找,网上说的方法(通过yumdownloader下载source包)根本下不到./">https://vault.centos.org找，网上说的方法(通过yumdownloader下载source包)根本下不到。</a></p>
<p>带src.rpm的就是相应的源码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#下载到的是一个安装包文件rpm，能够使用例如以下的命令查询rpm中的tar文件：</span><br><span class="line"></span><br><span class="line">rpm -qpl coreutils-8.4-37.el6.src.rpm | grep tar</span><br><span class="line"></span><br><span class="line">\# 输出：coreutils-8.4.tar.xz</span><br><span class="line"></span><br><span class="line">6）使用rpm2cpio命令将rpm包文件转换成cpio归档文件，再使用cpio命令，从cpio归档文件复制提取出一个归档文件。出例如以下：</span><br><span class="line"></span><br><span class="line">rpm2cpio coreutils-8.4-37.el6.src.rpm | cpio -idv coreutils-8.4.tar.xz</span><br><span class="line"></span><br><span class="line">\# 输出：</span><br><span class="line"></span><br><span class="line">\# coreutils-8.4.tar.xz</span><br><span class="line"></span><br><span class="line">\# 9561 blocks</span><br><span class="line"></span><br><span class="line">cpio的man解释为：cpio copies files into an archive</span><br><span class="line"></span><br><span class="line">-i：与--extract等同。提取之意</span><br><span class="line"></span><br><span class="line">-d：与--make-directories等同，当有须要时创建一个载入文件夹</span><br><span class="line"></span><br><span class="line">-v：列出文件的处理过程</span><br><span class="line"></span><br><span class="line">7）使用tar命令对coreutils-8.4.tar.xz压缩包进行解压缩，例如以下：</span><br><span class="line"></span><br><span class="line">tar -xvf ./coreutils-8.4.tar.xz</span><br><span class="line"></span><br><span class="line">至此，命令的源码获取完毕。</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>git clone github仓库，网络可通，但无法下载的问题</title>
    <url>/2022/01/14/2022-01-14-git-clone-github%E4%BB%93%E5%BA%93%EF%BC%8C%E7%BD%91%E7%BB%9C%E5%8F%AF%E9%80%9A%EF%BC%8C%E4%BD%86%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BD%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>有时把地址https 改为git可解决</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-15-centos ~]# git clone https://github.com/sorintlab/stolon.git</span><br><span class="line">Cloning into &#x27;stolon&#x27;...</span><br><span class="line">^C</span><br><span class="line">[root@VM-4-15-centos ~]# git clone git://github.com/sorintlab/stolon.git</span><br><span class="line">Cloning into &#x27;stolon&#x27;...</span><br><span class="line">remote: Enumerating objects: 9244, done.</span><br><span class="line">remote: Counting objects: 100% (47/47), done.</span><br><span class="line">remote: Compressing objects: 100% (38/38), done.</span><br><span class="line">remote: Total 9244 (delta 12), reused 19 (delta 6), pack-reused 9197</span><br><span class="line">Receiving objects: 100% (9244/9244), 9.29 MiB | 221.00 KiB/s, done.</span><br><span class="line">Resolving deltas: 100% (4346/4346), done.</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>harbor主从复制无法访问需要修改hsots</title>
    <url>/2022/01/14/2022-01-14-harbor%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9hsots/</url>
    <content><![CDATA[<p>问题：设定主从复制时， 目标url可能联系不到。 </p>
<p>问题分析： A仓库从ip访问不到B仓库，需要在B仓库添加解析。 之后可通过域名访问</p>
<p>解决： harbor-core  harbor-jobservice容器中添加DNS记录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /etc/hosts</span><br><span class="line">81.68.101.212 yourdomain.com</span><br><span class="line"># B仓库域名 ip</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>helm3安装</title>
    <url>/2022/01/14/2022-01-14-helm3%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>helm3安装</p>
<h3 id="二进制"><a href="#二进制" class="headerlink" title="二进制"></a>二进制</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 下载 </span><br><span class="line">wget https://get.helm.sh/helm-v3.5.3-linux-amd64.tar.gz -O /opt</span><br><span class="line"># 解压</span><br><span class="line">tar zxf helm-v3.5.3-linux-amd64.tar.gz</span><br><span class="line"># 转存</span><br><span class="line">cp -pr linux-amd64/helm /usr/local/bin/</span><br><span class="line"># 测试 </span><br><span class="line">helm --help </span><br></pre></td></tr></table></figure>

<h3 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>systax linux</title>
    <url>/2022/01/14/2022-01-14-systax-linux/</url>
    <content><![CDATA[<ol>
<li> cp 拷贝</li>
<li> alias 别名</li>
<li>apropos  </li>
<li>ar 打包</li>
<li>arch 显示主机硬件架构类型</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@nginx ~]# arch --version </span><br><span class="line">arch (GNU coreutils) 8.22</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>arp 命令用于显示和修改 IP 到 MAC 转换表 </li>
<li>at 定时任务  atq  atrm</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>mongodb</title>
    <url>/2022/01/17/2022-01-17-mongodb/</url>
    <content><![CDATA[<h3 id="1-docker-部署"><a href="#1-docker-部署" class="headerlink" title="1 docker 部署"></a>1 docker 部署</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull mongo </span><br><span class="line"># 本地数据文件</span><br><span class="line">mkdir /data/mongodb0 </span><br><span class="line">docker run --name mongodb -v /data/mongodb0:/data/db -p 27017:27017 -d mongo --auth</span><br><span class="line"></span><br><span class="line">#  挂载 </span><br><span class="line"># 端口映射 </span><br><span class="line"># 授权 </span><br></pre></td></tr></table></figure>

<h3 id="2-控制"><a href="#2-控制" class="headerlink" title="2  控制"></a>2  控制</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 进入容器 </span><br><span class="line">docker exec -it  mongodb bash </span><br><span class="line"># 进入mongodb </span><br><span class="line">mongo </span><br><span class="line"># 添加用户</span><br><span class="line">db.createUser(&#123; user: &#x27;root&#x27;, pwd: &#x27;root123&#x27;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;test&quot; &#125; ] &#125;); </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>mongodb 用户权限</p>
<p>数据库用户角色：read、readWrite;<br>数据库管理角色：dbAdmin、dbOwner、userAdmin；<br>集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager；<br>备份恢复角色：backup、restore；<br>所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase<br>超级用户角色：root // 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase）<br>内部角色：__system</p>
</blockquote>
<blockquote>
<p>角色说明</p>
<p>Read：允许用户读取指定数据库<br>readWrite：允许用户读写指定数据库<br>dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile<br>userAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户<br>clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。<br>readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限<br>readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限<br>userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限<br>dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。<br>root：只在admin数据库中可用。超级账号，超级权限</p>
</blockquote>
<h3 id="3-mongodb命令"><a href="#3-mongodb命令" class="headerlink" title="3 mongodb命令"></a>3 mongodb命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 数据库列表 </span><br><span class="line">&gt; show dbs </span><br><span class="line">admin   0.000GB</span><br><span class="line">config  0.000GB</span><br><span class="line">local   0.000GB</span><br><span class="line">test    0.000GB</span><br><span class="line"></span><br><span class="line"># 删除数据库</span><br><span class="line">db.dropDatabase()</span><br><span class="line"></span><br><span class="line"># 选择数据库, 没有则创建</span><br><span class="line">&gt; use test01 </span><br><span class="line">switched to db test01</span><br><span class="line"></span><br><span class="line"># 查看当前数据库</span><br><span class="line">&gt; db</span><br><span class="line">test01</span><br><span class="line"></span><br><span class="line"># 创建表</span><br><span class="line">&gt; db.createCollection(&quot;websites&quot;)</span><br><span class="line">&#123; &quot;ok&quot; : 1 &#125;</span><br><span class="line">&gt; db.createCollection(&quot;website&quot;)</span><br><span class="line">&#123; &quot;ok&quot; : 1 &#125;</span><br><span class="line"># 查看表 </span><br><span class="line">&gt; show tables </span><br><span class="line">website</span><br><span class="line">websites</span><br><span class="line"># 删除表</span><br><span class="line">&gt; db.websites.drop()</span><br><span class="line">true</span><br><span class="line"># 查看表 = show tables</span><br><span class="line">&gt;  show collections</span><br><span class="line">website</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 插入数据</span><br><span class="line">&gt; db.website.insert(&#123;&quot;web01&quot;:&quot;www.baidu.com&quot;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line"># 或者</span><br><span class="line">&gt; db.website.save(&#123;&quot;web02&quot;:&quot;www.bing.com&quot;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line"># 3.2 版本之后新增了 db.collection.insertOne() 和 db.collection.insertMany()。</span><br><span class="line">db.collection.insertOne() 用于向集合插入一个新文档，语法格式如下：</span><br><span class="line">db.collection.insertOne(</span><br><span class="line">   &lt;document&gt;,</span><br><span class="line">   &#123;</span><br><span class="line">      writeConcern: &lt;document&gt;</span><br><span class="line">   &#125;</span><br><span class="line">)</span><br><span class="line">db.collection.insertMany() 用于向集合插入一个多个文档，语法格式如下：</span><br><span class="line">db.collection.insertMany(</span><br><span class="line">   [ &lt;document 1&gt; , &lt;document 2&gt;, ... ],</span><br><span class="line">   &#123;</span><br><span class="line">      writeConcern: &lt;document&gt;,</span><br><span class="line">      ordered: &lt;boolean&gt;</span><br><span class="line">   &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># document：要写入的文档。</span><br><span class="line"># writeConcern：写入策略，默认为 1，即要求确认写操作，0 是不要求。</span><br><span class="line"># ordered：指定是否按顺序写入，默认 true，按顺序写入。</span><br><span class="line"></span><br><span class="line"># 查看表</span><br><span class="line">&gt; db.website.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;61e553bd1f4969ef76c0dad4&quot;), &quot;web01&quot; : &quot;www.baidu.com&quot; &#125;</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;61e553ee1f4969ef76c0dad5&quot;), &quot;web02&quot; : &quot;www.bing.com&quot; &#125;</span><br><span class="line"></span><br><span class="line"># 我们也可以将数据定义为一个变量，如下所示：</span><br><span class="line"></span><br><span class="line">&gt; document=(&#123;title: &#x27;MongoDB 教程&#x27;, </span><br><span class="line">    description: &#x27;MongoDB 是一个 Nosql 数据库&#x27;,</span><br><span class="line">    by: &#x27;菜鸟教程&#x27;,</span><br><span class="line">    url: &#x27;http://www.runoob.com&#x27;,</span><br><span class="line">    tags: [&#x27;mongodb&#x27;, &#x27;database&#x27;, &#x27;NoSQL&#x27;],</span><br><span class="line">    likes: 100</span><br><span class="line">&#125;);</span><br><span class="line">执行后显示结果如下：</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">        &quot;title&quot; : &quot;MongoDB 教程&quot;,</span><br><span class="line">        &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;,</span><br><span class="line">        &quot;by&quot; : &quot;菜鸟教程&quot;,</span><br><span class="line">        &quot;url&quot; : &quot;http://www.runoob.com&quot;,</span><br><span class="line">        &quot;tags&quot; : [</span><br><span class="line">                &quot;mongodb&quot;,</span><br><span class="line">                &quot;database&quot;,</span><br><span class="line">                &quot;NoSQL&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;likes&quot; : 100</span><br><span class="line">&#125;</span><br><span class="line">执行插入操作：</span><br><span class="line"></span><br><span class="line">&gt; db.col.insert(document)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line"># 更新文档内容</span><br><span class="line"># update() 方法用于更新已存在的文档。语法格式如下：</span><br><span class="line">db.collection.update(</span><br><span class="line">   &lt;query&gt;,</span><br><span class="line">   &lt;update&gt;,</span><br><span class="line">   &#123;</span><br><span class="line">     upsert: &lt;boolean&gt;,</span><br><span class="line">     multi: &lt;boolean&gt;,</span><br><span class="line">     writeConcern: &lt;document&gt;</span><br><span class="line">   &#125;</span><br><span class="line">)</span><br><span class="line"># 参数说明：</span><br><span class="line"># query : update的查询条件，类似sql update查询内where后面的。</span><br><span class="line"># update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的</span><br><span class="line"># upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插# 入。</span><br><span class="line"># multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录# 全部更新。</span><br><span class="line"># writeConcern :可选，抛出异常的级别。</span><br><span class="line"></span><br><span class="line">&gt; db.website.update(&#123;&quot;web01&quot; : &quot;www.baidu.com&quot;&#125;,&#123;$set: &#123;&quot;web01&quot; : &quot;www.baiduya.com&quot;&#125;&#125; )</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.website.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;61e553bd1f4969ef76c0dad4&quot;), &quot;web01&quot; : &quot;www.baiduya.com&quot; &#125;</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;61e553ee1f4969ef76c0dad5&quot;), &quot;web02&quot; : &quot;www.bing.com&quot; &#125;</span><br><span class="line"></span><br><span class="line">save() 方法</span><br><span class="line">save() 方法通过传入的文档来替换已有文档，_id 主键存在就更新，不存在就插入。语法格式如下：</span><br><span class="line"></span><br><span class="line">db.collection.save(</span><br><span class="line">   &lt;document&gt;,</span><br><span class="line">   &#123;</span><br><span class="line">     writeConcern: &lt;document&gt;</span><br><span class="line">   &#125;</span><br><span class="line">)</span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">document : 文档数据。</span><br><span class="line">writeConcern :可选，抛出异常的级别。</span><br><span class="line">实例</span><br><span class="line">以下实例中我们替换了 _id 为 56064f89ade2f21f36b03136 的文档数据：</span><br><span class="line"></span><br><span class="line">&gt;db.col.save(&#123;</span><br><span class="line">    &quot;_id&quot; : ObjectId(&quot;56064f89ade2f21f36b03136&quot;),</span><br><span class="line">    &quot;title&quot; : &quot;MongoDB&quot;,</span><br><span class="line">    &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;,</span><br><span class="line">    &quot;by&quot; : &quot;Runoob&quot;,</span><br><span class="line">    &quot;url&quot; : &quot;http://www.runoob.com&quot;,</span><br><span class="line">    &quot;tags&quot; : [</span><br><span class="line">            &quot;mongodb&quot;,</span><br><span class="line">            &quot;NoSQL&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;likes&quot; : 110</span><br><span class="line">&#125;)</span><br><span class="line">替换成功后，我们可以通过 find() 命令来查看替换后的数据</span><br><span class="line"></span><br><span class="line">&gt;db.col.find().pretty()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;56064f89ade2f21f36b03136&quot;),</span><br><span class="line">        &quot;title&quot; : &quot;MongoDB&quot;,</span><br><span class="line">        &quot;description&quot; : &quot;MongoDB 是一个 Nosql 数据库&quot;,</span><br><span class="line">        &quot;by&quot; : &quot;Runoob&quot;,</span><br><span class="line">        &quot;url&quot; : &quot;http://www.runoob.com&quot;,</span><br><span class="line">        &quot;tags&quot; : [</span><br><span class="line">                &quot;mongodb&quot;,</span><br><span class="line">                &quot;NoSQL&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;likes&quot; : 110</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-python-交互-pymongo"><a href="#4-python-交互-pymongo" class="headerlink" title="4 python 交互  pymongo"></a>4 python 交互  pymongo</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pymongo import MongoClient</span><br><span class="line"></span><br><span class="line">client = MongoClient(&quot;mongodb://1.117.61.155:27017&quot;)</span><br><span class="line"># client = MongoClient(host=&#x27;localhost&#x27;, port=27017)</span><br><span class="line"></span><br><span class="line">db = client[&quot;test01&quot;]</span><br><span class="line"></span><br><span class="line">col = db[&#x27;website&#x27;]</span><br><span class="line"></span><br><span class="line"># result = col.insert_one(&#123;&quot;web04&quot;:&quot;www.cnblogs.com&quot;&#125;)</span><br><span class="line"># print(result.inserted_id)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cursor = col.find() </span><br><span class="line"># cursor = col.find(&#123;&quot;web04&quot;:&quot;www.cnblogs.com&quot;&#125;) # 过滤查询 </span><br><span class="line">for doc in cursor: </span><br><span class="line">    print(doc)</span><br><span class="line"></span><br><span class="line"># result = col.update_one(</span><br><span class="line">#     &#123;&quot;web04&quot;:&quot;www.cnblogs.com&quot;&#125;,</span><br><span class="line">#     &#123;</span><br><span class="line">#         &quot;$set&quot;:  &#123;&quot;web04&quot;:&quot;www.cnblogs.cn&quot;&#125;,</span><br><span class="line">#         # &quot;$currentDate&quot;: &#123;&quot;lastModified&quot;: True&#125;</span><br><span class="line">#     &#125;</span><br><span class="line"># )</span><br><span class="line"># # 这个操作返回了一个UpdateResult对象。这个对象报告了符合条件的文档数目以及被修改的文档数目。</span><br><span class="line"># print(result.modified_count)</span><br><span class="line"></span><br><span class="line"># 删除文档</span><br><span class="line">result = col.delete_many(&#123;&quot;borough&quot;: &quot;Manhattan&quot;&#125;)</span><br><span class="line"></span><br><span class="line"># 删除表</span><br><span class="line">col.drop()</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>pika-rabbitmq</title>
    <url>/2022/01/17/2022-01-17-pika-rabbitmq/</url>
    <content><![CDATA[<h3 id="1-pika-简介"><a href="#1-pika-简介" class="headerlink" title="1 pika 简介"></a>1 pika 简介</h3><p><a href="https://www.bookstack.cn/read/RabbitMQ_into_Chinese/README.md">README - 《RabbitMQ 中文文档》 - 书栈网 · BookStack</a></p>
<p><a href="https://blog.csdn.net/o9109003234/article/details/115843165?ops_request_misc=%7B%22request_id%22:%22164246726616780271929962%22,%22scm%22:%2220140713.130102334..%22%7D&request_id=164246726616780271929962&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-3-115843165.first_rank_v2_pc_rank_v29&utm_term=rabbitmq&spm=1018.2226.3001.4187">(2条消息) 必知必会 RabbitMQ面试题 33道（附答案）_田维常-CSDN博客</a></p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>rabbitMQ</title>
    <url>/2022/01/17/2022-01-17-rabbitMQ/</url>
    <content><![CDATA[<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3>]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>centos 配置python3</title>
    <url>/2022/01/18/2022-01-18-centos-%E9%85%8D%E7%BD%AEpython3/</url>
    <content><![CDATA[<p>yum 准备</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># yum 准备 </span><br><span class="line"># 下载阿里源</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"># 生成缓存</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line"># yum 更新</span><br><span class="line">yum -y update </span><br><span class="line"># 拓展 </span><br><span class="line">yum -y install yum-utils </span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># centos开发工具</span><br><span class="line">yum -y groupinstall development</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 依赖</span><br><span class="line">yum -y install zlib-devel bzip2-devel openssl-devel openssl-static ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel lzma gcc</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 下载安装包</span><br><span class="line">cd /usr/local/src/</span><br><span class="line">wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar xvf Python-3.7.0.tar.xz</span><br><span class="line"># 重命名文件夹</span><br><span class="line">mv Python-3.7.0 python3</span><br><span class="line"># 进入到解压出的文件夹</span><br><span class="line">cd python3</span><br><span class="line"></span><br><span class="line"># 编译</span><br><span class="line">./configure --prefix=/usr/local/python3</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>k8s pod 网络策略network policy</title>
    <url>/2022/01/24/2022-01-24-k8s-pod-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5network-policy/</url>
    <content><![CDATA[<h3 id="1-什么是Network-Policy-？"><a href="#1-什么是Network-Policy-？" class="headerlink" title="1 什么是Network Policy ？"></a>1 什么是Network Policy ？</h3><p>Network Policy是k8s中的一种资源类型，它从属于namespace，用来配置pod<strong>网络隔离</strong>。 缩写为netpol。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# kubectl api-resources | grep NetworkPolicy</span><br><span class="line">globalnetworkpolicies     crd.projectcalico.org/v1   false   GlobalNetworkPolicy</span><br><span class="line">networkpolicies           crd.projectcalico.org/v1   true        NetworkPolicy</span><br><span class="line">networkpolicies   netpol  networking.k8s.io/v1       true        NetworkPolicy</span><br></pre></td></tr></table></figure>

<p>默认情况下，k8s集群中pod无论是节点内还是节点外都可以通信，或者说所有pod工作在同一跨节点网络，此网络一般是二层虚拟网络，称为pod网络。 </p>
<p>网络主要主要有两个方面： </p>
<ol>
<li>连通性， 实体之间能通过网络互通。 </li>
<li>隔离性， 由于安全、限流等问题，限制实体之间的互通。 </li>
</ol>
<p>Network Policy用于实现pod之间的隔离性。可用network plugin及是否支持Network Policy参考<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy">这里</a>。</p>
<h3 id="2-Network-Policy-内容"><a href="#2-Network-Policy-内容" class="headerlink" title="2 Network Policy 内容"></a>2 Network Policy 内容</h3><p>Network Policy既然k8s中的一种资源， 其Type Meta与object Meta与其他资源相同，Spec内容主要有两个部分：</p>
<ol>
<li> 标签选择器， 用于匹配需要添加规则的pod。 </li>
<li> 隔离策略， 就是网络流量进出pod的规则，采用的是白名单模式，符合规则的通过，不符合规则的拒绝。</li>
</ol>
<h3 id="3-spec如何配置"><a href="#3-spec如何配置" class="headerlink" title="3 spec如何配置?"></a>3 spec如何配置?</h3><h4 id="3-1-spec-podSelector"><a href="#3-1-spec-podSelector" class="headerlink" title="3.1 spec.podSelector"></a>3.1 spec.podSelector</h4><p>podSelector使用标签选择器来匹配需要限制出入的pod</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br></pre></td></tr></table></figure>

<ul>
<li>若matchLabels值为空，则匹配所在namespaces中所有pod. </li>
</ul>
<h4 id="3-2-spec-policyTypes"><a href="#3-2-spec-policyTypes" class="headerlink" title="3.2 spec.policyTypes"></a>3.2 spec.policyTypes</h4><p>网络限制规则有出入两种，policyType字段有两个字段可选：</p>
<ol>
<li>流量入pod规则， ingress</li>
<li>流量出pod规则， egress</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spec:</span><br><span class="line">  policyTypes：</span><br><span class="line">    -ingress </span><br><span class="line">    -egress </span><br></pre></td></tr></table></figure>

<ul>
<li> 选择即开启限制，如果没有配置字段spec.ingress与spec.egres，则<strong>默认禁止出或入</strong>。</li>
</ul>
<h4 id="3-3-spec-ingress"><a href="#3-3-spec-ingress" class="headerlink" title="3.3 spec.ingress"></a>3.3 spec.ingress</h4><p>ingress定义入pod流量规则，白名单模式，有四种：</p>
<ol>
<li> namespaces</li>
<li> pod</li>
<li> port</li>
<li> CIDR</li>
</ol>
<h5 id="3-3-1-namespaceSelector即开启哪些命名空间下的pod的访问白名单"><a href="#3-3-1-namespaceSelector即开启哪些命名空间下的pod的访问白名单" class="headerlink" title="3.3.1 namespaceSelector即开启哪些命名空间下的pod的访问白名单"></a>3.3.1 namespaceSelector即开启哪些命名空间下的pod的访问白名单</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spec: </span><br><span class="line">  ingress : </span><br><span class="line">  - from: </span><br><span class="line">    namespaceSelector: </span><br><span class="line">    	matchLables: </span><br><span class="line">          testingress: true</span><br><span class="line"> # 带有标签 testingress=true 的ns可以访问</span><br></pre></td></tr></table></figure>

<p>测试： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在default空间下创建一个pod nginx </span><br><span class="line">[root@node ~]# kubectl run --image=nginx nginx-one </span><br><span class="line">pod/nginx-one created</span><br><span class="line"></span><br><span class="line"># 新建一个测试的namespace</span><br><span class="line">[root@node ~]# kubectl create ns test1 </span><br><span class="line">namespace/test1 created</span><br><span class="line"></span><br><span class="line"># 在测试ns中新建pod nginx-test1</span><br><span class="line">[root@node ~]# kubectl run --image=nginx nginx-test1 --namespace=test1 </span><br><span class="line">pod/nginx-test1 created</span><br><span class="line"></span><br><span class="line"># 查看</span><br><span class="line">[root@node ~]# kubectl  get po --all-namespaces -o wide  | grep nginx</span><br><span class="line">default         nginx-one                                 1/1     Running     0          7m38s   10.42.0.11     10.206.16.17   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">test1           nginx-test1                               1/1     Running     0          3m27s   10.42.0.12     10.206.16.17   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"># 未限制之前， nginx-test1与nginx-one网络通</span><br><span class="line">[root@node ~]#  kubectl exec nginx-test1 -n test1 -- curl -I 10.42.0.11 | grep HTTP </span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line"></span><br><span class="line"># 新建netpolicy限制</span><br><span class="line">cat &gt;&gt; netpol_ingress_ns.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-ns</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx-one</span><br><span class="line">  policyTypes: </span><br><span class="line">    - Ingress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          testingress: &quot;true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl create -f netpol_ingress_ns.yml </span><br><span class="line">networkpolicy.networking.k8s.io/ingress-ns created</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl get netpol </span><br><span class="line">NAME         POD-SELECTOR    AGE</span><br><span class="line">ingress-ns   run=nginx-one   4m4s</span><br><span class="line"></span><br><span class="line"># 再测试网络,不通</span><br><span class="line">[root@node ~]# kubectl exec nginx-test1 -n test1 -- curl -I --connect-time 2 10.42.0.11 | grep HTTP </span><br><span class="line">curl: (28) Connection timed out after 2001 milliseconds</span><br><span class="line"></span><br><span class="line"># netpol通过标签匹配ns放开限制, 给test1加个标签</span><br><span class="line">[root@node ~]# kubectl label ns test1 testingress=true</span><br><span class="line">namespace/test1 labeled</span><br><span class="line"></span><br><span class="line"># 网络通了</span><br><span class="line">[root@node ~]#  kubectl exec nginx-test1 -n test1 -- curl -I --connect-time 2 10.42.0.11 | grep HTTP </span><br><span class="line">HTTP/1.1 200 OK</span><br></pre></td></tr></table></figure>

<h5 id="3-3-2-podSelector维度的限制测试"><a href="#3-3-2-podSelector维度的限制测试" class="headerlink" title="3.3.2 podSelector维度的限制测试"></a>3.3.2 podSelector维度的限制测试</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 删除ingress-ns， 新建另一个deploy </span><br><span class="line">[root@node ~]# kubectl create deploy nginx-two --image=nginx --replicas=2 </span><br><span class="line">deployment.apps/nginx-two create</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl get po </span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-one                    1/1     Running   0          15h</span><br><span class="line">nginx-two-6786cc87b4-7l9hh   1/1     Running   0          14h</span><br><span class="line">nginx-two-6786cc87b4-v96bx   1/1     Running   0          14h</span><br><span class="line"></span><br><span class="line"># 新建netpolicy限制</span><br><span class="line">cat &gt;&gt; netpol_ingress_pod.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-pod</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx-one</span><br><span class="line">  policyTypes: </span><br><span class="line">    - Ingress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">           testingress: &quot;true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 给其中一个pod添加标签</span><br><span class="line">[root@node ~]# kubectl label po nginx-two-6786cc87b4-7l9hh testingress=true </span><br><span class="line">pod/nginx-two-6786cc87b4-7l9hh labeled</span><br><span class="line"></span><br><span class="line"># 加入白名单的可以访问，另一个pod不通</span><br><span class="line">[root@node ~]#  kubectl exec    nginx-two-6786cc87b4-7l9hh  -- curl -I --connect-time 2 10.42.0.11 | grep HTTP </span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line"></span><br><span class="line">[root@node ~]#  kubectl exec  nginx-two-6786cc87b4-v96bx  -- curl -I --connect-time 2 10.42.0.11 | grep HTTP</span><br><span class="line">curl: (28) Connection timed out after 2001 milliseconds</span><br></pre></td></tr></table></figure>

<h5 id="3-3-3-端口维度的限制测试"><a href="#3-3-3-端口维度的限制测试" class="headerlink" title="3.3.3 端口维度的限制测试"></a>3.3.3 端口维度的限制测试</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建netpolicy限制, 放开80端口</span><br><span class="line">cat &gt; netpol_ingress_port.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-port</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx-one</span><br><span class="line">  policyTypes: </span><br><span class="line">    - Ingress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">           run: &quot;busybox&quot;</span><br><span class="line">    ports: </span><br><span class="line">    - protocol: TCP </span><br><span class="line">      port: 80</span><br><span class="line">EOF </span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl run busybox --rm -ti --image=busybox /bin/sh </span><br><span class="line">/ # telnet 10.42.0.11 80</span><br><span class="line">Connected to 10.42.0.11 </span><br></pre></td></tr></table></figure>

<h5 id="3-3-4-CIDR维度的限制测试"><a href="#3-3-4-CIDR维度的限制测试" class="headerlink" title="3.3.4  CIDR维度的限制测试"></a>3.3.4  CIDR维度的限制测试</h5><p>无类别域间路由（Classless Inter-Domain Routing、CIDR）是一个用于给用户分配IP地址以及在互联网上有效地路由IP数据包的对IP地址进行归类的方法。可以用CIDR指定一个ip段。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看</span><br><span class="line">[root@node ~]# kubectl get po -o wide </span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox                      1/1     Running   0          59m     10.42.1.13   10.206.16.15   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-one                    1/1     Running   0          17h     10.42.0.11   10.206.16.17   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-two-6786cc87b4-sl5jd   1/1     Running   0          9m12s   10.42.1.14   10.206.16.15   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-two-6786cc87b4-z66n5   1/1     Running   0          9m12s   10.42.0.15   10.206.16.17   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"># 让10.42.0.0/23段都能访问，除了10.42.0.15</span><br><span class="line"></span><br><span class="line"># 新建策略</span><br><span class="line">cat &gt;&gt; netpol_ingress_cidr.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-cidr</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx-one</span><br><span class="line">  policyTypes: </span><br><span class="line">    - Ingress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - ipBlock:</span><br><span class="line">        cidr: 10.42.0.0/23</span><br><span class="line">        except:</span><br><span class="line">        - 10.42.0.15/32</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl apply -f netpol_ingress_cidr.yml </span><br><span class="line">networkpolicy.networking.k8s.io/ingress-cidr created</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl exec   nginx-two-6786cc87b4-sl5jd    -- curl -I --connect-time 2 10.42.0.11 | grep HTTP </span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line"></span><br><span class="line">[root@node ~]# kubectl exec    nginx-two-6786cc87b4-z66n5   -- curl -I --connect-time 2 10.42.0.11 | grep HTTP </span><br><span class="line">curl: (28) Connection timed out after 2001 milliseconds</span><br><span class="line">command terminated with exit code 28</span><br></pre></td></tr></table></figure>

<blockquote>
<p>egress配置策略与ingress类似</p>
</blockquote>
<p>附录： 一个完整的networkpolicy.yml</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: network-policy</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: nginx-one</span><br><span class="line">  policyTypes:</span><br><span class="line">  - Ingress</span><br><span class="line">  - Egress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - ipBlock:</span><br><span class="line">        cidr: 10.42.0.0/23</span><br><span class="line">        except:</span><br><span class="line">        - 10.42.0.15/32</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          testingress: true</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          role: frontend</span><br><span class="line">    ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">  egress:</span><br><span class="line">  - to:</span><br><span class="line">    - ipBlock:</span><br><span class="line">        cidr: 10.0.0.0/24</span><br><span class="line">    ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>python shutil</title>
    <url>/2022/01/25/2022-01-25-python-shutil/</url>
    <content><![CDATA[<h3 id="1-what-does-shutil-do"><a href="#1-what-does-shutil-do" class="headerlink" title="1 what does shutil do?"></a>1 what does shutil do?</h3><p>shutil模块提供了一系列对文件和文件集合的高阶操作。 特别是提供了一些支持文件拷贝和删除的函数</p>
<h3 id="2-用法"><a href="#2-用法" class="headerlink" title="2 用法"></a>2 用法</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import shutil</span><br><span class="line"># 拷贝内容</span><br><span class="line">shutil.copyfileobj(open(&#x27;old.txt&#x27;,&#x27;r&#x27;), open(&#x27;new.txt&#x27;, &#x27;w&#x27;))</span><br><span class="line"></span><br><span class="line"># 拷贝文件内容，与上面的区别是不需要打开</span><br><span class="line">shutil.copyfile(&#x27;old.txt&#x27;, &#x27;new.txt&#x27;)</span><br><span class="line"></span><br><span class="line"># 拷贝权限，仅拷贝权限。内容、组、用户均不变</span><br><span class="line">shutil.copymode(&#x27;f1.log&#x27;, &#x27;f2.log&#x27;) #目标文件必须存在。 </span><br><span class="line"></span><br><span class="line"># 拷贝状态，仅拷贝状态的信息，包括：mode bits, atime, mtime, flags</span><br><span class="line"># ctime不拷贝</span><br><span class="line">shutil.copystat(&#x27;f1.log&#x27;, &#x27;f2.log&#x27;) #目标文件必须存在</span><br><span class="line">    # 对于linux中的文件或者目录中有3个时间，分别是：atime、ctime、mtime.</span><br><span class="line">    # atime:Access time，最后一次访问文件（读取或执行）的时间。</span><br><span class="line">    # citme:Change time，最后一次改变文件（属性）或者目录（属性）的时间。</span><br><span class="line">    # mtime:Modify time,最后一次改变文件（内容）或目录（内容）的时间。</span><br><span class="line"># [root@nginx shutiltest]# stat f1.txt </span><br><span class="line">#   File: ‘f1.txt’</span><br><span class="line">#   Size: 23        	Blocks: 8          IO Block: 4096   regular file</span><br><span class="line"># Device: fd01h/64769d	Inode: 536206      Links: 1</span><br><span class="line"># Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line"># Access: 2022-01-25 16:54:57.450843315 +0800</span><br><span class="line"># Modify: 2022-01-25 16:54:14.193587451 +0800</span><br><span class="line"># Change: 2022-01-25 16:54:14.196587469 +0800</span><br><span class="line">#  Birth: -</span><br><span class="line"></span><br><span class="line">#拷贝文件和权限</span><br><span class="line">shutil.copy(&#x27;f1.log&#x27;, &#x27;f2.log&#x27;)</span><br><span class="line"></span><br><span class="line"># 拷贝文件和状态信息 </span><br><span class="line">shutil.copy2(&#x27;f1.log&#x27;, &#x27;f2.log&#x27;)</span><br><span class="line"></span><br><span class="line"># 递归拷贝 目录</span><br><span class="line">shutil.copytree(&#x27;f1.log&#x27;, &#x27;f2.log&#x27;, symlinks=False, ignore=None)</span><br><span class="line"></span><br><span class="line"># 递归删除文件</span><br><span class="line">shutil.rmtree(&#x27;dir&#x27;)</span><br><span class="line"></span><br><span class="line"># mv </span><br><span class="line">shutil.move(src, dst)</span><br><span class="line"></span><br><span class="line"># 压缩</span><br><span class="line">shutil.make_archive(base_name, format,...)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>podsecuritypolicy--seccomp</title>
    <url>/2022/01/26/2022-01-26-psp--seccomp/</url>
    <content><![CDATA[<h3 id="1-seccomp-test-genxing"><a href="#1-seccomp-test-genxing" class="headerlink" title="1 seccomp test genxing"></a>1 seccomp test genxing</h3><p>seccomp（securecomputing mode）是linuxkernel从2.6.23版本开始所支持的一种安全机制。</p>
<p>在Linux系统里，大量的系统调用（systemcall）直接暴露给用户态程序。但是，并不是所有的系统调用都被需要，而且不安全的代码滥用系统调用会对系统造成安全威胁。通过seccomp，我们限制程序使用某些系统调用，这样可以减少系统的暴露面，同时是程序进入一种“安全”的状态。   该模式下的进程只能调用4种系统调用（system call），即 read(), write(), exit() 和 sigreturn()，否则进程便会被终止。</p>
<p>默认配置方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node101 ~]# kubectl get psp default-psp -o yaml </span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: &#x27;*&#x27;</span><br><span class="line">  creationTimestamp: &quot;2022-01-26T08:29:11Z&quot;</span><br><span class="line">  name: default-psp</span><br><span class="line">  resourceVersion: &quot;29900&quot;</span><br><span class="line">  selfLink: /apis/policy/v1beta1/podsecuritypolicies/default-psp</span><br><span class="line">  uid: 09f4fef4-74a7-43a9-9b8c-49dabbbb249e</span><br><span class="line">spec:</span><br><span class="line">  allowPrivilegeEscalation: true</span><br><span class="line">  allowedCapabilities:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  hostIPC: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPID: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - max: 65535</span><br><span class="line">    min: 0</span><br><span class="line">  privileged: true</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  volumes:</span><br><span class="line">  - &#x27;*&#x27;</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rke config --list-version --all</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; violation-pod.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: violation-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: violation-pod</span><br><span class="line">spec:</span><br><span class="line">  securityContext:</span><br><span class="line">    seccompProfile:</span><br><span class="line">      type: Localhost</span><br><span class="line">      localhostProfile: profiles/violation.json</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; violation-pod.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: violation-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: violation-pod</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/violation.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; audit-pod,yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: audit-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: audit-pod</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/audit.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: audit-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: audit-pod</span><br><span class="line">spec:</span><br><span class="line">  serviceAccountName: sa-seccomp</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">任意新建的sa  sa-seccomp 都可以创建pod </span><br><span class="line">那么肯定是某个crb绑定了所有认证的sa </span><br><span class="line">查看 crb s </span><br><span class="line">------------------------------clusterrolebindings 8-------------------------</span><br><span class="line">------------------------------system:basic-user-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:basic-user</span><br><span class="line">  resourceVersion: &quot;95&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Abasic-user</span><br><span class="line">  uid: 75d524ac-7876-4cfb-9413-3228e036b5d0</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:basic-user</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">其指向   kind: ClusterRole   name: system:basic-user</span><br><span class="line">其权限 </span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - authorization.k8s.io</span><br><span class="line">  resources:</span><br><span class="line">  - selfsubjectaccessreviews</span><br><span class="line">  - selfsubjectrulesreviews</span><br><span class="line">  verbs:</span><br><span class="line">  - create</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">------------------------------clusterrolebindings 37-------------------------</span><br><span class="line">------------------------------system:discovery-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:discovery</span><br><span class="line">  resourceVersion: &quot;94&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Adiscovery</span><br><span class="line">  uid: 4efe767c-2b60-4055-a7b5-52df76fe3633</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:discovery</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">其指向   kind: ClusterRole name: system:discovery</span><br><span class="line">其权限</span><br><span class="line">rules:</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - /api</span><br><span class="line">  - /api/*</span><br><span class="line">  - /apis</span><br><span class="line">  - /apis/*</span><br><span class="line">  - /healthz</span><br><span class="line">  - /livez</span><br><span class="line">  - /openapi</span><br><span class="line">  - /openapi/*</span><br><span class="line">  - /readyz</span><br><span class="line">  - /version</span><br><span class="line">  - /version/</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">------------------------------system:public-info-viewer-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:public-info-viewer</span><br><span class="line">  resourceVersion: &quot;96&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Apublic-info-viewer</span><br><span class="line">  uid: cb28ed46-27e9-40aa-9865-599791ef5ede</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:public-info-viewer</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:unauthenticated</span><br><span class="line"></span><br><span class="line">其指向   kind: ClusterRole name: system:public-info-viewer</span><br><span class="line">其权限   rules:</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - /healthz</span><br><span class="line">  - /livez</span><br><span class="line">  - /readyz</span><br><span class="line">  - /version</span><br><span class="line">  - /version/</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br></pre></td></tr></table></figure>





<p>实际上， admin用户拥有全部权限， 搞不清楚 </p>
<p>最好新建用户测试psp </p>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<h1 id="224a31b93706e3592cb8961318638e3dca071f41"><a href="#224a31b93706e3592cb8961318638e3dca071f41" class="headerlink" title="224a31b93706e3592cb8961318638e3dca071f41"></a>224a31b93706e3592cb8961318638e3dca071f41</h1></blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<hr>
<p>title: podsecuritypolicy–seccomp<br>date: 2022-01-26<br>categories: k8s    </p>
<hr>
<h3 id="1-seccomp-test-genxing-1"><a href="#1-seccomp-test-genxing-1" class="headerlink" title="1 seccomp test genxing"></a>1 seccomp test genxing</h3><p>seccomp（securecomputing mode）是linuxkernel从2.6.23版本开始所支持的一种安全机制。</p>
<p>在Linux系统里，大量的系统调用（systemcall）直接暴露给用户态程序。但是，并不是所有的系统调用都被需要，而且不安全的代码滥用系统调用会对系统造成安全威胁。通过seccomp，我们限制程序使用某些系统调用，这样可以减少系统的暴露面，同时是程序进入一种“安全”的状态。   该模式下的进程只能调用4种系统调用（system call），即 read(), write(), exit() 和 sigreturn()，否则进程便会被终止。</p>
<p>默认配置方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node101 ~]# kubectl get psp default-psp -o yaml </span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: &#x27;*&#x27;</span><br><span class="line">  creationTimestamp: &quot;2022-01-26T08:29:11Z&quot;</span><br><span class="line">  name: default-psp</span><br><span class="line">  resourceVersion: &quot;29900&quot;</span><br><span class="line">  selfLink: /apis/policy/v1beta1/podsecuritypolicies/default-psp</span><br><span class="line">  uid: 09f4fef4-74a7-43a9-9b8c-49dabbbb249e</span><br><span class="line">spec:</span><br><span class="line">  allowPrivilegeEscalation: true</span><br><span class="line">  allowedCapabilities:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  hostIPC: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPID: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - max: 65535</span><br><span class="line">    min: 0</span><br><span class="line">  privileged: true</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  volumes:</span><br><span class="line">  - &#x27;*&#x27;</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rke config --list-version --all</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; violation-pod.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: violation-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: violation-pod</span><br><span class="line">spec:</span><br><span class="line">  securityContext:</span><br><span class="line">    seccompProfile:</span><br><span class="line">      type: Localhost</span><br><span class="line">      localhostProfile: profiles/violation.json</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; violation-pod.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: violation-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: violation-pod</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/violation.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; audit-pod,yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: audit-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: audit-pod</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/audit.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: audit-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: audit-pod</span><br><span class="line">spec:</span><br><span class="line">  serviceAccountName: sa-seccomp</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">任意新建的sa  sa-seccomp 都可以创建pod </span><br><span class="line">那么肯定是某个crb绑定了所有认证的sa </span><br><span class="line">查看 crb s </span><br><span class="line">------------------------------clusterrolebindings 8-------------------------</span><br><span class="line">------------------------------system:basic-user-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:basic-user</span><br><span class="line">  resourceVersion: &quot;95&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Abasic-user</span><br><span class="line">  uid: 75d524ac-7876-4cfb-9413-3228e036b5d0</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:basic-user</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">其指向   kind: ClusterRole   name: system:basic-user</span><br><span class="line">其权限 </span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - authorization.k8s.io</span><br><span class="line">  resources:</span><br><span class="line">  - selfsubjectaccessreviews</span><br><span class="line">  - selfsubjectrulesreviews</span><br><span class="line">  verbs:</span><br><span class="line">  - create</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">------------------------------clusterrolebindings 37-------------------------</span><br><span class="line">------------------------------system:discovery-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:discovery</span><br><span class="line">  resourceVersion: &quot;94&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Adiscovery</span><br><span class="line">  uid: 4efe767c-2b60-4055-a7b5-52df76fe3633</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:discovery</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">其指向   kind: ClusterRole name: system:discovery</span><br><span class="line">其权限</span><br><span class="line">rules:</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - /api</span><br><span class="line">  - /api/*</span><br><span class="line">  - /apis</span><br><span class="line">  - /apis/*</span><br><span class="line">  - /healthz</span><br><span class="line">  - /livez</span><br><span class="line">  - /openapi</span><br><span class="line">  - /openapi/*</span><br><span class="line">  - /readyz</span><br><span class="line">  - /version</span><br><span class="line">  - /version/</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">------------------------------system:public-info-viewer-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-02-04T01:34:21Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:public-info-viewer</span><br><span class="line">  resourceVersion: &quot;96&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system%3Apublic-info-viewer</span><br><span class="line">  uid: cb28ed46-27e9-40aa-9865-599791ef5ede</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:public-info-viewer</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:authenticated</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:unauthenticated</span><br><span class="line"></span><br><span class="line">其指向   kind: ClusterRole name: system:public-info-viewer</span><br><span class="line">其权限   rules:</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - /healthz</span><br><span class="line">  - /livez</span><br><span class="line">  - /readyz</span><br><span class="line">  - /version</span><br><span class="line">  - /version/</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br></pre></td></tr></table></figure>





<p>实际上， admin用户拥有全部权限， 搞不清楚 </p>
<p>最好新建用户测试psp </p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>k8s-rbac</title>
    <url>/2022/01/28/2022-01-28-k8s-rbac/</url>
    <content><![CDATA[<h3 id="1-rabc是什么？"><a href="#1-rabc是什么？" class="headerlink" title="1 rabc是什么？"></a>1 rabc是什么？</h3><p>K8s api 服务器可以配置使用一个授权插件来检查用户或sa是否有权限执行动作。</p>
<p>什么是动作？ </p>
<p>REST客户端发送get, post, put, delete和其他资源的HTTP请求到特定的url路径上，这些路径表示特定的REST资源，如pod, svs,secret等。  动作包含如下： </p>
<table>
<thead>
<tr>
<th>HTTP</th>
<th>单一资源动词</th>
<th>集合动词</th>
</tr>
</thead>
<tbody><tr>
<td>get, head</td>
<td>get、watch</td>
<td>list、watch</td>
</tr>
<tr>
<td>post</td>
<td>create</td>
<td>n/a</td>
</tr>
<tr>
<td>put</td>
<td>update</td>
<td>n/a</td>
</tr>
<tr>
<td>patch</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>delete</td>
<td>deletecollection</td>
</tr>
</tbody></table>
<blockquote>
<p>额外的动词use用于podsecurity policy资源</p>
</blockquote>
<p>资源可以通过<code>kubectl api-resources</code>查看, 当前 k8s 支持两类 API Groups：</p>
<ol>
<li>Core Groups（核心组）， 该分组也可以称之为 Legacy Groups，作为 k8s 最核心的 API ，其特点是没有组的概念，例如 “v1”，在资源对象的定义中表示为 “apiVersion: v1”，属于核心组的资源主要有pod， svc等等。</li>
</ol>
<blockquote>
<p>注意核心组没有组名，只有版本，所以apiGroups的值为空。</p>
</blockquote>
<ol start="2">
<li>具有分组信息的 API， 这种 API 接口以/apis/$GROUP_NAME/$VERSION URL 路径进行标识，在api-resources定义中表示为 “apiVersion: groupname/version”， 例如 “apiVersion: batch/v1”.</li>
</ol>
<h3 id="2-如何实现rbac"><a href="#2-如何实现rbac" class="headerlink" title="2 如何实现rbac?"></a>2 如何实现rbac?</h3><p>rbac授权通过两组四种资源来配置的： </p>
<ol>
<li> namespace级别的资源， role和rolebinding</li>
<li>集群级别的资源， clusterrole和clusterrolebinding</li>
</ol>
<p>前一种是ns级别的限制，另一种是全局的，cluster级别的限制。 </p>
<p>role和clusterrole声明一种角色，表明哪些<strong>动作</strong>可以在哪些<strong>资源</strong>上执行。</p>
<p>binding和clusterbinding声明哪些用户或者SA被授权这些角色。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node psptest]# kubectl api-resources | grep role</span><br><span class="line">clusterrolebindings                            rbac.authorization.k8s.io/v1      false        ClusterRoleBinding</span><br><span class="line">clusterroles                                   rbac.authorization.k8s.io/v1      false        ClusterRole</span><br><span class="line">rolebindings                                   rbac.authorization.k8s.io/v1      true         RoleBinding</span><br><span class="line">roles                                          rbac.authorization.k8s.io/v1      true         Role</span><br></pre></td></tr></table></figure>

<h3 id="3-测试"><a href="#3-测试" class="headerlink" title="3 测试"></a>3 测试</h3><h4 id="3-1-role与rolebinding"><a href="#3-1-role与rolebinding" class="headerlink" title="3.1 role与rolebinding"></a>3.1 role与rolebinding</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建一个测试ns ns-test01</span><br><span class="line">[root@node psptest]# kubectl create ns ns-test01</span><br><span class="line">namespace/ns-test01 created</span><br><span class="line"></span><br><span class="line"># 新建一个测试pod </span><br><span class="line">[root@node psptest]#  kubectl run test --image=luksa/kubectl-proxy -n ns-test01</span><br><span class="line">pod/test created</span><br><span class="line"></span><br><span class="line"># 集群启用rbac后，默认pod没有访问集群内资源的权限</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;Status&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    </span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot;: &quot;Failure&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;service is forbidden: User \&quot;system:serviceaccount:ns-test01:default\&quot; cannot list resource \&quot;service\&quot; in API group \&quot;\&quot; in the namespace \&quot;ns-test01\&quot;&quot;,</span><br><span class="line">  &quot;reason&quot;: &quot;Forbidden&quot;,</span><br><span class="line">  &quot;details&quot;: &#123;</span><br><span class="line">    &quot;kind&quot;: &quot;service&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;code&quot;: 403</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 确实不能访问，说明rbac生效了</span><br><span class="line"></span><br><span class="line"># 给定一个可get pod的role,并绑定到该ns的sa</span><br><span class="line">cat &gt;&gt; role-read-services.yml  &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: role-read-ns-services</span><br><span class="line">  namespace: ns-test01</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;, &#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;services&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#因为资源是多个， services必须是复数，否则不能访问</span><br><span class="line"># 可以通过resourceNames 限定具体的资源</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f role-read-services.yml </span><br><span class="line">role.rbac.authorization.k8s.io/role-read-ns-services created</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create rolebinding rbd-read-pod-sa --role=role-read-ns-services --serviceaccount=ns-test01:default -n ns-test01</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/rbd-read-pod-sa created</span><br><span class="line"></span><br><span class="line"># 再pod中再次访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;ServiceList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/namespaces/ns-test01/services&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;129667&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;items&quot;: []</span><br><span class="line"> </span><br><span class="line"># 说明rbac授权成功</span><br></pre></td></tr></table></figure>

<h4 id="3-2-clusterrole与clusterrolebinding"><a href="#3-2-clusterrole与clusterrolebinding" class="headerlink" title="3.2 clusterrole与clusterrolebinding"></a>3.2 clusterrole与clusterrolebinding</h4><p>clusterrole是集群级别资源， 它允许访问没有命名空间级别的资源或者非资源型的URL。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建clusterrole 可以访问集群级别资源node</span><br><span class="line">[root@node psptest]# cat &gt;&gt; clusterrole-node-reader.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">kind: ClusterRole </span><br><span class="line">metadata: </span><br><span class="line">  name: node-reader</span><br><span class="line">rules: </span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;,&#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;nodes&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f clusterrole-node-reader.yaml </span><br><span class="line">clusterrole.rbac.authorization.k8s.io/node-reader created</span><br><span class="line"></span><br><span class="line"># 新建clusterrolebinding  </span><br><span class="line">[root@node psptest]# kubectl create clusterrolebinding crb-node-read --clusterrole=node-reader --serviceaccount=ns-test01:default</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/crb-node-read created</span><br><span class="line"></span><br><span class="line"># 未绑定之前无法访问，绑定之后可以访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/nodes</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;NodeList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/nodes&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;144316&quot;</span><br><span class="line">    ---</span><br></pre></td></tr></table></figure>

<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<h1 id="224a31b93706e3592cb8961318638e3dca071f41"><a href="#224a31b93706e3592cb8961318638e3dca071f41" class="headerlink" title="224a31b93706e3592cb8961318638e3dca071f41"></a>224a31b93706e3592cb8961318638e3dca071f41</h1></blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<hr>
<p>title: k8s-rbac<br>date: 2022-01-28<br>categories: k8s</p>
<hr>
<h3 id="1-rabc是什么？-1"><a href="#1-rabc是什么？-1" class="headerlink" title="1 rabc是什么？"></a>1 rabc是什么？</h3><p>K8s api 服务器可以配置使用一个授权插件来检查用户或sa是否有权限执行动作。</p>
<p>什么是动作？ </p>
<p>REST客户端发送get, post, put, delete和其他资源的HTTP请求到特定的url路径上，这些路径表示特定的REST资源，如pod, svs,secret等。  动作包含如下： </p>
<table>
<thead>
<tr>
<th>HTTP</th>
<th>单一资源动词</th>
<th>集合动词</th>
</tr>
</thead>
<tbody><tr>
<td>get, head</td>
<td>get、watch</td>
<td>list、watch</td>
</tr>
<tr>
<td>post</td>
<td>create</td>
<td>n/a</td>
</tr>
<tr>
<td>put</td>
<td>update</td>
<td>n/a</td>
</tr>
<tr>
<td>patch</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>delete</td>
<td>deletecollection</td>
</tr>
</tbody></table>
<blockquote>
<p>额外的动词use用于podsecurity policy资源</p>
</blockquote>
<p>资源可以通过<code>kubectl api-resources</code>查看, 当前 k8s 支持两类 API Groups：</p>
<ol>
<li>Core Groups（核心组）， 该分组也可以称之为 Legacy Groups，作为 k8s 最核心的 API ，其特点是没有组的概念，例如 “v1”，在资源对象的定义中表示为 “apiVersion: v1”，属于核心组的资源主要有pod， svc等等。</li>
</ol>
<blockquote>
<p>注意核心组没有组名，只有版本，所以apiGroups的值为空。</p>
</blockquote>
<ol start="2">
<li>具有分组信息的 API， 这种 API 接口以/apis/$GROUP_NAME/$VERSION URL 路径进行标识，在api-resources定义中表示为 “apiVersion: groupname/version”， 例如 “apiVersion: batch/v1”.</li>
</ol>
<h3 id="2-如何实现rbac-1"><a href="#2-如何实现rbac-1" class="headerlink" title="2 如何实现rbac?"></a>2 如何实现rbac?</h3><p>rbac授权通过两组四种资源来配置的： </p>
<ol>
<li> namespace级别的资源， role和rolebinding</li>
<li>集群级别的资源， clusterrole和clusterrolebinding</li>
</ol>
<p>前一种是ns级别的限制，另一种是全局的，cluster级别的限制。 </p>
<p>role和clusterrole声明一种角色，表明哪些<strong>动作</strong>可以在哪些<strong>资源</strong>上执行。</p>
<p>binding和clusterbinding声明哪些用户或者SA被授权这些角色。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node psptest]# kubectl api-resources | grep role</span><br><span class="line">clusterrolebindings                            rbac.authorization.k8s.io/v1      false        ClusterRoleBinding</span><br><span class="line">clusterroles                                   rbac.authorization.k8s.io/v1      false        ClusterRole</span><br><span class="line">rolebindings                                   rbac.authorization.k8s.io/v1      true         RoleBinding</span><br><span class="line">roles                                          rbac.authorization.k8s.io/v1      true         Role</span><br></pre></td></tr></table></figure>

<h3 id="3-测试-1"><a href="#3-测试-1" class="headerlink" title="3 测试"></a>3 测试</h3><h4 id="3-1-role与rolebinding-1"><a href="#3-1-role与rolebinding-1" class="headerlink" title="3.1 role与rolebinding"></a>3.1 role与rolebinding</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建一个测试ns ns-test01</span><br><span class="line">[root@node psptest]# kubectl create ns ns-test01</span><br><span class="line">namespace/ns-test01 created</span><br><span class="line"></span><br><span class="line"># 新建一个测试pod </span><br><span class="line">[root@node psptest]#  kubectl run test --image=luksa/kubectl-proxy -n ns-test01</span><br><span class="line">pod/test created</span><br><span class="line"></span><br><span class="line"># 集群启用rbac后，默认pod没有访问集群内资源的权限</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;Status&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    </span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot;: &quot;Failure&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;service is forbidden: User \&quot;system:serviceaccount:ns-test01:default\&quot; cannot list resource \&quot;service\&quot; in API group \&quot;\&quot; in the namespace \&quot;ns-test01\&quot;&quot;,</span><br><span class="line">  &quot;reason&quot;: &quot;Forbidden&quot;,</span><br><span class="line">  &quot;details&quot;: &#123;</span><br><span class="line">    &quot;kind&quot;: &quot;service&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;code&quot;: 403</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 确实不能访问，说明rbac生效了</span><br><span class="line"></span><br><span class="line"># 给定一个可get pod的role,并绑定到该ns的sa</span><br><span class="line">cat &gt;&gt; role-read-services.yml  &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: role-read-ns-services</span><br><span class="line">  namespace: ns-test01</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;, &#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;services&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#因为资源是多个， services必须是复数，否则不能访问</span><br><span class="line"># 可以通过resourceNames 限定具体的资源</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f role-read-services.yml </span><br><span class="line">role.rbac.authorization.k8s.io/role-read-ns-services created</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create rolebinding rbd-read-pod-sa --role=role-read-ns-services --serviceaccount=ns-test01:default -n ns-test01</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/rbd-read-pod-sa created</span><br><span class="line"></span><br><span class="line"># 再pod中再次访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;ServiceList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/namespaces/ns-test01/services&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;129667&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;items&quot;: []</span><br><span class="line"> </span><br><span class="line"># 说明rbac授权成功</span><br></pre></td></tr></table></figure>

<h4 id="3-2-clusterrole与clusterrolebinding-1"><a href="#3-2-clusterrole与clusterrolebinding-1" class="headerlink" title="3.2 clusterrole与clusterrolebinding"></a>3.2 clusterrole与clusterrolebinding</h4><p>clusterrole是集群级别资源， 它允许访问没有命名空间级别的资源或者非资源型的URL。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建clusterrole 可以访问集群级别资源node</span><br><span class="line">[root@node psptest]# cat &gt;&gt; clusterrole-node-reader.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">kind: ClusterRole </span><br><span class="line">metadata: </span><br><span class="line">  name: node-reader</span><br><span class="line">rules: </span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;,&#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;nodes&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f clusterrole-node-reader.yaml </span><br><span class="line">clusterrole.rbac.authorization.k8s.io/node-reader created</span><br><span class="line"></span><br><span class="line"># 新建clusterrolebinding  </span><br><span class="line">[root@node psptest]# kubectl create clusterrolebinding crb-node-read --clusterrole=node-reader --serviceaccount=ns-test01:default</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/crb-node-read created</span><br><span class="line"></span><br><span class="line"># 未绑定之前无法访问，绑定之后可以访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/nodes</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;NodeList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/nodes&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;144316&quot;</span><br><span class="line">    ---</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>osp探索备忘</title>
    <url>/2022/01/31/2022-01-31-osp%E6%8E%A2%E7%B4%A2%E5%A4%87%E5%BF%98%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">osp当前可用配置</span><br><span class="line"></span><br><span class="line">宿主机ip ： 172.21.27.24 </span><br><span class="line"></span><br><span class="line">docker server, controller， rabbitmq, mongodb镜像</span><br><span class="line">[root@yubinbin3 ~]# docker images </span><br><span class="line">REPOSITORY                                 TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hub.komect.com:10443/sddc-cloud/cluster    v1.0.3              4c8531debc40        14 months ago       1.26GB</span><br><span class="line"></span><br><span class="line">rabbitmq                                   management          7601e834fa14        2 years ago         177MB</span><br><span class="line"></span><br><span class="line">mongo                                      latest              cdc6740b66a7        2 years ago         361MB</span><br><span class="line"></span><br><span class="line"># </span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 集群信息</span><br><span class="line">&#123;</span><br><span class="line">	&quot;_id&quot; : ObjectId(&quot;5f9fa5bd045fc259377b0d9b&quot;),</span><br><span class="line">	&quot;cluster_name&quot; : &quot;test-1604298173&quot;,</span><br><span class="line">	&quot;nodes&quot; : [</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;cluster_name&quot; : &quot;test-1604298173&quot;,</span><br><span class="line">			&quot;key_id&quot; : 6,</span><br><span class="line">			&quot;ldap&quot; : &quot;yubinbin&quot;,</span><br><span class="line">			&quot;type&quot; : &quot;master0&quot;,</span><br><span class="line">			&quot;GROUP_CONCAT(distinct ip_address)&quot; : &quot;172.21.27.229&quot;,</span><br><span class="line">			&quot;user&quot; : &quot;root&quot;,</span><br><span class="line">			&quot;password&quot; : &quot;4443aa24&quot;,</span><br><span class="line">			&quot;port&quot; : &quot;22&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	],</span><br><span class="line">	&quot;info&quot; : [</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;cluster_name&quot; : &quot;test-1604298173&quot;,</span><br><span class="line">			&quot;key_id&quot; : 6,</span><br><span class="line">			&quot;ldap&quot; : &quot;yubinbin&quot;,</span><br><span class="line">			&quot;type&quot; : &quot;master0&quot;,</span><br><span class="line">			&quot;GROUP_CONCAT(distinct ip_address)&quot; : &quot;172.21.27.229&quot;,</span><br><span class="line">			&quot;user&quot; : &quot;root&quot;,</span><br><span class="line">			&quot;password&quot; : &quot;4443aa24&quot;,</span><br><span class="line">			&quot;port&quot; : &quot;22&quot;</span><br><span class="line">		&#125;</span><br><span class="line">	],</span><br><span class="line">	&quot;id&quot; : 6</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试 扩容</span><br><span class="line">def test_cluster_expand(self):</span><br><span class="line">		data=&#123;&#x27;info&#x27;:[&#123;&quot;cluster_name&quot;:&quot;test6&quot;,&quot;key_id&quot;:6,&quot;ldap&quot;:&quot;yubinbin&quot;,</span><br><span class="line">					&quot;type&quot;:&quot;worker0&quot;,&quot;GROUP_CONCAT(distinct ip_address)&quot;:&quot;172.28.88.128&quot;,</span><br><span class="line">					&quot;user&quot;:&quot;root&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;port&quot;:&quot;22&quot;&#125;,],</span><br><span class="line">			 &#x27;method&#x27;:&#x27;expand&#x27;&#125;</span><br><span class="line">		url=self.baseurl+&quot;cluster/cluster/test6&quot;</span><br><span class="line">		requests.post(url,data=json.dumps(data))</span><br><span class="line"></span><br><span class="line"># 测试 创建集群</span><br><span class="line"></span><br><span class="line">def test_cluster_create(self):</span><br><span class="line">		url=self.baseurl+&quot;cluster/clusters&quot;</span><br><span class="line">		data=&#123;&#x27;info&#x27;:[&#123;&quot;cluster_name&quot;:&quot;test-      &quot;+str(int(time.time())),&quot;key_id&quot;:6,&quot;ldap&quot;:&quot;yubinbin&quot;,</span><br><span class="line">					&quot;type&quot;:&quot;master0&quot;,&quot;GROUP_CONCAT(distinct ip_address)&quot;:&quot;172.28.88.185&quot;,</span><br><span class="line">					&quot;user&quot;:&quot;root&quot;,&quot;password&quot;:&quot;123456&quot;,&quot;port&quot;:&quot;22&quot;&#125;],&quot;method&quot;:&quot;create&quot;&#125;</span><br><span class="line">		requests.post(url,data=json.dumps(data))</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建集群主路线</span><br><span class="line"># 用户： </span><br><span class="line">post请求 ip:8000/cluster/clusters  info-&gt;  # server/url</span><br><span class="line"></span><br><span class="line"># 生产端:</span><br><span class="line">路由到 class  ClusterManagerAPIView(APIView)  # server/view</span><br><span class="line"></span><br><span class="line">获取集群节点信息， 给到 ClusterManager().create(cluster_info,nodes)方法 # server/view</span><br><span class="line"></span><br><span class="line">调用class ClusterManager的方法: def create(self, cluster_info, node_infos):</span><br><span class="line">做两件事: </span><br><span class="line"></span><br><span class="line">1) 后端添加信息, self.backend.add(info)， 来自 ClusterModel()的方法# cluster/model </span><br><span class="line"></span><br><span class="line">2) 发送操作消息到队列 message_producer.send(message)</span><br><span class="line">来自 MessageSender.send(message)方法, 实际就是basic_publish(info)  #server/manager</span><br><span class="line"></span><br><span class="line"># 消费端： </span><br><span class="line">-&gt; class ClusterControllerMessagerConsumer(SelectConsumer)： # 负责接受消息</span><br><span class="line">#cluster/cluster_controller </span><br><span class="line"># 集群控制		self.controller=ClusterController()</span><br><span class="line"></span><br><span class="line"># 线程   		threading.Thread(target=self.controller.start).start()</span><br><span class="line">该线程回调函数为 self.controller.start， # 即执行的操作#cluster/cluster_controller  </span><br><span class="line"></span><br><span class="line">又调用 threading.Thread(target=self.run,args=(info,)).start()</span><br><span class="line">self.run即回调函数，真正创建集群的操作。</span><br><span class="line"></span><br><span class="line"># 开始进程</span><br><span class="line">process=multiprocessing.Process(target=self.create_cluster,args=(cluster_name,c_id,data))</span><br><span class="line"></span><br><span class="line">#调用ClusterController类create_cluster方法 #cluster/cluster_controller  </span><br><span class="line">target=self.create_cluster</span><br><span class="line"></span><br><span class="line"># 实例化cluster类  # cluster/cluster</span><br><span class="line">cluster=Cluster(cluster_name,c_id) </span><br><span class="line"></span><br><span class="line"># 调用cluster类create方法</span><br><span class="line">res=cluster.create(data)</span><br><span class="line">1) 调用负责集群环境配置ClusterConfig()类， .create()方法</span><br><span class="line">self.config.create(nodes) # 从节点信息中创建cluster.yml</span><br><span class="line"></span><br><span class="line">self.nodes=[Node(node_info,self.config) for node_info in  self.config.get_nodes()]# 实例化节点</span><br><span class="line"></span><br><span class="line">#这里会设置主节点</span><br><span class="line">for node in self.nodes:</span><br><span class="line">if node.is_admin:</span><br><span class="line">self.admin_node=node</span><br><span class="line"></span><br><span class="line">#这里是把集群所有的节点进行预处理</span><br><span class="line">self._prepare_nodes(self.nodes)</span><br><span class="line"></span><br><span class="line">#主节点进程和其他任务 准备，部署， 加入rancher， 加储存</span><br><span class="line">self.admin_node.prepare_cluster()</span><br><span class="line">self.admin_node.rke_up()</span><br><span class="line">self.admin_node.join_rancher(self.rancher_url)</span><br><span class="line">self.admin_node.create_default_storage_class(</span><br><span class="line"></span><br><span class="line"># 配置节点</span><br><span class="line">2) 调用rancher()类  # /cluster/rancher </span><br><span class="line">self.rancher.create_cluster(self.cluster_name)</span><br><span class="line">self._post(url,params)</span><br><span class="line">self.command=self._get_more_info()[&#x27;insecureCommand&#x27;]</span><br><span class="line">self._get_yaml_url(self.command)</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">单个node  </span><br><span class="line">&#123;</span><br><span class="line">            &quot;cluster_name&quot;: &quot;test-ywl01&quot;,</span><br><span class="line">            &quot;key_id&quot;: 6,</span><br><span class="line">            &quot;ldap&quot;: &quot;tuoxin&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;master0&quot;,</span><br><span class="line">            &quot;GROUP_CONCAT(distinct ip_address)&quot;: &quot;172.21.49.237&quot;,</span><br><span class="line">            &quot;user&quot;: &quot;root&quot;,</span><br><span class="line">            &quot;password&quot;: &quot;N@m^21oUgA&quot;,</span><br><span class="line">            &quot;port&quot;: &quot;22&quot;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<p>—&gt;</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;vm_state&quot; : &quot;active&quot;,  *</span><br><span class="line">	&quot;project_name&quot; : &quot;yyzc&quot;, *</span><br><span class="line">	&quot;description&quot; : &quot;&quot;, *</span><br><span class="line">	&quot;ldap&quot; : &quot;tuoxin&quot;,</span><br><span class="line">	&quot;host_ip&quot; : &quot;172.21.1.79&quot;, *</span><br><span class="line">	&quot;updated_at&quot; : NumberLong(&quot;1610937988000&quot;), *</span><br><span class="line">	&quot;host&quot; : &quot;HY-D01-S203-J19-POD5-COMPUTE-29&quot;, *</span><br><span class="line">	&quot;size_datavolume&quot; : &quot;&quot;, *</span><br><span class="line">	&quot;port_id&quot; : &quot;228d0767-b2d7-42c5-adad-c43429780760&quot;, *</span><br><span class="line">	&quot;device_id&quot; : &quot;&quot;, *</span><br><span class="line">	&quot;cluster_name&quot; : &quot;helmtest&quot;,  *</span><br><span class="line">	&quot;password&quot; : &quot;NJkg3@P!1y&quot;,</span><br><span class="line">	&quot;task_state&quot; : &quot;&quot;, *</span><br><span class="line">	&quot;display_name&quot; : &quot;worker3.547.yyzc&quot;, *</span><br><span class="line">	&quot;uuid&quot; : &quot;71cb1a5e-4574-4c55-b06f-d6b09f9ece24&quot;, * *</span><br><span class="line">	&quot;GROUP_CONCAT(value)&quot; : &quot;centos7.9&quot;, *</span><br><span class="line">	&quot;created_at&quot; : NumberLong(&quot;1610937971000&quot;), *</span><br><span class="line">	&quot;launched_on&quot; : &quot;HY-D01-S203-J19-POD5-COMPUTE-29&quot;, *</span><br><span class="line">	&quot;size_rootvolume&quot; : 40, *</span><br><span class="line">	&quot;memory_mb&quot; : 8192,  *</span><br><span class="line">	&quot;vcpus&quot; : 4, *</span><br><span class="line">	&quot;GROUP_CONCAT(distinct ip_address)&quot; : &quot;172.21.49.244&quot;,</span><br><span class="line">	&quot;vip&quot; : &quot;&quot;, *</span><br><span class="line">	&quot;key_id&quot; : &quot;547&quot;,</span><br><span class="line">	&quot;project_id&quot; : &quot;1217a4d5f0e546c288e9898d258fff95&quot;, *</span><br><span class="line">	&quot;type&quot; : &quot;worker3&quot; *</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2022-01-19 18:26:42,858 - /root/cluster/rancher_cluster/server/view.py[line:24] - ERROR: CMP平台反馈地址错误</p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>gitee+hexo搭建个人博客</title>
    <url>/2022/02/02/2022-02-02-gitee+hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>rke cluster.yaml完整示例</title>
    <url>/2022/02/07/2022-02-07-rke-cluster.yaml%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<p>cluster.yaml完整示例</p>
<p><a href="https://docs.rancher.cn/docs/rke/example-yamls/_index">cluster.yml 文件示例 | Rancher文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nodes:</span><br><span class="line">  - address: 1.1.1.1</span><br><span class="line">    user: ubuntu</span><br><span class="line">    role:</span><br><span class="line">      - controlplane</span><br><span class="line">      - etcd</span><br><span class="line">      port: 2222</span><br><span class="line">      docker_socket: /var/run/docker.sock</span><br><span class="line">    - address: 2.2.2.2</span><br><span class="line">      user: ubuntu</span><br><span class="line">      role:</span><br><span class="line">        - worker</span><br><span class="line">      ssh_key_path: /home/user/.ssh/id_rsa</span><br><span class="line">      ssh_key: |-</span><br><span class="line">        -----BEGIN RSA PRIVATE KEY-----</span><br><span class="line">        -----END RSA PRIVATE KEY-----</span><br><span class="line">      ssh_cert_path: /home/user/.ssh/test-key-cert.pub</span><br><span class="line">      ssh_cert: |-</span><br><span class="line">        ssh-rsa-cert-v01@openssh.com AAAAHHNzaC1yc2EtY2VydC12MDFAb3Bl....</span><br><span class="line">    - address: example.com</span><br><span class="line">      user: ubuntu</span><br><span class="line">      role:</span><br><span class="line">        - worker</span><br><span class="line">      hostname_override: node3</span><br><span class="line">      internal_address: 192.168.1.6</span><br><span class="line">      labels:</span><br><span class="line">        app: ingress</span><br><span class="line">      taints:</span><br><span class="line">        - key: test-key</span><br><span class="line">          value: test-value</span><br><span class="line">          effect: NoSchedule</span><br><span class="line"># If set to true, RKE will not fail when unsupported Docker version</span><br><span class="line"># are found</span><br><span class="line">ignore_docker_version: false</span><br><span class="line"></span><br><span class="line"># Enable running cri-dockerd</span><br><span class="line"># Up to Kubernetes 1.23, kubelet contained code called dockershim </span><br><span class="line"># to support Docker runtime. The replacement is called cri-dockerd </span><br><span class="line"># and should be enabled if you want to keep using Docker as your</span><br><span class="line"># container runtime</span><br><span class="line"># Only available to enable in Kubernetes 1.21 and higher</span><br><span class="line">enable_cri_dockerd: true</span><br><span class="line"></span><br><span class="line"># Cluster level SSH private key</span><br><span class="line"># Used if no ssh information is set for the node</span><br><span class="line">ssh_key_path: ~/.ssh/test</span><br><span class="line"># Enable use of SSH agent to use SSH private keys with passphrase</span><br><span class="line"># This requires the environment `SSH_AUTH_SOCK` configured pointing</span><br><span class="line">#to your SSH agent which has the private key added</span><br><span class="line">ssh_agent_auth: true</span><br><span class="line"># List of registry credentials</span><br><span class="line"># If you are using a Docker Hub registry, you can omit the `url`</span><br><span class="line"># or set it to `docker.io`</span><br><span class="line"># is_default set to `true` will override the system default</span><br><span class="line"># registry set in the global settings</span><br><span class="line">private_registries:</span><br><span class="line">     - url: registry.com</span><br><span class="line">       user: Username</span><br><span class="line">       password: password</span><br><span class="line">       is_default: true</span><br><span class="line"># Bastion/Jump host configuration</span><br><span class="line">bastion_host:</span><br><span class="line">    address: x.x.x.x</span><br><span class="line">    user: ubuntu</span><br><span class="line">    port: 22</span><br><span class="line">    ssh_key_path: /home/user/.ssh/bastion_rsa</span><br><span class="line"># or</span><br><span class="line">#   ssh_key: |-</span><br><span class="line">#     -----BEGIN RSA PRIVATE KEY-----</span><br><span class="line">#</span><br><span class="line">#     -----END RSA PRIVATE KEY-----</span><br><span class="line"># Set the name of the Kubernetes cluster</span><br><span class="line">cluster_name: mycluster</span><br><span class="line"># The Kubernetes version used. The default versions of Kubernetes</span><br><span class="line"># are tied to specific versions of the system images.</span><br><span class="line">#</span><br><span class="line"># For RKE v0.2.x and below, the map of Kubernetes versions and their system images is</span><br><span class="line"># located here:</span><br><span class="line"># https://github.com/rancher/types/blob/release/v2.2/apis/management.cattle.io/v3/k8s_defaults.go</span><br><span class="line">#</span><br><span class="line"># For RKE v0.3.0 and above, the map of Kubernetes versions and their system images is</span><br><span class="line"># located here:</span><br><span class="line"># https://github.com/rancher/kontainer-driver-metadata/blob/master/rke/k8s_rke_system_images.go</span><br><span class="line">#</span><br><span class="line"># In case the kubernetes_version and kubernetes image in</span><br><span class="line"># system_images are defined, the system_images configuration</span><br><span class="line"># will take precedence over kubernetes_version.</span><br><span class="line">kubernetes_version: v1.10.3-rancher2</span><br><span class="line"># System Images are defaulted to a tag that is mapped to a specific</span><br><span class="line"># Kubernetes Version and not required in a cluster.yml.</span><br><span class="line"># Each individual system image can be specified if you want to use a different tag.</span><br><span class="line">#</span><br><span class="line"># For RKE v0.2.x and below, the map of Kubernetes versions and their system images is</span><br><span class="line"># located here:</span><br><span class="line"># https://github.com/rancher/types/blob/release/v2.2/apis/management.cattle.io/v3/k8s_defaults.go</span><br><span class="line">#</span><br><span class="line"># For RKE v0.3.0 and above, the map of Kubernetes versions and their system images is</span><br><span class="line"># located here:</span><br><span class="line"># https://github.com/rancher/kontainer-driver-metadata/blob/master/rke/k8s_rke_system_images.go</span><br><span class="line">#</span><br><span class="line">system_images:</span><br><span class="line">    kubernetes: rancher/hyperkube:v1.10.3-rancher2</span><br><span class="line">    etcd: rancher/coreos-etcd:v3.1.12</span><br><span class="line">    alpine: rancher/rke-tools:v0.1.9</span><br><span class="line">    nginx_proxy: rancher/rke-tools:v0.1.9</span><br><span class="line">    cert_downloader: rancher/rke-tools:v0.1.9</span><br><span class="line">    kubernetes_services_sidecar: rancher/rke-tools:v0.1.9</span><br><span class="line">    kubedns: rancher/k8s-dns-kube-dns-amd64:1.14.8</span><br><span class="line">    dnsmasq: rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8</span><br><span class="line">    kubedns_sidecar: rancher/k8s-dns-sidecar-amd64:1.14.8</span><br><span class="line">    kubedns_autoscaler: rancher/cluster-proportional-autoscaler-amd64:1.0.0</span><br><span class="line">    pod_infra_container: rancher/pause-amd64:3.1</span><br><span class="line">services:</span><br><span class="line">    etcd:</span><br><span class="line">      # Custom uid/guid for etcd directory and files</span><br><span class="line">      uid: 52034</span><br><span class="line">      gid: 52034</span><br><span class="line">      # if external etcd is used</span><br><span class="line">      # path: /etcdcluster</span><br><span class="line">      # external_urls:</span><br><span class="line">      #   - https://etcd-example.com:2379</span><br><span class="line">      # ca_cert: |-</span><br><span class="line">      #   -----BEGIN CERTIFICATE-----</span><br><span class="line">      #   xxxxxxxxxx</span><br><span class="line">      #   -----END CERTIFICATE-----</span><br><span class="line">      # cert: |-</span><br><span class="line">      #   -----BEGIN CERTIFICATE-----</span><br><span class="line">      #   xxxxxxxxxx</span><br><span class="line">      #   -----END CERTIFICATE-----</span><br><span class="line">      # key: |-</span><br><span class="line">      #   -----BEGIN PRIVATE KEY-----</span><br><span class="line">      #   xxxxxxxxxx</span><br><span class="line">      #   -----END PRIVATE KEY-----</span><br><span class="line">    # Note for Rancher v2.0.5 and v2.0.6 users: If you are configuring</span><br><span class="line">    # Cluster Options using a Config File when creating Rancher Launched</span><br><span class="line">    # Kubernetes, the names of services should contain underscores</span><br><span class="line">    # only: `kube_api`.</span><br><span class="line"></span><br><span class="line">    kube-api:</span><br><span class="line">      # IP range for any services created on Kubernetes</span><br><span class="line">      # This must match the service_cluster_ip_range in kube-controller</span><br><span class="line">      service_cluster_ip_range: 10.43.0.0/16</span><br><span class="line">      # Expose a different port range for NodePort services</span><br><span class="line">      service_node_port_range: 30000-32767</span><br><span class="line">      pod_security_policy: false</span><br><span class="line">      # Encrypt secret data at Rest</span><br><span class="line">      # Available as of v0.3.1</span><br><span class="line">      secrets_encryption_config:</span><br><span class="line">        enabled: true</span><br><span class="line">        custom_config:</span><br><span class="line">          apiVersion: apiserver.config.k8s.io/v1</span><br><span class="line">          kind: EncryptionConfiguration</span><br><span class="line">          resources:</span><br><span class="line">          - resources:</span><br><span class="line">            - secrets</span><br><span class="line">            providers:</span><br><span class="line">            - aescbc:</span><br><span class="line">                keys:</span><br><span class="line">                - name: k-fw5hn</span><br><span class="line">                  secret: RTczRjFDODMwQzAyMDVBREU4NDJBMUZFNDhCNzM5N0I=</span><br><span class="line">            - identity: &#123;&#125;</span><br><span class="line">      # Enable audit logging</span><br><span class="line">      # Available as of v1.0.0</span><br><span class="line">      audit_log:</span><br><span class="line">        enabled: true</span><br><span class="line">        configuration:</span><br><span class="line">          max_age: 6</span><br><span class="line">          max_backup: 6</span><br><span class="line">          max_size: 110</span><br><span class="line">          path: /var/log/kube-audit/audit-log.json</span><br><span class="line">          format: json</span><br><span class="line">          policy:</span><br><span class="line">            apiVersion: audit.k8s.io/v1 # This is required.</span><br><span class="line">            kind: Policy</span><br><span class="line">            omitStages:</span><br><span class="line">              - &quot;RequestReceived&quot;</span><br><span class="line">            rules:</span><br><span class="line">              # Log pod changes at RequestResponse level</span><br><span class="line">              - level: RequestResponse</span><br><span class="line">                resources:</span><br><span class="line">                - group: &quot;&quot;</span><br><span class="line">                  # Resource &quot;pods&quot; doesn&#x27;t match requests to any subresource of pods,</span><br><span class="line">                  # which is consistent with the RBAC policy.</span><br><span class="line">                  resources: [&quot;pods&quot;]</span><br><span class="line">      # Using the EventRateLimit admission control enforces a limit on the number of events</span><br><span class="line">      # that the API Server will accept in a given time period</span><br><span class="line">      # Available as of v1.0.0</span><br><span class="line">      event_rate_limit:</span><br><span class="line">        enabled: true</span><br><span class="line">        configuration:</span><br><span class="line">          apiVersion: eventratelimit.admission.k8s.io/v1alpha1</span><br><span class="line">          kind: Configuration</span><br><span class="line">          limits:</span><br><span class="line">          - type: Server</span><br><span class="line">            qps: 6000</span><br><span class="line">            burst: 30000</span><br><span class="line">      # Enable AlwaysPullImages Admission controller plugin</span><br><span class="line">      # Available as of v0.2.0</span><br><span class="line">      always_pull_images: false</span><br><span class="line">      # Add additional arguments to the kubernetes API server</span><br><span class="line">      # This WILL OVERRIDE any existing defaults</span><br><span class="line">      extra_args:</span><br><span class="line">        # Enable audit log to stdout</span><br><span class="line">        audit-log-path: &quot;-&quot;</span><br><span class="line">        # Increase number of delete workers</span><br><span class="line">        delete-collection-workers: 3</span><br><span class="line">        # Set the level of log output to debug-level</span><br><span class="line">        v: 4</span><br><span class="line">    # Note for Rancher 2 users: If you are configuring Cluster Options</span><br><span class="line">    # using a Config File when creating Rancher Launched Kubernetes,</span><br><span class="line">    # the names of services should contain underscores only:</span><br><span class="line">    # `kube_controller`. This only applies to Rancher v2.0.5 and v2.0.6.</span><br><span class="line">    kube-controller:</span><br><span class="line">      # CIDR pool used to assign IP addresses to pods in the cluster</span><br><span class="line">      cluster_cidr: 10.42.0.0/16</span><br><span class="line">      # IP range for any services created on Kubernetes</span><br><span class="line">      # This must match the service_cluster_ip_range in kube-api</span><br><span class="line">      service_cluster_ip_range: 10.43.0.0/16</span><br><span class="line">      # Add additional arguments to the kubernetes API server</span><br><span class="line">      # This WILL OVERRIDE any existing defaults</span><br><span class="line">      extra_args:</span><br><span class="line">        # Set the level of log output to debug-level</span><br><span class="line">        v: 4</span><br><span class="line">        # Enable RotateKubeletServerCertificate feature gate</span><br><span class="line">        feature-gates: RotateKubeletServerCertificate=true</span><br><span class="line">        # Enable TLS Certificates management</span><br><span class="line">        # https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/</span><br><span class="line">        cluster-signing-cert-file: &quot;/etc/kubernetes/ssl/kube-ca.pem&quot;</span><br><span class="line">        cluster-signing-key-file: &quot;/etc/kubernetes/ssl/kube-ca-key.pem&quot;</span><br><span class="line">    kubelet:</span><br><span class="line">      # Base domain for the cluster</span><br><span class="line">      cluster_domain: cluster.local</span><br><span class="line">      # IP address for the DNS service endpoint</span><br><span class="line">      cluster_dns_server: 10.43.0.10</span><br><span class="line">    # Fail if swap is on</span><br><span class="line">    fail_swap_on: false</span><br><span class="line">    # Configure pod-infra-container-image argument</span><br><span class="line">      pod-infra-container-image: &quot;k8s.gcr.io/pause:3.2&quot;</span><br><span class="line">      # Generate a certificate signed by the kube-ca Certificate Authority</span><br><span class="line">      # for the kubelet to use as a server certificate</span><br><span class="line">      # Available as of v1.0.0</span><br><span class="line">      generate_serving_certificate: true</span><br><span class="line">      extra_args:</span><br><span class="line">        # Set max pods to 250 instead of default 110</span><br><span class="line">        max-pods: 250</span><br><span class="line">        # Enable RotateKubeletServerCertificate feature gate</span><br><span class="line">        feature-gates: RotateKubeletServerCertificate=true</span><br><span class="line">      # Optionally define additional volume binds to a service</span><br><span class="line">      extra_binds:</span><br><span class="line">        - &quot;/usr/libexec/kubernetes/kubelet-plugins:/usr/libexec/kubernetes/kubelet-plugins&quot;</span><br><span class="line">    scheduler:</span><br><span class="line">      extra_args:</span><br><span class="line">        # Set the level of log output to debug-level</span><br><span class="line">        v: 4</span><br><span class="line">    kubeproxy:</span><br><span class="line">      extra_args:</span><br><span class="line">        # Set the level of log output to debug-level</span><br><span class="line">        v: 4</span><br><span class="line"># Currently, only authentication strategy supported is x509.</span><br><span class="line"># You can optionally create additional SANs (hostnames or IPs) to</span><br><span class="line"># add to the API server PKI certificate.</span><br><span class="line"># This is useful if you want to use a load balancer for the</span><br><span class="line"># control plane servers.</span><br><span class="line">authentication:</span><br><span class="line">  strategy: x509</span><br><span class="line">  sans:</span><br><span class="line">    - &quot;10.18.160.10&quot;</span><br><span class="line">    - &quot;my-loadbalancer-1234567890.us-west-2.elb.amazonaws.com&quot;</span><br><span class="line"></span><br><span class="line"># Kubernetes Authorization mode</span><br><span class="line"># Use `mode: rbac` to enable RBAC</span><br><span class="line"># Use `mode: none` to disable authorization</span><br><span class="line">authorization:</span><br><span class="line">  mode: rbac</span><br><span class="line"></span><br><span class="line"># If you want to set a Kubernetes cloud provider, you specify</span><br><span class="line"># the name and configuration</span><br><span class="line">cloud_provider:</span><br><span class="line">  name: aws</span><br><span class="line"></span><br><span class="line"># Add-ons are deployed using kubernetes jobs. RKE will give</span><br><span class="line"># up on trying to get the job status after this timeout in seconds..</span><br><span class="line">addon_job_timeout: 30</span><br><span class="line"></span><br><span class="line"># Specify network plugin-in (canal, calico, flannel, weave, or none)</span><br><span class="line">network:</span><br><span class="line">  plugin: canal</span><br><span class="line">  # Specify MTU</span><br><span class="line">  mtu: 1400</span><br><span class="line">  options:</span><br><span class="line">    # Configure interface to use for Canal</span><br><span class="line">    canal_iface: eth1</span><br><span class="line">    canal_flannel_backend_type: vxlan</span><br><span class="line">    # Available as of v1.2.6</span><br><span class="line">    canal_autoscaler_priority_class_name: system-cluster-critical</span><br><span class="line">    canal_priority_class_name: system-cluster-critical</span><br><span class="line">  # Available as of v1.2.4</span><br><span class="line">  tolerations:</span><br><span class="line">  - key: &quot;node.kubernetes.io/unreachable&quot;</span><br><span class="line">    operator: &quot;Exists&quot;</span><br><span class="line">    effect: &quot;NoExecute&quot;</span><br><span class="line">    tolerationseconds: 300</span><br><span class="line">  - key: &quot;node.kubernetes.io/not-ready&quot;</span><br><span class="line">    operator: &quot;Exists&quot;</span><br><span class="line">    effect: &quot;NoExecute&quot;</span><br><span class="line">    tolerationseconds: 300</span><br><span class="line">  # Available as of v1.1.0</span><br><span class="line">  update_strategy:</span><br><span class="line">    strategy: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 6</span><br><span class="line"></span><br><span class="line"># Specify DNS provider (coredns or kube-dns)</span><br><span class="line">dns:</span><br><span class="line">  provider: coredns</span><br><span class="line">  # Available as of v1.1.0</span><br><span class="line">  update_strategy:</span><br><span class="line">    strategy: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 20%</span><br><span class="line">      maxSurge: 15%</span><br><span class="line">  linear_autoscaler_params:</span><br><span class="line">    cores_per_replica: 0.34</span><br><span class="line">    nodes_per_replica: 4</span><br><span class="line">    prevent_single_point_failure: true</span><br><span class="line">    min: 2</span><br><span class="line">    max: 3</span><br><span class="line"># Specify monitoring provider (metrics-server)</span><br><span class="line">monitoring:</span><br><span class="line">  provider: metrics-server</span><br><span class="line">  # Available as of v1.1.0</span><br><span class="line">  update_strategy:</span><br><span class="line">    strategy: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 8</span><br><span class="line"># Currently only nginx ingress provider is supported.</span><br><span class="line"># To disable ingress controller, set `provider: none`</span><br><span class="line"># `node_selector` controls ingress placement and is optional</span><br><span class="line">ingress:</span><br><span class="line">  provider: nginx</span><br><span class="line">  node_selector:</span><br><span class="line">    app: ingress</span><br><span class="line">  # Available as of v1.1.0</span><br><span class="line">  update_strategy:</span><br><span class="line">    strategy: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 5</span><br><span class="line"># All add-on manifests MUST specify a namespace</span><br><span class="line">addons: |-</span><br><span class="line">  ---</span><br><span class="line">  apiVersion: v1</span><br><span class="line">  kind: Pod</span><br><span class="line">  metadata:</span><br><span class="line">    name: my-nginx</span><br><span class="line">    namespace: default</span><br><span class="line">  spec:</span><br><span class="line">    containers:</span><br><span class="line">    - name: my-nginx</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">      - containerPort: 80</span><br><span class="line"></span><br><span class="line">addons_include:</span><br><span class="line">  - https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/rook-operator.yaml</span><br><span class="line">  - https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/rook-cluster.yaml</span><br><span class="line">  - /path/to/manifest</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>seccomp实验记录</title>
    <url>/2022/02/08/2022-02-08-seccomp%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>seccomp json模板</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir profiles</span><br><span class="line"></span><br><span class="line">cat &gt; audit.json &lt;&lt; EOF </span><br><span class="line">&#123;</span><br><span class="line">    &quot;defaultAction&quot;: &quot;SCMP_ACT_LOG&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; violation.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;defaultAction&quot;: &quot;SCMP_ACT_ERRNO&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; fine-grained.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;defaultAction&quot;: &quot;SCMP_ACT_ERRNO&quot;,</span><br><span class="line">    &quot;architectures&quot;: [</span><br><span class="line">        &quot;SCMP_ARCH_X86_64&quot;,</span><br><span class="line">        &quot;SCMP_ARCH_X86&quot;,</span><br><span class="line">        &quot;SCMP_ARCH_X32&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;syscalls&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;names&quot;: [</span><br><span class="line">                &quot;accept4&quot;,</span><br><span class="line">                &quot;epoll_wait&quot;,</span><br><span class="line">                &quot;pselect6&quot;,</span><br><span class="line">                &quot;futex&quot;,</span><br><span class="line">                &quot;madvise&quot;,</span><br><span class="line">                &quot;epoll_ctl&quot;,</span><br><span class="line">                &quot;getsockname&quot;,</span><br><span class="line">                &quot;setsockopt&quot;,</span><br><span class="line">                &quot;vfork&quot;,</span><br><span class="line">                &quot;mmap&quot;,</span><br><span class="line">                &quot;read&quot;,</span><br><span class="line">                &quot;write&quot;,</span><br><span class="line">                &quot;close&quot;,</span><br><span class="line">                &quot;arch_prctl&quot;,</span><br><span class="line">                &quot;sched_getaffinity&quot;,</span><br><span class="line">                &quot;munmap&quot;,</span><br><span class="line">                &quot;brk&quot;,</span><br><span class="line">                &quot;rt_sigaction&quot;,</span><br><span class="line">                &quot;rt_sigprocmask&quot;,</span><br><span class="line">                &quot;sigaltstack&quot;,</span><br><span class="line">                &quot;gettid&quot;,</span><br><span class="line">                &quot;clone&quot;,</span><br><span class="line">                &quot;bind&quot;,</span><br><span class="line">                &quot;socket&quot;,</span><br><span class="line">                &quot;openat&quot;,</span><br><span class="line">                &quot;readlinkat&quot;,</span><br><span class="line">                &quot;exit_group&quot;,</span><br><span class="line">                &quot;epoll_create1&quot;,</span><br><span class="line">                &quot;listen&quot;,</span><br><span class="line">                &quot;rt_sigreturn&quot;,</span><br><span class="line">                &quot;sched_yield&quot;,</span><br><span class="line">                &quot;clock_gettime&quot;,</span><br><span class="line">                &quot;connect&quot;,</span><br><span class="line">                &quot;dup2&quot;,</span><br><span class="line">                &quot;epoll_pwait&quot;,</span><br><span class="line">                &quot;execve&quot;,</span><br><span class="line">                &quot;exit&quot;,</span><br><span class="line">                &quot;fcntl&quot;,</span><br><span class="line">                &quot;getpid&quot;,</span><br><span class="line">                &quot;getuid&quot;,</span><br><span class="line">                &quot;ioctl&quot;,</span><br><span class="line">                &quot;mprotect&quot;,</span><br><span class="line">                &quot;nanosleep&quot;,</span><br><span class="line">                &quot;open&quot;,</span><br><span class="line">                &quot;poll&quot;,</span><br><span class="line">                &quot;recvfrom&quot;,</span><br><span class="line">                &quot;sendto&quot;,</span><br><span class="line">                &quot;set_tid_address&quot;,</span><br><span class="line">                &quot;setitimer&quot;,</span><br><span class="line">                &quot;writev&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;action&quot;: &quot;SCMP_ACT_ALLOW&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">mkdir /var/lib/kubelet/seccomp/ </span><br><span class="line">cp -r profiles/ /var/lib/kubelet/seccomp/</span><br></pre></td></tr></table></figure>

<p>POD </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;  pod-audit.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod-audit</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/audit.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;  pod-violation.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod-violation</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/violation.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt;  pod-fine-grained.yaml &lt;&lt; EOF </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod-fine-grained</span><br><span class="line">  labels:</span><br><span class="line">    app: fine-pod</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: localhost/profiles/fine-grained.json</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat  &gt; pod-default-seccomp.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pod-default-seccomp</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/pod: runtime/default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-container</span><br><span class="line">    image: hashicorp/http-echo:0.2.3</span><br><span class="line">    args:</span><br><span class="line">    - &quot;-text=just made some syscalls!&quot;</span><br><span class="line">    securityContext:</span><br><span class="line">      allowPrivilegeEscalation: false</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>默认配置方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node101 ~]# kubectl get psp default-psp -o yaml </span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: &#x27;*&#x27;</span><br><span class="line">  creationTimestamp: &quot;2022-01-26T08:29:11Z&quot;</span><br><span class="line">  name: default-psp</span><br><span class="line">  resourceVersion: &quot;29900&quot;</span><br><span class="line">  selfLink: /apis/policy/v1beta1/podsecuritypolicies/default-psp</span><br><span class="line">  uid: 09f4fef4-74a7-43a9-9b8c-49dabbbb249e</span><br><span class="line">spec:</span><br><span class="line">  allowPrivilegeEscalation: true</span><br><span class="line">  allowedCapabilities:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  hostIPC: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPID: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - max: 65535</span><br><span class="line">    min: 0</span><br><span class="line">  privileged: true</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  volumes:</span><br><span class="line">  - &#x27;*&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>gitpython基础用法</title>
    <url>/2022/02/09/2022-02-09-gitpython%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">导入</span><br><span class="line">pip install gitpython </span><br><span class="line">from git import Repo </span><br><span class="line"># 初始化</span><br><span class="line">repopath=&#x27;test&#x27;</span><br><span class="line">repo = Repo.init(path=&#x27;&#x27;) # 初始一个更新仓库， 若存在.git, 不会覆盖</span><br><span class="line"># clone # 克隆地址不要包含.git</span><br><span class="line">new_repo = git.Repo.clone_from(url=&#x27;git@github.com:USER/REPO.git&#x27;, to_path=repopath)</span><br><span class="line"># add # commit 	 </span><br><span class="line">repo.index.add(items=[&#x27;test.file&#x27;]) # 次路径是相对于repo路径，不是python cwd</span><br><span class="line">repo.index.commit(&#x27;write a line into test.file&#x27;)</span><br><span class="line"># 远端</span><br><span class="line">remote = repo.create_remote(name=&#x27;gitlab&#x27;, url=&#x27;git@gitlab.com:USER/REPO.git&#x27;) # 远端只要添加一次 </span><br><span class="line">remote = repo.remote()</span><br><span class="line">remote.fetch()</span><br><span class="line">remote.pull()</span><br><span class="line">remote.push()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>python  module json</title>
    <url>/2022/02/10/2022-02-10-python-module-json/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import json </span><br><span class="line"># dic-&gt; json </span><br><span class="line">json.dumps()</span><br><span class="line"># json-&gt; dic </span><br><span class="line">json.loads()</span><br></pre></td></tr></table></figure>

<p>函数原型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">json.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=&quot;utf-8&quot;, default=None, sort_keys=False, **kw)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>ansible使用</title>
    <url>/2022/02/18/2022-02-18-ansible%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="1-ansible是什么"><a href="#1-ansible是什么" class="headerlink" title="1 ansible是什么"></a>1 ansible是什么</h3><p>Ansilbe是一个部署一群远程s主机的工具。远程的主机可以是本地或者远程的虚拟机，也可以是远程的物理机。</p>
<h3 id="2-Ansible能做什么？"><a href="#2-Ansible能做什么？" class="headerlink" title="2 Ansible能做什么？"></a>2 Ansible能做什么？</h3><p>Ansilbe是一个部署一群远程主机的工具。远程的主机可以是本地或者远程的虚拟机，也可以是远程的物理机。</p>
<h3 id="3-ansible-配置"><a href="#3-ansible-配置" class="headerlink" title="3 ansible 配置"></a>3 ansible 配置</h3><ul>
<li>安装</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Redhat/CentOS Linux上，Ansible目前放在的epel源中</span><br><span class="line"># Fedora默认源中包含ansible，直接安装包既可</span><br><span class="line">yum install epel-release </span><br><span class="line">yum install ansible -y</span><br></pre></td></tr></table></figure>

<ul>
<li>配置Ansible管理节点和主机的连接</li>
</ul>
<p>其实就是配置从<strong>管理节点到远程主机</strong>之间基于key（无密码的方式）的<strong>SSH连接</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 复制代码$ # 生成ssh key$ ssh-keygen$ </span><br><span class="line"># 拷贝ssh key到远程主机，ssh的时候就不需要输入密码了$ ssh-copy-id remoteuser@remoteserver$ # ssh的时候不会提示是否保存key$ ssh-keyscan remote_servers &gt;&gt; ~/.ssh/known_hosts</span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>helm使用</title>
    <url>/2022/02/18/2022-02-18-helm%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="1-1-为什么需要helm"><a href="#1-1-为什么需要helm" class="headerlink" title="1.1 为什么需要helm"></a>1.1 为什么需要helm</h3><p>在没使用helm之前，向<code>kubernetes</code>部署应用，我们要依次部署<code>deployment</code>,<code>service</code>,<code>configMap</code>等,步骤较繁琐。况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂.</p>
<p><code>helm</code>通过打包的方式，支持发布的版本管理和控制,很大程度上简化了<code>Kubernetes</code>应用的部署和管理</p>
<h3 id="1-2-helm中几个概念"><a href="#1-2-helm中几个概念" class="headerlink" title="1.2 helm中几个概念"></a>1.2 helm中几个概念</h3><p><code>Helm</code>可以理解为<code>Kubernetes</code>的包管理工具，可以方便地发现、共享和使用为<code>Kubernetes</code>构建的应用，它包含几个基本概念</p>
<ul>
<li><strong>Chart</strong>: 一个Helm包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含Kubernetes集群中的服务定义</li>
</ul>
<blockquote>
<p>可以理解为docker的image</p>
</blockquote>
<ul>
<li><strong>Release</strong>: 在<code>Kubernetes</code>集群上运行的 <code>Chart</code>的一个实例。在同一个集群上，一个 <code>Chart</code>可以安装很多次。每次安装都会创建一个新的<code>release</code></li>
</ul>
<blockquote>
<p>可以理解为docker的container实例</p>
</blockquote>
<ul>
<li><strong>Repository</strong>: 用于发布和存储 Chart 的仓库。</li>
</ul>
<h3 id="1-3-helm用途"><a href="#1-3-helm用途" class="headerlink" title="1.3 helm用途"></a>1.3 helm用途</h3><p>做为<code>Kubernetes</code>的一个包管理工具，Helm具有如下功能：</p>
<ul>
<li><p>创建新的<code>chart</code></p>
</li>
<li><p><code>chart</code>打包成<code>tgz</code>格式</p>
</li>
<li><p>上传chart到chart仓库或从仓库中下载 chart</p>
<ul>
<li>官方<code>chart</code>仓库是: <a href="https://hub.helm.sh/">https://hub.helm.sh</a></li>
</ul>
</li>
<li><p>在<code>Kubernetes</code>集群中安装或卸载<code>chart</code></p>
</li>
<li><p>用<code>Helm</code>管理安装的<code>chart</code>的发布周期</p>
</li>
</ul>
<h3 id="1-4-helm安装"><a href="#1-4-helm安装" class="headerlink" title="1.4 helm安装"></a>1.4 helm安装</h3><ul>
<li>注意：这里安装的是<code>helm v3.2.4</code>，如需下载更新的版本，可以至github官方repo选择</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://github.com/helm/helm/tags</span><br></pre></td></tr></table></figure>

<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2 安装"></a>2 安装</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 如无需更换版本，直接执行下载</span><br><span class="line">wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf helm-v3.2.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 进入到解压后的目录</span><br><span class="line">cd linux-amd64/</span><br><span class="line"></span><br><span class="line"># 赋予权限</span><br><span class="line">chmod a+x /usr/local/bin/helm</span><br><span class="line"></span><br><span class="line"># 查看版本</span><br><span class="line">helm version</span><br></pre></td></tr></table></figure>

<h3 id="3-1-chart"><a href="#3-1-chart" class="headerlink" title="3.1 chart"></a>3.1 chart</h3><p>可以直接使用官方的chart仓库或者其他仓库来安装一些<code>chart</code></p>
<blockquote>
<p><a href="https://hub.helm.sh/">https://hub.helm.sh</a></p>
</blockquote>
<ul>
<li>下面以官方仓库的一个redis为例</li>
</ul>
<blockquote>
<p><a href="https://hub.helm.sh/charts/choerodon/redis">https://hub.helm.sh/charts/choerodon/redis</a></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加仓库</span><br><span class="line">helm repo add choerodon https://openchart.choerodon.com.cn/choerodon/c7n</span><br><span class="line"></span><br><span class="line"># 安装</span><br><span class="line">helm install choerodon/redis --version 0.2.5</span><br></pre></td></tr></table></figure>

<h3 id="3-2-自定义chart"><a href="#3-2-自定义chart" class="headerlink" title="3.2 自定义chart"></a>3.2 自定义chart</h3><p>文件目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── Chart.yaml</span><br><span class="line">├── templates</span><br><span class="line">|   ├── deployment.yaml</span><br><span class="line">|   └── service.yaml</span><br><span class="line">├── values.yaml</span><br></pre></td></tr></table></figure>

<p>一个基本的自定义chart的文件目录结构大概是如上：</p>
<ul>
<li><p><strong>Chart.yaml</strong>: 定义当前<code>chart</code>的基本metadata, 比如name，tag啥的</p>
</li>
<li><p>templates</p>
<p>: 这个文件夹下放当前chart需要的一些yaml资源清单</p>
<ul>
<li>资源清单支持<code>变量模版语法</code></li>
</ul>
</li>
<li><p><strong>values.yaml</strong>: 定义变量，可被<code>template</code>下的yaml资源清单使用</p>
</li>
</ul>
<h3 id="3-3-helm使用"><a href="#3-3-helm使用" class="headerlink" title="3.3 helm使用"></a>3.3 helm使用</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node229 linux-amd64]# helm --help</span><br><span class="line">The Kubernetes package manager</span><br><span class="line"></span><br><span class="line">Common actions for Helm:</span><br><span class="line"></span><br><span class="line">- helm search:    search for charts # 搜索公开仓库的charts </span><br><span class="line">- helm pull:      download a chart to your local directory to view # 下载charts</span><br><span class="line">- helm install:   upload the chart to Kubernetes # 安装charts </span><br><span class="line">- helm list:      list releases of charts # 查看Charts 下面对于的releases </span><br><span class="line"></span><br><span class="line">Environment variables: # 环境变量</span><br><span class="line"></span><br><span class="line">| Name                               | Description                                                                       |</span><br><span class="line">|------------------------------------|-----------------------------------------------------------------------------------|</span><br><span class="line">| $XDG_CACHE_HOME                    | set an alternative location for storing cached files.                             |</span><br><span class="line">| $XDG_CONFIG_HOME                   | set an alternative location for storing Helm configuration.                       |</span><br><span class="line">| $XDG_DATA_HOME                     | set an alternative location for storing Helm data.                                |</span><br><span class="line">| $HELM_DRIVER                       | set the backend storage driver. Values are: configmap, secret, memory, postgres   |</span><br><span class="line">| $HELM_DRIVER_SQL_CONNECTION_STRING | set the connection string the SQL storage driver should use.                      |</span><br><span class="line">| $HELM_NO_PLUGINS                   | disable plugins. Set HELM_NO_PLUGINS=1 to disable plugins.                        |</span><br><span class="line">| $KUBECONFIG                        | set an alternative Kubernetes configuration file (default &quot;~/.kube/config&quot;)       |</span><br><span class="line"></span><br><span class="line">Helm stores configuration based on the XDG base directory specification, so</span><br><span class="line"></span><br><span class="line">- cached files are stored in $XDG_CACHE_HOME/helm</span><br><span class="line">- configuration is stored in $XDG_CONFIG_HOME/helm</span><br><span class="line">- data is stored in $XDG_DATA_HOME/helm</span><br><span class="line"></span><br><span class="line">By default, the default directories depend on the Operating System. The defaults are listed below:</span><br><span class="line"></span><br><span class="line">| Operating System | Cache Path                | Configuration Path             | Data Path               |</span><br><span class="line">|------------------|---------------------------|--------------------------------|-------------------------|</span><br><span class="line">| Linux            | $HOME/.cache/helm         | $HOME/.config/helm             | $HOME/.local/share/helm |</span><br><span class="line">| macOS            | $HOME/Library/Caches/helm | $HOME/Library/Preferences/helm | $HOME/Library/helm      |</span><br><span class="line">| Windows          | %TEMP%\helm               | %APPDATA%\helm                 | %APPDATA%\helm          |</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  helm [command]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  completion  generate autocompletions script for the specified shell (bash or zsh)#为指定的shell生成自动完成脚本</span><br><span class="line">  create      create a new chart with the given name # 用给定的名称创建一个新的chart </span><br><span class="line">  dependency  manage a chart&#x27;s dependencies # 管理chart的依赖关系</span><br><span class="line">  env         helm client environment information # 掌握client环境</span><br><span class="line">  get         download extended information of a named release # 下载指定版本的扩展信息</span><br><span class="line">  help        Help about any command # </span><br><span class="line">  history     fetch release history # 获取版本历史</span><br><span class="line">  install     install a chart # 装一个chart</span><br><span class="line">  lint        examine a chart for possible issues # ：检查chart中可能出现的问题</span><br><span class="line">  list        list releases # list</span><br><span class="line">  package     package a chart directory into a chart archive # 将chart目录打包到chart存档文件中</span><br><span class="line">  plugin      install, list, or uninstall Helm plugins # 安装，列表，或卸载Helm插件</span><br><span class="line">  pull        download a chart from a repository and (optionally) unpack it in local directory # 从存储库下载chart，并(可选地)将其解压缩到本地目录中</span><br><span class="line">  repo        add, list, remove, update, and index chart repositories # 添加、列出、删除、更新和索引chart存储库</span><br><span class="line">  rollback    roll back a release to a previous revision # 将一个版本回滚到以前的版本</span><br><span class="line">  search      search for a keyword in charts # 在chart中搜索关键字</span><br><span class="line">  show        show information of a chart # 显示chart的信息</span><br><span class="line">  status      display the status of the named release # 显示指定版本的状态</span><br><span class="line">  template    locally render templates # 本地呈现模板</span><br><span class="line">  test        run tests for a release # 为发行版运行测试</span><br><span class="line">  uninstall   uninstall a release # 卸载一个release</span><br><span class="line">  upgrade     upgrade a release # 升级一个release</span><br><span class="line">  verify      verify that a chart at the given path has been signed and is valid # 验证给定路径上的chart已签名并有效</span><br><span class="line">  version     print the client version information # 打印client版本信息</span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">      --add-dir-header                   If true, adds the file directory to the header # 如果为true，则将文件目录添加到头文件中</span><br><span class="line">      --alsologtostderr                  log to standard error as well as files # 记录标准错误和文件</span><br><span class="line">      --debug                            enable verbose output # 启用详细输出</span><br><span class="line">  -h, --help                             help for helm</span><br><span class="line">      --kube-apiserver string            the address and the port for the Kubernetes API server# Kubernetes API服务器的地址和端口</span><br><span class="line">      --kube-context string              name of the kubeconfig context to use#要使用的kubecconfig上下文的名称</span><br><span class="line">      --kube-token string                bearer token used for authentication #用于认证的承载令牌</span><br><span class="line">      --kubeconfig string                path to the kubeconfig file#kubecconfig文件的路径</span><br><span class="line">      --log-backtrace-at traceLocation   when logging hits line file:N, emit a stack trace (default :0)#当日志命中行文件:N时，发出一个堆栈跟踪(默认值:0)</span><br><span class="line">      --log-dir string                   If non-empty, write log files in this directory#如果不为空，则将日志文件写入该目录</span><br><span class="line">      --log-file string                  If non-empty, use this log file#如果非空，使用此日志文件</span><br><span class="line">      --log-file-max-size uint           Defines the maximum size a log file can grow to. Unit is megabytes. If the value is 0, the maximum file size is unlimited. (default 1800)#定义日志文件可以增长到的最大大小。单位是字节。当取值为0时，表示不限制文件的最大大小。1800(默认)</span><br><span class="line">      --logtostderr                      log to standard error instead of files (default true)#将日志记录到标准错误而不是文件(默认为true)</span><br><span class="line">  -n, --namespace string                 namespace scope for this request#此请求的名称空间范围</span><br><span class="line">      --registry-config string           path to the registry config file (default &quot;/root/.config/helm/registry.json&quot;)#注册表配置文件的路径(默认&quot;/root/.config/helm/registry.json&quot;)</span><br><span class="line">      --repository-cache string          path to the file containing cached repository indexes (default &quot;/root/.cache/helm/repository&quot;)#包含缓存存储库索引的文件路径(默认为&quot;/root/.cache/helm/repository&quot;)</span><br><span class="line">      --repository-config string         path to the file containing repository names and URLs (default &quot;/root/.config/helm/repositories.yaml&quot;)#包含存储库名称和url的文件路径(默认为&quot;/root/.config/helm/repositories.yaml&quot;)</span><br><span class="line">      --skip-headers                     If true, avoid header prefixes in the log messages#如果为true，则避免在日志消息中使用头前缀</span><br><span class="line">      --skip-log-headers                 If true, avoid headers when opening log files#如果为true，则在打开日志文件时避免使用头文件</span><br><span class="line">      --stderrthreshold severity         logs at or above this threshold go to stderr (default 2)</span><br><span class="line">  -v, --v Level                          number for the log level verbosity#超过这个阈值的日志将转到stderr(默认2)</span><br><span class="line">      --vmodule moduleSpec               comma-separated list of pattern=N settings for file-filtered logging#以逗号分隔的模式列表=N个文件过滤日志设置</span><br><span class="line"></span><br><span class="line">Use &quot;helm [command] --help&quot; for more information about a command.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>docker删除镜像失败</title>
    <url>/2022/02/21/2022-02-21-docker%E5%88%A0%E9%99%A4%E9%95%9C%E5%83%8F%E5%A4%B1%E8%B4%A5/</url>
    <content><![CDATA[<p>docker删除镜像报错，一般来说有容器使用该镜像是不能直接删除的。先删除容器，再删除镜像。</p>
<p>Error response from daemon: conflict: unable to delete de529ffbdb66 (cannot be forced) - image has dependent child images</p>
<p>该镜像存在依赖它的子镜像，要先删除其依赖镜像。</p>
<p>[root@nginx ~]# docker rmi ee8623d6c15a<br>Error response from daemon: conflict: unable to delete ee8623d6c15a (must be forced) - image is referenced in multiple repositories</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">[root@nginx ~]# docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">autoblog            v1                  ee8623d6c15a        3 days ago          1.12GB</span><br><span class="line">autoblog            v2                  ee8623d6c15a        3 days ago          1.12GB</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>两个仓库是同一个镜像，那么需要安装镜像：tag方式指定删除</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@nginx ~]# docker rmi autoblog:v1</span><br><span class="line">Untagged: autoblog:v1</span><br><span class="line">[root@nginx ~]# docker rmi autoblog:v2</span><br><span class="line">Untagged: autoblog:v2</span><br></pre></td></tr></table></figure>

<p>实际上docker images只能列出镜像，但docker image还可以做与其他的事情。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">[root@nginx ~]# docker images --help</span><br><span class="line"></span><br><span class="line">Usage:  docker images [OPTIONS] [REPOSITORY[:TAG]]</span><br><span class="line"></span><br><span class="line">List images</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -a, --all             Show all images (default hides intermediate images)</span><br><span class="line">      --digests         Show digests</span><br><span class="line">  -f, --filter filter   Filter output based on conditions provided</span><br><span class="line">      --format string   Pretty-print images using a Go template</span><br><span class="line">      --no-trunc        Don&#x27;t truncate output</span><br><span class="line">  -q, --quiet           Only show numeric IDs</span><br><span class="line">[root@nginx ~]# docker image</span><br><span class="line"></span><br><span class="line">Usage:  docker image COMMAND</span><br><span class="line"></span><br><span class="line">Manage images</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">  build       Build an image from a Dockerfile</span><br><span class="line">  history     Show the history of an image</span><br><span class="line">  import      Import the contents from a tarball to create a filesystem image</span><br><span class="line">  inspect     Display detailed information on one or more images</span><br><span class="line">  load        Load an image from a tar archive or STDIN</span><br><span class="line">  ls          List images</span><br><span class="line">  prune       Remove unused images</span><br><span class="line">  pull        Pull an image or a repository from a registry</span><br><span class="line">  push        Push an image or a repository to a registry</span><br><span class="line">  rm          Remove one or more images</span><br><span class="line">  save        Save one or more images to a tar archive (streamed to STDOUT by default)</span><br><span class="line">  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">docker image prune 删除未被使用的镜像 </span><br><span class="line"># prune 修剪</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rm -f container </span><br><span class="line"># 直接删除容器等于 </span><br><span class="line">docker stop container </span><br><span class="line">docker rm container </span><br><span class="line"></span><br><span class="line">docker container prune # 修整not runing的容器</span><br><span class="line">docker system prune</span><br><span class="line">#4种会被prune的对象以及其他信息，包括： </span><br><span class="line">stopped containers, 不是运行状态的container</span><br><span class="line">unused volumes，不被任何container引用的volume，所谓dangling volume，一般删除了某个container后，可能会产生这样的volume，可以通过docker rm -v避免这种dangling volume</span><br><span class="line">unused network，不被任何container引用的network</span><br><span class="line">dangling images，不被任何container引用的image</span><br><span class="line">每个被删除的对象都能看到它的ID，比如container ID、volume ID</span><br><span class="line">最后有个释放空间大小的summary</span><br></pre></td></tr></table></figure>







]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>django学习笔记</title>
    <url>/2022/02/21/django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>开始django</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 安装特定版本的django </span><br><span class="line">pip install django==1.11.4 </span><br><span class="line"># 安装django会按照 django-admin命令行工具</span><br><span class="line"># 创建一个新的项目</span><br><span class="line">mkdir myproject </span><br><span class="line">cd myproject </span><br><span class="line">django-admin startproject myproject </span><br><span class="line"># 结构目录如下</span><br><span class="line">myproject/                  &lt;-- 高级别的文件夹</span><br><span class="line"> |-- myproject/             &lt;-- Django项目文件夹</span><br><span class="line"> |    |-- myproject/</span><br><span class="line"> |    |    |-- __init__.py</span><br><span class="line"> |    |    |-- settings.py</span><br><span class="line"> |    |    |-- urls.py</span><br><span class="line"> |    |    |-- wsgi.py</span><br><span class="line"> |    +-- manage.py</span><br></pre></td></tr></table></figure>

<p>最初的项目结构由五个文件组成：</p>
<ul>
<li><strong>manage.py</strong>：使用<strong>django-admin</strong>命令行工具的快捷方式。它用于运行与我们项目相关的管理命令。我们将使用它来运行开发服务器，运行测试，创建迁移等等。</li>
<li><strong>__init.py</strong>：这个空文件告诉python这个文件夹是一个python包。</li>
<li><strong>settings.py</strong>：这个文件包含了所有的项目配置。将来我们会一直提到这个文件！</li>
<li><strong>urls.py</strong>：这个文件负责映射我们项目中的路由和路径。例如，如果你想在访问URL <code>/ about/</code> 时显示某些内容，则必须先在这里做映射关系。</li>
<li><strong>wsgi.py</strong>：该文件是用于部署的简单网关接口。你可以暂且先不用关心她的内容，就先让他在那里就好了。</li>
</ul>
<p>django自带了一个简单的网络服务器。在开发过程中非常方便，所以我们无需安装任何其他软件即可在本地运行项目。我们可以通过执行命令来测试一下它：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver </span><br></pre></td></tr></table></figure>

<p>访问web, <a href="http://localhost:8000即可看到。">http://localhost:8000即可看到。</a></p>
<p>在Django的哲学中，我们有两个重要的概念：</p>
<ul>
<li><strong>app</strong>：是一个可以做完成某件事情的Web应用程序。一个应用程序通常由一组<strong>models(数据库表)<strong>，</strong>views(视图)<strong>，</strong>templates(模板)<strong>，</strong>tests(测试)</strong> 组成。</li>
<li><strong>project</strong>：是配置和应用程序的集合。一个项目可以由多个应用程序或一个应用程序组成。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在项目中新建一个应用</span><br><span class="line">django-admin startapp boards</span><br></pre></td></tr></table></figure>

<p>如何新建一个视图？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在views中新建一个header page+response </span><br><span class="line">def home(request):</span><br><span class="line">    return HttpResponse(&quot;hello world&quot;)</span><br><span class="line"># 在urls中新建一个路由匹配规则， 正则</span><br><span class="line">from boards import views </span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(r&#x27;^$&#x27;, views.home, name=&#x27;home&#x27;),</span><br><span class="line">]</span><br><span class="line"># ^$开始到结束，匹配空路径 </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>test</title>
    <url>/2022/02/06/test/</url>
    <content><![CDATA[<p>this is test</p>
<p>this is test</p>
<p>this is test</p>
<p>this is test</p>
<p>search is ok ?  i  dont know<br>yes</p>
]]></content>
      <categories>
        <category>test</category>
      </categories>
  </entry>
  <entry>
    <title>《经济学通识》</title>
    <url>/2021/10/10/2021-10-10-%E3%80%8A%E7%BB%8F%E6%B5%8E%E5%AD%A6%E9%80%9A%E8%AF%86%E3%80%8B/</url>
    <content><![CDATA[<h2 id="《经济学通识》"><a href="#《经济学通识》" class="headerlink" title="《经济学通识》"></a>《经济学通识》</h2><p>作者： 薛兆丰</p>
<p>摘录：</p>
<ul>
<li> 一项资产的价值，总是它未来收入的折线，而过去投入的成本是沉没成本，不论大小都不影响资产的现值。</li>
<li>以纯朴的眼光看，人类至少面临四项普遍约束：（1）东西不够；（2）生命有限；（3）互相依赖；和（4）需要协调。人类种种制度安排，一概是为了应付这些约束而衍生的。粗略地概括，这四项约束对应着四类经济理论：（1）需求定律；（2）利息理论；（3）制度理论；和（4）宏观理论。</li>
<li>读书“瘾”也是一样。没有人生来就喜欢读书。得先在“阅读理解力”上作投资。要识字、要懂文法、要自己写过、要学过天文地理，懂得人情世故，要读得多，享受才能油然而生。有些人酷爱读书，要读书才够过瘾，而有些人则只看杂志，有些人看报纸就满足了，有些人只能看懂漫画，有些人就只看电视。对“阅读理解力”的投资不同，追求享受的方式就不同。</li>
<li>科斯理论的这两个思想渊源，有三个重要的含义： 一，在解决生产资源分配时，要紧的永远是边际的数值，而不是平均或总计的数值； 二，在协调资源的争用时，要紧的是要存在私有产权； 三，只要存在私有产权，产权所有者的个数就并不重要，也就是说，不管生产要素由多少人拥有，只要他们能保持充分的理智，他们就会达致相同的生产资源分配方案。</li>
<li>增加合作，并不意味着減少竞争；要鼓励竞争，也未必要靠遏制合作来实现。我们深化对合作的理解，也就是深化了对竞争的理解。</li>
<li>第六，价格决定成本，而不是成本决定价格。价格是由对最终成品的供求决定的，决定了以后，再倒过来决定生产原料的价格。房价是完全由供求决定的，房价被供求决定后，才倒过来决定土地的拍卖价格和开发商的利润。这因果关系，是学习价格规律的难点和重点，要想个不停，才能明白。到此请重读第四点。    第七，需求旺，有原因。（1）农民进城，数以亿计，创人类纪录。（2）住房面积和质量提高，购房者的平均年龄提前。（3）人均寿命延长，退休年期增加，但养儿防老已不可能，而养老保障并不健全，购房便成了人们储蓄保值的常用手段。购房月供三千，一千实为租金，两千实为储蓄。在上述因素的推动下房价高涨实属正常，而并非个别人的阴谋。非得要说是阴谋，那么大可以清者自清，选择只租不买，自动退出购房大军。到此请重读第三点。    第八，价格规律与市场状态无关。不管中国的市场是否成熟、官商有没有勾结、政府是否廉洁、行业是否垄断</li>
<li>事实上，金融危机的症结，最重要的是银行受到了政府的操控。出于政治需要或裙带关系，银行冒险将借来的外汇转贷给经营不善的国内企业，然而到期后，这些落后的企业无法清偿借款。改变这种状况的药方，就是切断政府意志与银行贷款之间的联系，消灭政策贷款和裙带贷款，增强银行的独立性和风险意识。金融危机并不表明自由经济的机器失效了，恰恰相反，引发连串问题的症结，正在于那些违反自由经济原则的环节。 金融危机的另一个原因，是那些既有中央银行、又实施汇率管制的国家，在将借来的外汇转贷给国内企业时，以该国的本位币来记账。由于这些国家往往未能成功地抑制货币发行量，所以该国的货币一旦贬值，企业到期的还款，就无法折合成足够的外汇，进而引发债务危机。 第三个原因，是大型的私人金融机构的投资失误。如美国“长期资本管理（LTCM）”的亏蚀，致使相关的以高杠杆率放款的银行濒临破产。这些不顾风险的银行，是咎由自取的。 第四个原因，是某些地区的货币体制出现了漏洞，引致投机者兴风作浪。例如香港，在实施警花货币发行局的七项措施以前，只要大量沽出港元，就能大幅扯高港元利率。本来，忠实地执行1983年所设计的联系汇率制度，这种情况是不会发生的。国际投资者看准了这个漏洞，连番操纵香港的汇市和股市，从中获利。</li>
<li>哈耶克断言：如何协调千万人之间的行为，如何利用分散在千万人头脑中的信息，才是真正的经济学核心问题。 </li>
<li>知道此岸，也了解彼岸，改革的困难，都是过渡的困难……经济改革如果不定下“事前规则”，而靠“酌情处理”来推进，就必然阻力重重，越改越难，越改越慢。 其实，成功的经济制度，并不在于改造人们的思想，而在于激励人们的行动。 每个人的资源和时间有限，用来上产此，就不能生产彼。”顾此“的成本就是”失彼“，选择”失彼“最小的”顾此“，就是这个人的相对优势。由于这始终是自己跟自己比的结果，所以任何人都永远具有相对优势。 成本就是放弃了的最好机会。 与富人为伍，你的处境会改善。不是因为你可以仰仗他们的仁慈，而是因为你在某方面的成本必定比他们低，是因为你有颠扑不破的相对优势。他们处于自私，就会与你分工合作。 他们享受现代化成果的同时，呼吁别人选择落后。 革命的蓝图越宏伟，就越容易推延，就越是画饼充饥。</li>
<li>只要知识是增长的，那么必定有部分知识是我们明天才知道而今天不知道的，那既然社会是受我们的知识影响的，那么社会的发展就是不可预测的 </li>
<li>一个能在市场上靠其产品获利的卖家，不可能通过搭售其他产品，来获得超额利润。</li>
<li>现实有约束，愿望得取舍。这是经济学者理解世界的出发点。</li>
<li>供求”先决定最终产品的“价格”，而最终产品的“价格”再决定原材料的“成本”。 </li>
<li>但不要试图说服我，给你个基尼系数，你就有本事告诉我将会发生什么。</li>
<li>数据本身不足以说明问题，因为它至少同时支持两种对立的情况 </li>
<li>这是说，即使是同一个人，究竞是”风险爱好者”、”风险 厌恶者”还是”风险漠视者”，也与其所处的财富水平有关。 美国哲学家罗尔斯（J. Rawls) , 因”公平”而盛名远播。他 用了一个生动的比喻，来证明”公平”是先于一切”公约”的。 罗尔斯说，有人生于豪门，有人生于陋室，一切皆出偶然，只能 听天由命：但是，在投胎之前，若人们能聚首一堂，他们会达成 怎样的协议呢？罗尔斯推断，由于每个人都对自己将来的命运懷 然不知，为了规避风险，即使每个人都出于自私，他们也必定会 达成一个”公平公约”，即在出生后趋向于”均分”每个人与生 俱来的一切，因为这样能使每个人的平均幸福程度达到最大。 罗尔斯这个关于”无知之幕”(veil of ignorance) 的比喻远近 闻名。我的质疑是：即使有过那样的聚会，会上人们真会一致赞 成”公平公约”吗？答案是未必！ 因为只要他们当中有些是”风 险喜爱者”，那么后者就一定宁愿挺而走险，不会受”结果公 平”的方案。毕竞，即使在现实生活中，我们也没见过自愿买完 彩票后，又要求全部参与者平分奖金的人群。</li>
<li>按“价高者得”原则筛选出来的不是贫富，而是需求的大小</li>
<li>而人们从来就只有权衡和取舍，而没有绝对的刚需</li>
<li>人的欲望是无止境的，所以世界上的经济商品永远都是稀缺的。</li>
<li>如何协调千万人之间的行为，如何利用分散在千万人头脑中的信息，才是真正的经济学核心问题 </li>
<li>要解决问题，就必须通过市场，就必须由分立的个人并行处理他们独自拥有的信息，这样才能协调众人的行为和分散的信息</li>
<li>供求决定售价，售价决定成本</li>
<li>这个世界的任何商品，其价值都是因为有人争夺才产生的 </li>
<li>正是一国对异国资源的需求，决定了汇率</li>
<li>寻求知识是辛苦的，保持理性是吃力的 </li>
<li>“民主”是按多数原则，集体商议如何行使国家暴力，来干预人与人之间本来可以缔结的契约，本来可以进行的贸易以及本来可以保有的产业 </li>
<li>任何管制都只能改变人们竞争的方式，而无法消除竞争本身</li>
<li>经济学人应该看清一般人不容易看到的一面</li>
<li>事物的价值完全依赖于每个个人的主观判断</li>
<li>只要有人群，就存在对事物的不同估值，就会出现交易；只要有选择，就必然有机会成本；只要存在时间，就存在耐用品，就会刺激投资 </li>
<li>市场从不失灵。那并不是市场失灵，而是解释失灵。 “外部性”恰恰不是因为市场失灵，而是因为缺乏市场。不是产权失灵，而是产权缺席。 天真的发问，有时可以重塑对世情的理解。 逻辑上可能出现的“市场失灵”，恰恰就是被市场的出现而修复的。 产品的价格不是事前根据成本决定的，而是事后根据市场钞票投票的结果决定的。定价由供求决定，与成本无关。 出价太低的卖家或出价过高的买家，其谈判力强；出价太高的卖家或还价过低的买家，其谈判力弱。</li>
<li>重要的问题是：政府向地产商征税，或者向购房者征税，两者有区别吗？经济学明白无误地告诉我们：两者没有任何区别。不管政府规定税赋是向哪一方征收的，都不影响买卖双方分担税负的比例。这被戏称为“法律无效定律”（The Law of the Irrelevance of the Laws），是任何接触税务问题的经济学学生必学的内容。</li>
<li>投资和投机，从可观察的行为看，是没有区别的。</li>
<li>歧视行为的影响不是单向的，而是双向的，不仅被歧视者要受影响，歧视者本身也要受影响。</li>
<li>更直截了当地说，选择就是歧视。</li>
<li>概括一下：具体情景下的供需关系，决定了单笔交易价；无数单笔交易价累加，形成了统计学意义上的均价；时间和条件不同，均价也就不同，而想求索产品的真正“原价”只能是折腾，注定徒劳无功；真正帮助顾客享受低价的方法，不是通过“纵向原价监管”来减少单笔交易间的价格离差，而是让卖家充分竞争、形成稳定而统一的交易平台，从而让顾客通过“横向实时比价”来获得低价。</li>
<li>消费者的选择行为，是与贸易保护主义者的口号背道而驰的。贸易保护主义者总是声称，消费者需要质量更高的产品，而进口的大米有虫、进口的西红柿太小、进口的香蕉改了基因、进口的面条缺乏韧性。问题不在于他们说的是不是事实，而是他们假借消费者的名义，限制了消费者选择劣质产品的自由。</li>
<li>从经济学看，道路不是公用品（public goods），而是私用品（private goods）。所谓公用品，指的是一个人用不影响其他人用的物品。典型的例子是音乐旋律、故事情节、科学定理等。公用品既可以由政府提供，如公共电视台的节目；也可以由个人提供，如带版权的电影和书籍。 私用品，指“一个人用了别人就不能用”的物品，包括粮食、电力、用水、医疗服务、教育设施、国家公园、交通工具和公路航道等。私用品也是既可以由政府提供，也可以由个人或者私营机构提供的。关键是，不论谁提供，也不论提供者是否向使用者收费，私用品的“一个人用了别人就不能用”的属性不变。公路就是这样：尽管它很可能是政府铺设的，而政府也很可能不收费，但一条车道，一辆车用了，别的车就不能同时同地使用，所以才会发生拥堵。其他私用品，也一概如是。</li>
<li>要知道，经济学家常说交易双方是自愿的，是双赢的。这没错，但他们还说了第三句话，即交易往往会使第三方受损。经济学上所说的“帕雷托最优”状态——交易后双方得益，且没有任何第三方受损的状态——是几乎不会出现的。也就是说，任何自愿交易的背后，几乎总是能够找到一些不同程度受损害的人。</li>
<li>假设市场上存在两个互相竞争的标准或平台，分别称为方案甲和方案乙，两者都具有正的网络效应，即参与的用户越多就越具价值，其中方案甲的价值，能从2人参与时的10元上升到10人参与时的20元，而方案乙的价值，能从2人参与时的4元上升到10人参与时的34元。尽管当参与者增加到10人时，方案乙优于方案甲，但人们是否会由于方案甲的初期价值较高，而在路径依赖的作用下，被方案甲锁住而无法选择当用户数量增加后价值后来居上的方案乙呢？ 两位经济学家的回答是：取决于方案乙是否“有主”。如果方案乙是无主的，那它就会得不到推广而被放弃，而这不是“市场所造成的失败”，而是“缺乏市场所造成的失败”。反之，如果方案乙是有主的，那么其主就会设法先垫支部分未来收入，补贴方案乙的早期用户，从而推动方案乙尽快达到超越方案甲的盈利规模。在这个过程中，拥有标准或平台的产权、从而形成动力、努力预测未来收益、筹资补贴先到用户、从而扩大网络规模、提高网络增值速度等环节，恰恰是市场挣脱“路径依赖陷阱”的关键步骤。</li>
<li>唯一应该反对的垄断，就是政府设置的准入障碍和特许经营。如果解除了政府保护，市场上出现的一切似乎是垄断的竞争形态，其实就都是自由竞争的结果。</li>
<li>弗里德曼（Milton Friedman）曾经列举过四种效率递减的花钱模式：一，花自己的钱替自己办事；二，花自己的钱替别人办事；三，花别人的钱替自己办事；四，花别人的钱替别人办事。</li>
<li>经济学家阿尔钦说得准确：“竞争从来都是在需求者和需求者之间展开的，或在供应者和供应者之间展开的。需求者和供应者之间不存在竞争。”</li>
<li>1960年代，法律经济学创始人戴瑞德（Aaron Director，1901-2004）曾经发现一个规律，即任何政府针对穷人的补贴措施，最终都会让中产阶级得益，而由极穷者和极富者付账。</li>
<li>所谓“管制汇率”，就是一国通过强行控制进出口商品量和外币兑换量，把本国货币的币值，硬性维持在某个先定的价位上。……而“自主汇率”，就是一国的货币当局只盯着本国的物价水平，以维持物价稳定为原则来控制货币流通量，而让本国货币与外币的兑换率自由浮动。至于“联系汇率”，则是本国货币与某国外币按固定汇率进行兑换。</li>
<li><strong>人的思想五花八门，而人的行动却大同小异；因为前者不承受代价，后者承受代价。</strong></li>
<li>很多人并不了解罢工的真正含义。不工作是旷工，集体不工作是集体旷工，生病不工作是请假，雇主允许不工作是放假，要求加薪是劳资协议，集体要求加薪是集体协议，自己卷铺盖走人是辞工。都不是罢工。 只有通过（1）在关键时刻忽然停止工作、使得雇主临时无法找到别人替代，或（2）占着工作岗位不工作，并且设法阻止别人代替自己工作，来要挟雇主增加工资或福利的行为，才叫罢工。占着位置不干活并且不让别人代替自己干活，是罢工的基本特征。罢工就是集体敲竹杠，就是集体违约，而且必然包含暴力因素。 临时以停止工作为威胁来要求加薪，是罢工的雏形。在1902年美国的Alaska Packers’ Association v. Domenico 案中，雇主准备了渔船，雇用了渔民，从旧金山出发到阿拉斯加捕捞三文鱼。船到了目的地后，渔民们便宣布临时要求加薪，否则就停止工作，这叫罢工。同样，1965年在美国爆发了葡萄园罢工，大量的葡萄眼看就要烂掉，采摘工人集体停工并要求增加工资，这也是罢工。敲竹杠是罢工的首要特征。</li>
<li>斯密并非写了两部自相矛盾的著作，分别供市场经济的怀疑这和支持者引用。相反，他通过《道德情操论》和《国富论》构造了一个自洽体系：由于人不仅是自私的，而且还天生需要通过满足小范围的同情心来换取快感，所以不仅需要在私人领域强调爱心，而且也更需要在公众领域强调应由自私之心在看不见的手的引导下来推动公益，并强调要警惕自私的掌权者对市场机制的破坏。只有这样，才能理解斯密为什么被视为市场经济之父，而不是计划经济或福利主义之父。</li>
<li>首次为阿尔钦带来国际声誉，并为经济学科学找到了稳固的落脚点的，是在他1950年发表的《不确定性、进化和经济理论》 （Uncertainty,Evolution, and Economic Theory )一文。该文的背景很简单：当时有两位大经济学家（Richard Lester和Fritz Machlup）在争论，企业家究竟有没有在计算边际成本和边际收益。阿尔钦回答：计算与否不重要，重要的是背后主宰企业家存活的客观规律；由于存在不确定性，所以人们在逻辑上不可能求得最大化； 人们只是在争取存活；即使（或虽然）人人都是傻瓜，物竞天择的规律也仍然时刻在发挥作用。 人们总想随心所欲，但因为必须为自己的所作所为负责，所以才不得不尽量保持理性。这正是阿尔钦（Armen Alchian）在1950年的《莫测、进化和经济理论》一文的深刻主题：不管人的主观上是否有意识地追求最大化，客观上只有那些成功地达到了最大化的人或集体才能在竞争中存活。 </li>
<li>价格有三个作用，一是传递信息，二是激励最有效的生产，三是分配产品。市场上的每个人都根据价格所蕴含的信息，选择生存方式和调整生产节奏，并以社会成本最低的方式分配产品</li>
<li>世界上不存在绝对刚性的需求，人们不可能不惜任何代价地追求某个目标。 人际需求不可比原则：效用只能自己跟自己比，不能拿人与人比。 人们有追求免费服务的自由，却没有逃避付出代价的自由。</li>
<li>正是客流暴增，才导致了火车票的涨价。火车票提价的幅度是多少，取决于客流增加的幅度，而跟乘客的心理承受能力扯不上任何关系。</li>
<li>现实可能不受欢迎，甚至令人憎恶，但经济评论的任务，应该是客观地解释真实的世界，而不是给读者发送歪曲的信息，流于用一厢情愿的愿望来博取读者的欢心。</li>
<li>愿意出高价买火车票的人，他所挣得的钞票，是他在别的场合向社会其他人提供服务换来的。也就是说，他为争夺火车票而作出的努力，已经得到了社会其他人的认可。</li>
<li>多年前、老友尹忠东教了我三件事情、会我受益无穷。一，他要我讨论问题或写文章时不要用比喻；二他告诉我有一个经济学家名字叫“弗里德曼”；三，他告诉我人的言辞与行动往往是背道而驰的，说是一套，做往往是另一套；人的思想和言论可谓五花八门，但行动却是高度一致的 这第三点，是我理解人性、理解学术争论、理解市场之美的起点。要对付“不确定性”，要提高对未来的预测力，减少资源浪费或空置的现象，人类不仅需要精准的知识，还需要追求知识和信息的原始动力，而追求知识和信息，往往是昂贵而痛苦的过程，而其中的试金石，就是到市场上赌一手，因为市场会不动声色地对你的判断恰如其分的奖惩。</li>
<li>政府不再负责分配住房，大量农村人口涌入城市，城市交通网络极不发达，政府批租土地有限，而居民收入预期逐年增长，这些因素全都表明中国的住房需求不是泡沫，而是真实的、强劲的、递增的、不可能靠行政手段打压下去的</li>
<li>这是说，即使‘政府有责任’，也并不等于‘政府有能力’。政府可以轻而易举地推出各种管制措施，但这些管制措施既不能替代、也不能增加真实的供应。这是经济学教训的核心。未掌握经济学的人，往往异想天开，以为政府有多大责任就能有多大能力，于是赋予政府极大的责任，让他包办衣食住行、生老病死，结果造就了上世纪‘计划经济’的大悲剧。</li>
<li>诺贝尔经济学奖得主加里 贝克尔教授，以研究家庭、犯罪和歧视问题闻名，他给‘歧视’下了定义：只有当歧视者愿意放弃一定的利益，例如收入、利益、工资或者享受，以便满足他个人的偏好时，才是歧视。</li>
<li>那个搔首弄姿的明星，之所以赚大钱，是因为市场对她有需求。你可以讨厌她，但得承认，别的很多人喜欢她，所以她的劳动力才值钱；而不是反过来，因为她投入的成本低，所以她的表演就不值钱。培养博士和专家的成本确实很大，但他们如果去扫地，那就只能接受扫地的工资，而他们过去钻研学问的成本与此无关。如果我搬到总统套房里写专栏，那么应该提高我的稿费吗？不。 归根结底，市场的‘供需’是劳动力价格的唯一决定因素。</li>
<li>根据维基百科的定义：‘庞氏骗局就是靠投资者或后继投资者的钱来还钱，而不是靠实际盈利来还钱的运作。它通常靠别人所不能的回报来吸引新的投资者，而这些回报通常是短期还款，它要么高的不正常，要么就是持续地不正常。这种生生不息的回报需要不断增长的现金流来维持。’ …… 有别于次，庞氏骗局的特征，是举债人刻意、反复、系统地向放款人谎报其经营所得和还款来源。甄别的关键，一是举债人的还款究竟来自经营的盈利，还是新的举债；二是放贷人在做出放贷决定时，究竟是清楚了解举债人的财务运作模式，还是受到了刻意的蒙骗。</li>
<li>考试是考书上的，不要东看西看。但平时思想的时候，就要东看西看、东想西想才行。</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>转载iptables</title>
    <url>/2021/11/22/2021-11-22-iptables%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="iptables概念"><a href="#iptables概念" class="headerlink" title="iptables概念"></a>iptables概念</h1><p>这篇文章会尽量以通俗易懂的方式描述iptables的相关概念，请耐心的读完它。</p>
<p> 你好顶顶顶的</p>
<h2 id="防火墙相关概念"><a href="#防火墙相关概念" class="headerlink" title="防火墙相关概念"></a>防火墙相关概念</h2><p>此处先描述一些相关概念。</p>
<p>从逻辑上讲。防火墙可以大体分为主机防火墙和网络防火墙。</p>
<ul>
<li><p>主机防火墙：针对于单个主机进行防护。</p>
</li>
<li><p>网络防火墙：往往处于网络入口或边缘，针对于网络入口进行防护，服务于防火墙背后的本地局域网。</p>
</li>
</ul>
<p>网络防火墙和主机防火墙并不冲突，可以理解为，网络防火墙主外（集体）， 主机防火墙主内（个人）。</p>
<p>从物理上讲，防火墙可以分为硬件防火墙和软件防火墙。</p>
<ul>
<li><p>硬件防火墙：在硬件级别实现部分防火墙功能，另一部分功能基于软件实现，性能高，成本高。</p>
</li>
<li><p>软件防火墙：应用软件处理逻辑运行于通用硬件平台之上的防火墙，性能低，成本低。<br><img src="https://www.zsythink.net/wp-content/uploads/ueditor/php/upload/image/20170212/1486863972980583.png"></p>
</li>
</ul>
<p>那么在此处，我们就来聊聊Linux的iptables</p>
<p><em><strong>iptables</strong></em>其实不是真正的防火墙，我们可以把它理解成一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的安全框架中，这个安全框架才是真正的防火墙，这个框架的名字叫<em><strong>netfilter</strong></em></p>
<p>netfilter才是防火墙真正的安全框架（framework），netfilter位于内核空间。</p>
<p>iptables其实是一个命令行工具，位于用户空间，我们用这个工具操作真正的框架。</p>
<p>netfilter/iptables（下文中简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。</p>
<p>Netfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：</p>
<p>网络地址转换(Network Address Translate)</p>
<p>数据包内容修改</p>
<p>以及数据包过滤的防火墙功能</p>
<p>所以说，虽然我们使用service iptables start启动iptables”服务”，但是其实准确的来说，iptables并没有一个守护进程，所以并不能算是真正意义上的服务，而应该算是内核提供的功能。</p>
<h2 id="iptables基础"><a href="#iptables基础" class="headerlink" title="iptables基础"></a>iptables基础</h2><p>我们知道iptables是按照规则来办事的，我们就来说说规则（rules），规则其实就是网络管理员预定义的条件，规则一般的定义为”如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的主要工作就是添加、修改和删除这些规则。</p>
<p>这样说可能并不容易理解，我们来换个容易理解的角度，从头说起.</p>
<p>当客户端访问服务器的web服务时，客户端发送报文到网卡，而tcp/ip协议栈是属于内核的一部分，所以，客户端的信息会通过内核的TCP协议传输到用户空间中的web服务中，而此时，客户端报文的目标终点为web服务所监听的套接字（IP：Port）上，当web服务需要响应客户端请求时，web服务发出的响应报文的目标终点则为客户端，这个时候，web服务所监听的IP与端口反而变成了原点，我们说过，netfilter才是真正的防火墙，它是内核的一部分，所以，如果我们想要防火墙能够达到”防火”的目的，则需要在内核中设置关卡，所有进出的报文都要通过这些关卡，经过检查后，符合放行条件的才能放行，符合阻拦条件的则需要被阻止，于是，就出现了input关卡和output关卡，而这些关卡在iptables中不被称为”关卡,而被称为”链”。<br><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_1.png"></p>
<p>其实我们上面描述的场景并不完善，因为客户端发来的报文访问的目标地址可能并不是本机，而是其他服务器，当本机的内核支持IP_FORWARD时，我们可以将报文转发给其他服务器，所以，这个时候，我们就会提到iptables中的其他”关卡”，也就是其他”链，他们就是  “路由前”、”转发”、”路由后”，他们的英文名是</p>
<p><strong>PREROUTING、FORWARD、POSTROUTING</strong></p>
<p>也就是说，当我们启用了防火墙功能时，报文需要经过如下关卡，也就是说，根据实际情况的不同，报文经过链”可能不同。如果报文需要转发，那么报文则不会经过input链发往用户空间，而是直接在内核空间中经过forward链和postrouting链转发出去的。</p>
<p><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_2.png"></p>
<p>所以，根据上图，我们能够想象出某些常用场景中，报文的流向：</p>
<p>到本机某进程的报文：PREROUTING –&gt; INPUT</p>
<p>由本机转发的报文：PREROUTING &gt; FORWARD –&gt; POSTROUTING</p>
<p>由本机的某进程发出报文（通常为响应报文）：OUTPUT –&gt; POSTROUTING</p>
<h2 id="链的概念"><a href="#链的概念" class="headerlink" title="链的概念"></a>链的概念</h2><p>现在，我们想象一下，这些”关卡”在iptables中为什么被称作”链”呢？我们知道，防火墙的作用就在于对经过的报文匹配”规则”，然后执行对应的”动作”,所以，当报文经过这些关卡的时候，则必须匹配这个关卡上的规则，但是，这个关卡上可能不止有一条规则，而是有很多条规则，当我们把这些规则串到一个链条上的时候，就形成了”链,所以，我们把每一个”关卡”想象成如下图中的模样  ，这样来说，把他们称为”链更为合适，每个经过这个”关卡的报文，都要将这条链”上的所有规则匹配一遍，如果有符合条件的规则，则执行规则对应的动作。<br><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_3.png"></p>
<h2 id="表的概念"><a href="#表的概念" class="headerlink" title="表的概念"></a>表的概念</h2><p>我们再想想另外一个问题，我们对每个”链上都放置了一串规则，但是这些规则有些很相似，比如，A类规则都是对IP或者端口的过滤，B类规则是修改报文，那么这个时候，我们是不是能把实现相同功能的规则放在一起呢，必须能的。</p>
<p>我们把具有相同功能的规则的集合叫做”表，所以说，不同功能的规则，我们可以放置在不同的表中进行管理，而iptables已经为我们定义了4种表，每种表对应了不同的功能，而我们定义的规则也都逃脱不了这4种功能的范围，所以，学习iptables之前，我们必须先搞明白每种表 的作用。</p>
<p>iptables为我们提供了如下规则的分类，或者说，iptables为我们提供了如下”表</p>
<ul>
<li><p>filter表：负责过滤功能，防火墙；内核模块：iptables_filter</p>
</li>
<li><p>nat表：network address translation，网络地址转换功能；内核模块：iptable_nat</p>
</li>
<li><p>mangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle</p>
</li>
<li><p>raw表：关闭nat表上启用的连接追踪机制；iptable_raw</p>
</li>
</ul>
<p>也就是说，我们自定义的所有规则，都是这四种分类中的规则，或者说，所有规则都存在于这4张”表中。</p>
<h2 id="表链关系"><a href="#表链关系" class="headerlink" title="表链关系"></a>表链关系</h2><p>但是我们需要注意的是，某些”链”中注定不会包含”某类规则”，就像某些关卡”天生就不具备某些功能一样，比如，A”关卡只负责打击陆地敌人，没有防空能力，B关卡”只负责打击空中敌人，没有防御步兵的能力，C”关卡”可能比较NB，既能防空，也能防御陆地敌人，D关卡”最屌，海陆空都能防。</p>
<p>那让我们来看看，每个”关卡”都有哪些能力，或者说，让我们看看每个”链上的规则都存在于哪些”表”中。</p>
<p>我们还是以图为例，先看看prerouting链”上的规则都存在于哪些表中。</p>
<blockquote>
<p>注意：下图只用于说明prerouting链上的规则存在于哪些表中，并没有描述表的顺序。<br><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_4.png"></p>
</blockquote>
<p>这幅图是什么意思呢？它的意思是说，prerouting链”只拥有nat表、raw表和mangle表所对应的功能，所以，prerouting中的规则只能存放于nat表、raw表和mangle表中。</p>
<p>那么，根据上述思路，我们来总结一下，每个”关卡”都拥有什么功能，</p>
<p>或者说，每个”链”中的规则都存在于哪些”表”中。</p>
<ul>
<li><p>PREROUTING      的规则可以存在于：raw表，mangle表，nat表。</p>
</li>
<li><p>INPUT          的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。</p>
</li>
<li><p>FORWARD         的规则可以存在于：mangle表，filter表。</p>
</li>
<li><p>OUTPUT         的规则可以存在于：raw表mangle表，nat表，filter表。</p>
</li>
<li><p>POSTROUTING      的规则可以存在于：mangle表，nat表。</p>
</li>
</ul>
<p>但是，我们在实际的使用过程中，往往是通过”表作为操作入口，对规则进行定义的，之所以按照上述过程介绍iptables，是因为从”关卡”的角度更容易从入门的角度理解，但是为了以便在实际使用的时候，更加顺畅的理解它们，此处我们还要将各”表与”链”的关系罗列出来，</p>
<p>表（功能）&lt;–&gt;   链（钩子）：</p>
<p>raw     表中的规则可以被哪些链使用：PREROUTING，OUTPUT</p>
<p>mangle  表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING</p>
<p>nat     表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有）</p>
<p>filter  表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT</p>
<p>其实我们还需要注意一点，因为数据包经过一个”链的时候，会将当前链的所有规则都匹配一遍，但是匹配时总归要有顺序，我们应该一条一条的去匹配，而且我们说过，相同功能类型的规则会汇聚在一张”表中，那么，哪些”表中的规则会放在”链的最前面执行呢，这时候就需要有一个优先级的问题，我们还拿prerouting”链”做图示。</p>
<p><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_5.png"><br>prerouting链中的规则存放于三张表中，而这三张表中的规则执行的优先级如下：</p>
<p>raw –&gt; mangle –&gt; nat</p>
<p>但是我们知道，iptables为我们定义了4张”表,当他们处于同一条链”时，执行的优先级如下。</p>
<p>优先级次序（由高而低）：</p>
<p>raw –&gt; mangle &gt; nat –&gt; filter</p>
<p>但是我们前面说过，某些链天生就不能使用某些表中的规则，所以，4张表中的规则处于同一条链的目前只有output链，它就是传说中海陆空都能防守的关卡。</p>
<p>为了更方便的管理，我们还可以在某个表里面创建自定义链，将针对某个应用程序所设置的规则放置在这个自定义链中，但是自定义链接不能直接使用，只能被某个默认的链当做动作去调用才能起作用，我们可以这样想象，自定义链就是一段比较”短”的链子，这条短”链子上的规则都是针对某个应用程序制定的，但是这条短的链子并不能直接使用，而是需要”焊接”在iptables默认定义链子上，才能被IPtables使用，这就是为什么默认定义的”链”需要把”自定义链”当做动作”去引用的原因。这是后话，后面再聊，在实际使用时我们即可更加的明白。</p>
<h2 id="数据经过防火墙的流程"><a href="#数据经过防火墙的流程" class="headerlink" title="数据经过防火墙的流程"></a>数据经过防火墙的流程</h2><p>结合上述所有的描述，我们可以将数据包通过防火墙的流程总结为下图：</p>
<p><img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_6.png"></p>
<p>我们在写Iptables规则的时候，要时刻牢记这张路由次序图，灵活配置规则。</p>
<p>我们将经常用到的对应关系重新写在此处，方便对应图例查看。</p>
<p>链的规则存放于哪些表中（从链到表的对应关系）：</p>
<ul>
<li><p>PREROUTING   的规则可以存在于：raw表，mangle表，nat表。</p>
</li>
<li><p>NPUT        的规则可以存在于：mangle表，filter表，（centos7中还有nat表，centos6中没有）。</p>
</li>
<li><p> FORWARD      的规则可以存在于：mangle表，filter表。</p>
</li>
<li><p>OUTPUT       的规则可以存在于：raw表mangle表，nat表，filter表。</p>
</li>
<li><p>POSTROUTING  的规则可以存在于：mangle表，nat表。</p>
</li>
</ul>
<p>表中的规则可以被哪些链使用（从表到链的对应关系）：</p>
<ul>
<li><p> raw     表中的规则可以被哪些链使用：PREROUTING，OUTPUT</p>
</li>
<li><p>mangle  表中的规则可以被哪些链使用：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING</p>
</li>
<li><p>nat     表中的规则可以被哪些链使用：PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有）</p>
</li>
<li><p>filter  表中的规则可以被哪些链使用：INPUT，FORWARD，OUTPUT</p>
</li>
</ul>
<p>下图中nat表在centos7中的情况就不再标明。</p>
<p> <img src="https://www.zsythink.net/wp-content/uploads/2017/02/021217_0051_7.png"></p>
<h2 id="规则的概念"><a href="#规则的概念" class="headerlink" title="规则的概念"></a>规则的概念</h2><p>说了一圈又说回来了，在上述描述中我们一直在提规则，可是没有细说，现在说说它。</p>
<p>先说说规则的概念，然后再通俗的解释它。</p>
<p>规则：根据指定的匹配条件来尝试匹配每个流经此处的报文，一旦匹配成功，则由规则后面指定的处理动作进行处理；</p>
<p>那么我们来通俗的解释一下什么是iptables的规则，之前打过一个比方，每条链”都是一个”关卡，每个通过这个”关卡”的报文都要匹配这个关卡上的规则，如果匹配，则对报文进行对应的处理，比如说，你我二人此刻就好像两个报文”，你我二人此刻都要入关，可是城主有命，只有器宇轩昂的人才能入关，不符合此条件的人不能入关，于是守关将士按照城主制定的”规则，开始打量你我二人，最终，你顺利入关了，而我已被拒之门外，因为你符合器宇轩昂的标准，所以把你”放行”了，而我不符合标准，所以没有被放行，其实，”器宇轩昂”就是一种”匹配条件”，”放行”就是一种”动作”，”匹配条件”与”动作”组成了规则。</p>
<p>了解了规则的概念，那我们来聊聊规则的组成部分,此处只是大概的将规则的结构列出，后面的文章中会单独对规则进行总结。</p>
<p>规则由匹配条件和处理动作组成。</p>
<p><strong>匹配条件</strong><br>匹配条件分为基本匹配条件与扩展匹配条件</p>
<p><strong>基本匹配条件</strong>：</p>
<p>源地址Source IP，目标地址 Destination IP</p>
<p>上述内容都可以作为基本匹配条件。</p>
<p><strong>扩展匹配条件</strong>：</p>
<p>除了上述的条件可以用于匹配，还有很多其他的条件可以用于匹配，这些条件泛称为扩展条件，这些扩展条件其实也是netfilter中的一部分，只是以模块的形式存在，如果想要使用这些条件，则需要依赖对应的扩展模块。</p>
<p>源端口Source Port, 目标端口Destination Port</p>
<p>上述内容都可以作为扩展匹配条件</p>
<p><strong>处理动作</strong><br>处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。</p>
<p>此处列出一些常用的动作，之后的文章会对它们进行详细的示例与总结：</p>
<ul>
<li><p>ACCEPT：允许数据包通过。</p>
</li>
<li><p>DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。</p>
</li>
<li><p>REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。</p>
</li>
<li><p>SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。</p>
</li>
<li><p>MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。</p>
</li>
<li><p>DNAT：目标地址转换。</p>
</li>
<li><p>REDIRECT：在本机做端口映射。</p>
</li>
<li><p>LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>harbor搭建、镜像推拉、主从备份</title>
    <url>/2021/12/23/2021-12-02-harbor%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<h3 id="1-harbor是什么"><a href="#1-harbor是什么" class="headerlink" title="1 harbor是什么"></a>1 harbor是什么</h3><p>Harbor是一个开源镜像仓库，它使用策略和基于角色的访问控制来保护镜像，确保镜像被扫描并没有漏洞，并将图像标记为受信任的。Harbor是CNCF的一个孵化的项目，提供合规、性能和互操作性，帮助您在Kubernetes和Docker等云本地计算平台上一致安全地管理工件。</p>
<p>简而言之， harbor就是跟docker hub差不多的镜像仓库，是一个开源仓库框架。  <a href="https://demo.goharbor.io/">https://demo.goharbor.io</a>.这是官网提供的样本仓库，看看就明白了。 搭建出来的东西和这个是一样的。 类似的仓库也有不少，官方给出了比较。<a href="https://goharbor.io/docs/2.4.0/install-config/harbor-compatibility-list/">Harbor docs | Harbor Compatibility List (goharbor.io)</a></p>
<h3 id="2-harbor特性"><a href="#2-harbor特性" class="headerlink" title="2 harbor特性"></a>2 harbor特性</h3><h3 id="3-harbor搭建"><a href="#3-harbor搭建" class="headerlink" title="3 harbor搭建"></a>3 harbor搭建</h3><p>harbor提供release, 搭建也很简单，只是harbor本身不提供证书， 需要第三方或自签的证书。  </p>
<h4 id="3-1-搭建harbor基本要求"><a href="#3-1-搭建harbor基本要求" class="headerlink" title="3.1 搭建harbor基本要求"></a>3.1 搭建harbor基本要求</h4><p><strong>硬件</strong></p>
<table>
<thead>
<tr>
<th align="left">Resource</th>
<th align="left">Minimum</th>
<th align="left">Recommended</th>
</tr>
</thead>
<tbody><tr>
<td align="left">CPU</td>
<td align="left">2 CPU</td>
<td align="left">4 CPU</td>
</tr>
<tr>
<td align="left">Mem</td>
<td align="left">4 GB</td>
<td align="left">8 GB</td>
</tr>
<tr>
<td align="left">Disk</td>
<td align="left">40 GB</td>
<td align="left">160 GB</td>
</tr>
</tbody></table>
<p><strong>软件</strong></p>
<table>
<thead>
<tr>
<th align="left">Software</th>
<th align="left">Version</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Docker engine</td>
<td align="left">Version 17.06.0-ce+ or higher</td>
<td align="left">For installation instructions, see <a href="https://docs.docker.com/engine/installation/">Docker Engine documentation</a></td>
</tr>
<tr>
<td align="left">Docker Compose</td>
<td align="left">Version 1.18.0 or higher</td>
<td align="left">For installation instructions, see <a href="https://docs.docker.com/compose/install/">Docker Compose documentation</a></td>
</tr>
<tr>
<td align="left">Openssl</td>
<td align="left">Latest is preferred</td>
<td align="left">Used to generate certificate and keys for Harbor</td>
</tr>
</tbody></table>
<p><strong>网络</strong></p>
<table>
<thead>
<tr>
<th align="left">Port</th>
<th align="left">Protocol</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">443</td>
<td align="left">HTTPS</td>
<td align="left">Harbor portal and core API accept HTTPS requests on this port. You can change this port in the configuration file.</td>
</tr>
<tr>
<td align="left">4443</td>
<td align="left">HTTPS</td>
<td align="left">Connections to the Docker Content Trust service for Harbor. Only required if Notary is enabled. You can change this port in the configuration file.</td>
</tr>
<tr>
<td align="left">80</td>
<td align="left">HTTP</td>
<td align="left">Harbor portal and core API accept HTTP requests on this port. You can change this port in the configuration file.</td>
</tr>
</tbody></table>
<h3 id="3-2-配置HTTPS访问harbor"><a href="#3-2-配置HTTPS访问harbor" class="headerlink" title="3.2  配置HTTPS访问harbor"></a>3.2  配置HTTPS访问harbor</h3><p>Harbor不提供证书。所以配置HTTPS时，需要先创建SSL证书。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir harbor &amp;&amp; cd harbor</span><br><span class="line"># 生成CA证书私钥</span><br><span class="line">openssl genrsa -out ca.key 4096</span><br><span class="line"></span><br><span class="line"># 生成CA证书</span><br><span class="line">openssl req -x509 -new -nodes -sha512 -days 3650 \</span><br><span class="line"> -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=myharbor.com&quot; \</span><br><span class="line"> -key ca.key \</span><br><span class="line"> -out ca.crt</span><br><span class="line"> </span><br><span class="line"># 生成服务器证书, 证书通常包含一个.crt文件和一个.key文件，例如myharbor.com.crt和myharbor.com.key</span><br><span class="line">openssl genrsa -out myharbor.com.key 4096</span><br><span class="line"></span><br><span class="line"># 生成证书签名请求(CSR) </span><br><span class="line">openssl req -sha512 -new \</span><br><span class="line">    -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=myharbor.com&quot; \</span><br><span class="line">    -key myharbor.com.key \</span><br><span class="line">    -out myharbor.com.csr</span><br><span class="line">    </span><br><span class="line"># 生成x509 v3扩展文件 </span><br><span class="line">cat &gt; v3.ext &lt;&lt;-EOF</span><br><span class="line">authorityKeyIdentifier=keyid,issuer</span><br><span class="line">basicConstraints=CA:FALSE</span><br><span class="line">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment</span><br><span class="line">extendedKeyUsage = serverAuth</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line"></span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1=myharbor.com</span><br><span class="line">DNS.2=myharbor</span><br><span class="line">DNS.3=hostname</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 使用v3.ext文件为Harbor主机生成证书 </span><br><span class="line">openssl x509 -req -sha512 -days 3650 \</span><br><span class="line">    -extfile v3.ext \</span><br><span class="line">    -CA ca.crt -CAkey ca.key -CAcreateserial \</span><br><span class="line">    -in myharbor.com.csr \</span><br><span class="line">    -out myharbor.com.crt </span><br><span class="line">    </span><br><span class="line"># 向harbor和docker提供证书 </span><br><span class="line"># 将服务器证书和密钥复制到您的Harbor host的证书文件夹中</span><br><span class="line">mkdir /data/cert/ </span><br><span class="line">cp myharbor.com.crt /data/cert/</span><br><span class="line">cp myharbor.com.key /data/cert/</span><br><span class="line"></span><br><span class="line"># 将.crt转换为.cert，以供Docker使用</span><br><span class="line">openssl x509 -inform PEM -in /data/cert/myharbor.com.crt -out /data/cert/myharbor.com.cert</span><br><span class="line"></span><br><span class="line"># 将服务器证书、密钥和CA文件复制到Harbor主机的Docker证书文件夹中 </span><br><span class="line">mkdir -p /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp myharbor.com.cert /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp myharbor.com.key /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp ca.crt /etc/docker/certs.d/myharbor.com/ </span><br><span class="line"></span><br><span class="line"># 查看证书</span><br><span class="line">[root@k8s-node02 harbor]# ll -a</span><br><span class="line">-rw-r--r--  1 root root 2029 Dec 23 15:37 ca.crt</span><br><span class="line">-rw-r--r--  1 root root 3243 Dec 23 15:37 ca.key</span><br><span class="line">-rw-r--r--  1 root root   17 Dec 23 15:41 ca.srl</span><br><span class="line">-rw-r--r--  1 root root 2090 Dec 23 15:42 myharbor.com.cert</span><br><span class="line">-rw-r--r--  1 root root 2090 Dec 23 15:41 myharbor.com.crt</span><br><span class="line">-rw-r--r--  1 root root 1704 Dec 23 15:40 myharbor.com.csr</span><br><span class="line">-rw-r--r--  1 root root 3243 Dec 23 15:40 myharbor.com.key</span><br><span class="line">-rw-r--r--  1 root root  261 Dec 23 15:41 v3.ext</span><br><span class="line"></span><br><span class="line"># 重启docker </span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="3-3-下载安装包"><a href="#3-3-下载安装包" class="headerlink" title="3.3 下载安装包"></a>3.3 下载安装包</h3><p>分为在线安装和离线两种， 都是一样的，按需选择。 这里我们直接选择在线安装，安装包小一点</p>
<p>下载<a href="https://github.com/goharbor/harbor/releases">Releases · goharbor/harbor (github.com)</a></p>
<p>这里我选择最新版本，<code> harbor-online-installer-v2.4.1.tgz</code>  ，版本按需选择</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压 </span><br><span class="line">[root@k8s-node02 harbor]# tar -xvf  harbor-online-installer-v2.4.1.tgz</span><br><span class="line">[root@k8s-node02 harbor]# ll</span><br><span class="line">total 48</span><br><span class="line">-rw-r--r-- 1 root root 2029 Dec 23 15:37 ca.crt</span><br><span class="line">-rw-r--r-- 1 root root 3243 Dec 23 15:37 ca.key</span><br><span class="line">-rw-r--r-- 1 root root   17 Dec 23 15:41 ca.srl</span><br><span class="line">drwxr-xr-x 2 root root 4096 Dec 23 15:46 harbor</span><br><span class="line">-rw-r--r-- 1 root root 9844 Dec 23 15:45 harbor-online-installer-v2.4.1.tgz</span><br><span class="line">-rw-r--r-- 1 root root 2090 Dec 23 15:42 myharbor.com.cert</span><br><span class="line">-rw-r--r-- 1 root root 2090 Dec 23 15:41 myharbor.com.crt</span><br><span class="line">-rw-r--r-- 1 root root 1704 Dec 23 15:40 myharbor.com.csr</span><br><span class="line">-rw-r--r-- 1 root root 3243 Dec 23 15:40 myharbor.com.key</span><br><span class="line">-rw-r--r-- 1 root root  261 Dec 23 15:41 v3.ext</span><br><span class="line">[root@k8s-node02 harbor]# cd harbor/</span><br><span class="line">[root@k8s-node02 harbor]# ll</span><br><span class="line">total 36</span><br><span class="line">-rw-r--r-- 1 root root  3361 Dec 16 12:24 common.sh</span><br><span class="line">-rw-r--r-- 1 root root  8999 Dec 16 12:24 harbor.yml.tmpl</span><br><span class="line">-rwxr-xr-x 1 root root  2500 Dec 16 12:24 install.sh</span><br><span class="line">-rw-r--r-- 1 root root 11347 Dec 16 12:24 LICENSE</span><br><span class="line">-rwxr-xr-x 1 root root  1881 Dec 16 12:24 prepare</span><br></pre></td></tr></table></figure>



<h3 id="3-4-配置harbor-yml"><a href="#3-4-配置harbor-yml" class="headerlink" title="3.4 配置harbor.yml"></a>3.4 配置harbor.yml</h3><p>在harbor.yml中配置harbor,</p>
<p>这些参数在运行install.sh脚本安装或重新配置Harbor时生效。</p>
<p>在初始部署和启动Harbor之后，也可以在Harbor Web中执行额外的配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp  harbor.yml.tmpl  harbor.yml</span><br><span class="line">vim  harbor.yml</span><br><span class="line"># 至少要配置hostname 与 证书路径</span><br><span class="line">hostname: myharbor.com</span><br><span class="line"># https related config</span><br><span class="line">https:</span><br><span class="line">  # https port for harbor, default is 443</span><br><span class="line">  port: 443</span><br><span class="line">  # The path of cert and key files for nginx</span><br><span class="line">  certificate: /data/cert/myharbor.com.cert</span><br><span class="line">  private_key: /data/cert/myharbor.com.key</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置生效 </span><br><span class="line">./prepare</span><br><span class="line"># 部署</span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure>

<p>然后仓库就搭建好了，本地修改hosts就可以通过域名访问，或直接通过ip访问</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/harbor.png"></p>
<p>参数如下，来自官网<a href="https://goharbor.io/docs/2.4.0/install-config/configure-yml-file/">Harbor docs | Configure the Harbor YML File (goharbor.io)</a></p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">子参数</th>
<th align="left">用法</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>hostname</code></td>
<td align="left">None</td>
<td align="left">指定要部署Harbor的目标主机的IP地址或完全限定域名(FQDN)。这是您访问harbor和注册服务的地址。例如，“192.168.1.10”或“reg.yourdomain.com”。注册表服务必须能够被外部客户端访问，所以不要指定’ localhost ‘、’ 127.0.0.1 ‘或’ 0.0.0.0 ‘作为主机名。</td>
</tr>
<tr>
<td align="left"><code>http</code></td>
<td align="left"></td>
<td align="left">不要在生产环境中使用HTTP。只有在没有连接到外部internet的测试或开发环境中，才可以接受使用HTTP。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">HTTP的端口号，海港门户和Docker命令。默认值是80。</td>
</tr>
<tr>
<td align="left"><code>https</code></td>
<td align="left"></td>
<td align="left">使用HTTPS访问海港门户和令牌/通知服务。在生产环境和没有气隙隔离的环境中始终使用HTTPS。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">使用HTTPS访问海港门户和令牌/通知服务。在生产环境和没有气隙隔离的环境中始终使用HTTPS。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>certificate</code></td>
<td align="left">SSL证书的路径</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>private_key</code></td>
<td align="left">SSL密钥的路径。</td>
</tr>
<tr>
<td align="left"><code>internal_tls</code></td>
<td align="left"></td>
<td align="left">使用HTTPS在港口组件之间通信</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">将该标志设置为“true”意味着启用了内部tls</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>dir</code></td>
<td align="left">包含内部证书和密钥的目录的路径</td>
</tr>
<tr>
<td align="left"><code>harbor_admin_password</code></td>
<td align="left">None</td>
<td align="left">设置Harbor系统管理员的初始密码。此密码仅在第一次启动Harbor时使用。在随后的登录中，将忽略此设置，并在Harbor Portal中设置管理员密码。默认用户名和密码为“admin”和“Harbor12345”。</td>
</tr>
<tr>
<td align="left"><code>database</code></td>
<td align="left"></td>
<td align="left">使用本地PostgreSQL数据库。您可以选择配置一个外部数据库，在这种情况下，您可以禁用这个选项。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>password</code></td>
<td align="left">使用本地PostgreSQL数据库。您可以选择配置一个外部数据库，在这种情况下，您可以禁用这个选项。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>max_idle_conns</code></td>
<td align="left">空闲连接池中的最大连接数。如果设置为&lt;=0，则不保留空闲连接。缺省值是50。如果不配置，则为2。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>max_open_conns</code></td>
<td align="left">‘数据库的最大打开连接数。如果&lt;= 0，则没有打开连接的数量限制。对于到Harbor数据库的最大连接，默认值是100。如果不配置，则为0。</td>
</tr>
<tr>
<td align="left"><code>data_volume</code></td>
<td align="left">None</td>
<td align="left">**目标主机上存储Harbor数据的位置。即使在移除和/或重新创建Harbor的集装箱时，该数据也保持不变。您可以选择配置外部存储，在这种情况下禁用该选项并启用’ storage_service ‘。默认值是’ /data ‘。</td>
</tr>
<tr>
<td align="left"><code>trivy</code></td>
<td align="left"></td>
<td align="left">配置 Trivy 扫描.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>ignore_unfixed</code></td>
<td align="left">将标志设置为“true”，只显示已修复的漏洞。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>skip_update</code></td>
<td align="left">您可能希望在测试或CI/CD环境中启用此标志，以避免GitHub速率限制问题。如果启用了该标志，你必须手动下载“trivy-offline.tar.gz”存档文件，提取“trivy.db”和“元数据”。Json ‘文件，并将它们挂载到容器的’ /home/scanner/.cache/trivy/db/trivy.db ‘路径下。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>insecure</code></td>
<td align="left">设置标志为true，跳过验证注册表证书。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">`github_token</td>
<td align="left">‘设置GitHub访问令牌下载Trivy DB。Trivy DB由Trivy从GitHub发布页面下载。从GitHub匿名下载受每小时60次请求的限制。通常，这样的速率限制对于生产操作来说已经足够了。如果出于任何原因，这还不够，你可以通过指定GitHub访问令牌将速率限制到每小时5000个请求。有关GitHub速率限制的更多信息，请咨询<a href="https://developer.github.com/v3/#rate-limiting%E3%80%82%E6%82%A8%E5%8F%AF%E4%BB%A5%E6%8C%89%E7%85%A7https://help.github.com/en/github/authen%E4%B8%AD%E7%9A%84%E8%AF%B4%E6%98%8E%E5%88%9B%E5%BB%BAGitHub%E4%BB%A4%E7%89%8C">https://developer.github.com/v3/#rate-limiting。您可以按照https://help.github.com/en/github/authen中的说明创建GitHub令牌</a></td>
</tr>
<tr>
<td align="left"><code>jobservice</code></td>
<td align="left"><code>max_job_workers</code></td>
<td align="left">作业服务中复制工作者的最大数量。对于每个映像复制作业，一个工作人员将存储库中的所有标记同步到远程目标。增加这个数量将允许系统中有更多的并发复制作业。但是，由于每个worker都会消耗一定数量的网络/CPU/IO资源，因此需要根据主机的硬件资源来设置该属性的值。默认值是10。</td>
</tr>
<tr>
<td align="left"><code>notification</code></td>
<td align="left"><code>webhook_job_max_retry</code></td>
<td align="left">设置web hook任务的最大重试次数。默认值是10。</td>
</tr>
<tr>
<td align="left"><code>chart</code></td>
<td align="left"><code>absolute_url</code></td>
<td align="left">设置为“启用”，以便Chart使用绝对URL。设置为’ disabled ‘以便Chart使用相对URL。</td>
</tr>
<tr>
<td align="left"><code>log</code></td>
<td align="left"></td>
<td align="left">配置日志记录。Harbor使用’ rsyslog ‘来收集每个容器的日志</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>level</code></td>
<td align="left">将日志级别设置为“debug”、“info”、“warning”、“error”或“fatal”。默认为’ info ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>local</code></td>
<td align="left">设置日志保留参数:’ rotate_count ‘:日志文件在被删除之前会旋转’ rotate_count ‘多次。如果count为0，则删除旧版本而不是旋转。默认值是50。’ rotate_size ‘:日志文件只有在增长大于’ rotate_size ‘字节时才会被旋转。k表示千字节，M表示兆字节，G表示千兆字节。‘100’、‘100k’、‘100M’和‘100G’都是有效值。默认为200M。’ location ‘:设置存储日志的目录。默认值是’ /var/log/harbor ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>external_endpoint</code></td>
<td align="left">启用此选项，将日志转发到syslog服务器。“protocol”:syslog服务器的传输协议。默认是TCP。’ host ‘: syslog服务器的URL。’ port ‘: syslog服务器监听的端口</td>
</tr>
<tr>
<td align="left"><code>proxy</code></td>
<td align="left"></td>
<td align="left"><em>：</em>配置代理以供普通适配器、复制jobservice和Harbor使用。如果不需要代理，请留空。一些代理服务器有白名单设置，如果Trivy是启用的，你需要添加以下url到代理服务器白名单:’ github-releases.githubusercontent.com ‘，和’ *.s3. amazonaws.com/ ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>http_proxy</code></td>
<td align="left">Configure an HTTP proxy, for example, <code>http://my.proxy.com:3128</code>.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>https_proxy</code></td>
<td align="left">Configure an HTTPS proxy, for example, <code>http://my.proxy.com:3128</code>.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>no_proxy</code></td>
<td align="left">Configure when not to use a proxy, for example, <code>127.0.0.1,localhost,core,registry</code>.</td>
</tr>
</tbody></table>
<h2 id="可选参数-Parameters"><a href="#可选参数-Parameters" class="headerlink" title="可选参数 Parameters"></a>可选参数 Parameters</h2><p>The following table lists the additional, optional parameters that you can set to configure your Harbor deployment beyond the minimum required settings. To enable a setting, you must uncomment it in <code>harbor.yml</code> by deleting the leading <code>#</code> character.</p>
<table>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Sub-Parameters</th>
<th align="left">Description and Additional Parameters</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>external_url</code></td>
<td align="left">None</td>
<td align="left">Enable this option to use an external proxy. When enabled, the hostname is no longer used.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>storage_service</code></td>
<td align="left"></td>
<td align="left">By default, Harbor stores images and charts on your local filesystem. In a production environment, you might want to use another storage backend instead of the local filesystem. The parameters listed below are the configurations for the registry. See <em>Configuring Storage Backend</em> below for more information about how to configure a different backend.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>ca_bundle</code></td>
<td align="left">The path to the custom root CA certificate, which is injected into the trust store of registry and chart repository containers. This is usually needed if internal storage uses a self signed certificate.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>filesystem</code></td>
<td align="left">The default is <code>filesystem</code>, but you can set <code>azure</code>, <code>gcs</code>, <code>s3</code>, <code>swift</code> and <code>oss</code>. For information about how to configure other backends, see <a href="https://goharbor.io/docs/2.4.0/install-config/configure-yml-file/#backend">Configuring a Storage Backend</a> below. Set <code>maxthreads</code> to limit the number of threads to the external provider. The default is 100.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>redirect</code></td>
<td align="left">Set <code>disable</code> to <code>true</code> when you want to disable registry redirect</td>
</tr>
<tr>
<td align="left"><code>external_database</code></td>
<td align="left"></td>
<td align="left">Configure external database settings, if you disable the local database option. Currently, Harbor only supports PostgreSQL database. You must create three databases for Harbor core, Notary server, and Notary signer. The tables are generated automatically when Harbor starts up.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>harbor</code></td>
<td align="left">Configure an external database for Harbor data.<code>host</code>: Hostname of the Harbor database.<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the core Harbor database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.<code>max_idle_conns</code>: The maximum number of connections in the idle connection pool. If &lt;=0 no idle connections are retained. The default value is 2.<code>max_open_conns</code>: The maximum number of open connections to the database. If &lt;= 0 there is no limit on the number of open connections. The default value is 0.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>notary_signer</code></td>
<td align="left">Configure an external database for the Notary signer database<code>host</code>: Hostname of the Notary signer database<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the Notary signer database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>notary_server</code></td>
<td align="left"><code>host</code>: Hostname of the Notary server database.<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the Notary server database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.e</td>
</tr>
<tr>
<td align="left"><code>external_redis</code></td>
<td align="left"></td>
<td align="left">Configure an external Redis instance.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>host</code></td>
<td align="left">redis_host:redis_port of the external Redis instance. If you are using Sentinel mode, this part should be host_sentinel1:port_sentinel1,host_sentinel2:port_sentinel2</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>sentinel_master_set</code></td>
<td align="left">Only set this when using Sentinel mode</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>password</code></td>
<td align="left">Password to connect to the external Redis instance.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>registry_db_index</code></td>
<td align="left">Database index for Harbor registry.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>jobservice_db_index</code></td>
<td align="left">Database index for jobservice.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>chartmuseum_db_index</code></td>
<td align="left">Database index for Chart museum.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>trivy_db_index</code></td>
<td align="left">Database index for Trivy adapter.</td>
</tr>
<tr>
<td align="left"><code>metric</code></td>
<td align="left"></td>
<td align="left">Configure exposing Harbor instance metrics to a specified port and path</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">Enable exposing metrics on your Harbor instance by setting this to <code>true</code>. Default is <code>false</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">Port metrics are exposed on. Default is <code>9090</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>path</code></td>
<td align="left">Path metrics are exposed on. Default is <code>/metrics</code></td>
</tr>
<tr>
<td align="left"><code>trace</code></td>
<td align="left"></td>
<td align="left">Configure exposing Distributed tracing data</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">Enable exposing tracing on your Harbor instance by setting this to <code>true</code>. Default is <code>false</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>sample_rate</code></td>
<td align="left">Set the sample rate of tracing. For example, set sample_rate to <code>1</code> if you wanna sampling 100% of trace data; set <code>0.5</code> if you wanna sampling 50% of trace data, and so forth</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>namespace</code></td>
<td align="left">Namespace used to differenciate different harbor services, which will set to attribute with key <code>service.namespace</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>attributes</code></td>
<td align="left">The attributes is a key value dict contains user defined customized attributes used to initialize trace provider, and all of these atributes will added to trace data</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>jaeger</code></td>
<td align="left"><code>endpoint</code>: The url of endpoint(for example <code>http://127.0.0.1:14268/api/traces</code>). set endpoint means export to jaeger collector via http.<code>username:</code>: Username used to connect endpoint. Left empty if not needed.<code>password:</code>: Password used to connect endpoint. Left empty if not needed.<code>agent_host</code>: The host name of jaeger agent. Set agent_host means export data to jaeger agent via udp.<code>agent_port:</code>: The port name of jaeger agent.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>otel</code></td>
<td align="left"><code>endpoint</code>: The hostname and port for otel compitable backend(for example <code>127.0.0.1:4318</code>).<code>url_path:</code>: The url path of endpoint(for example <code>127.0.0.1:4318</code>)<code>compression:</code>: If enabling data compression<code>insecure</code>: Ignore cert verification for otel backend<code>timeout:</code>: The timeout of data transfer</td>
</tr>
</tbody></table>
<h3 id="3-镜像推送"><a href="#3-镜像推送" class="headerlink" title="3 镜像推送"></a>3 镜像推送</h3><p>镜像推送也很方便，现在仓库web中新建账户zhangsan，再新建项mytest, 在项目中添加zhangsan. 就可以在项目-&gt;镜像仓库中看到推拉镜像的参考命令。十分的人性化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/harbor2.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 登陆到harbor </span><br><span class="line">[root@k8s-node02 harbor]# docker login myharbor.com</span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line">Login Succeeded</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>harbor</title>
    <url>/2021/12/23/2021-12-23-harbor%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<h3 id="1-harbor是什么"><a href="#1-harbor是什么" class="headerlink" title="1 harbor是什么"></a>1 harbor是什么</h3><p>Harbor是一个开源镜像仓库，它使用策略和基于角色的访问控制来保护镜像，确保镜像被扫描并没有漏洞，并将图像标记为受信任的。Harbor是CNCF的一个孵化的项目，提供合规、性能和互操作性，帮助您在Kubernetes和Docker等云本地计算平台上一致安全地管理工件。</p>
<p>简而言之， harbor就是跟docker hub差不多的镜像仓库，是一个开源仓库框架。  <a href="https://demo.goharbor.io/">https://demo.goharbor.io</a>.这是官网提供的样本仓库，看看就明白了。 搭建出来的东西和这个是一样的。 类似的仓库也有不少，官方给出了比较。<a href="https://goharbor.io/docs/2.4.0/install-config/harbor-compatibility-list/">Harbor docs | Harbor Compatibility List (goharbor.io)</a></p>
<h3 id="2-harbor特性"><a href="#2-harbor特性" class="headerlink" title="2 harbor特性"></a>2 harbor特性</h3><h3 id="3-harbor搭建"><a href="#3-harbor搭建" class="headerlink" title="3 harbor搭建"></a>3 harbor搭建</h3><p>harbor提供release, 搭建也很简单，只是harbor本身不提供证书， 需要第三方或自签的证书。  </p>
<h4 id="3-1-搭建harbor基本要求"><a href="#3-1-搭建harbor基本要求" class="headerlink" title="3.1 搭建harbor基本要求"></a>3.1 搭建harbor基本要求</h4><p><strong>硬件</strong></p>
<table>
<thead>
<tr>
<th align="left">Resource</th>
<th align="left">Minimum</th>
<th align="left">Recommended</th>
</tr>
</thead>
<tbody><tr>
<td align="left">CPU</td>
<td align="left">2 CPU</td>
<td align="left">4 CPU</td>
</tr>
<tr>
<td align="left">Mem</td>
<td align="left">4 GB</td>
<td align="left">8 GB</td>
</tr>
<tr>
<td align="left">Disk</td>
<td align="left">40 GB</td>
<td align="left">160 GB</td>
</tr>
</tbody></table>
<p><strong>软件</strong></p>
<table>
<thead>
<tr>
<th align="left">Software</th>
<th align="left">Version</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Docker engine</td>
<td align="left">Version 17.06.0-ce+ or higher</td>
<td align="left">For installation instructions, see <a href="https://docs.docker.com/engine/installation/">Docker Engine documentation</a></td>
</tr>
<tr>
<td align="left">Docker Compose</td>
<td align="left">Version 1.18.0 or higher</td>
<td align="left">For installation instructions, see <a href="https://docs.docker.com/compose/install/">Docker Compose documentation</a></td>
</tr>
<tr>
<td align="left">Openssl</td>
<td align="left">Latest is preferred</td>
<td align="left">Used to generate certificate and keys for Harbor</td>
</tr>
</tbody></table>
<p><strong>网络</strong></p>
<table>
<thead>
<tr>
<th align="left">Port</th>
<th align="left">Protocol</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">443</td>
<td align="left">HTTPS</td>
<td align="left">Harbor portal and core API accept HTTPS requests on this port. You can change this port in the configuration file.</td>
</tr>
<tr>
<td align="left">4443</td>
<td align="left">HTTPS</td>
<td align="left">Connections to the Docker Content Trust service for Harbor. Only required if Notary is enabled. You can change this port in the configuration file.</td>
</tr>
<tr>
<td align="left">80</td>
<td align="left">HTTP</td>
<td align="left">Harbor portal and core API accept HTTP requests on this port. You can change this port in the configuration file.</td>
</tr>
</tbody></table>
<h3 id="3-2-配置HTTPS访问harbor"><a href="#3-2-配置HTTPS访问harbor" class="headerlink" title="3.2  配置HTTPS访问harbor"></a>3.2  配置HTTPS访问harbor</h3><p>Harbor不提供证书。所以配置HTTPS时，需要先创建SSL证书。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir harbor &amp;&amp; cd harbor</span><br><span class="line"># 生成CA证书私钥</span><br><span class="line">openssl genrsa -out ca.key 4096</span><br><span class="line"></span><br><span class="line"># 生成CA证书</span><br><span class="line">openssl req -x509 -new -nodes -sha512 -days 3650 \</span><br><span class="line"> -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=myharbor.com&quot; \</span><br><span class="line"> -key ca.key \</span><br><span class="line"> -out ca.crt</span><br><span class="line"> </span><br><span class="line"># 生成服务器证书, 证书通常包含一个.crt文件和一个.key文件，例如myharbor.com.crt和myharbor.com.key</span><br><span class="line">openssl genrsa -out myharbor.com.key 4096</span><br><span class="line"></span><br><span class="line"># 生成证书签名请求(CSR) </span><br><span class="line">openssl req -sha512 -new \</span><br><span class="line">    -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=myharbor.com&quot; \</span><br><span class="line">    -key myharbor.com.key \</span><br><span class="line">    -out myharbor.com.csr</span><br><span class="line">    </span><br><span class="line"># 生成x509 v3扩展文件 </span><br><span class="line">cat &gt; v3.ext &lt;&lt;-EOF</span><br><span class="line">authorityKeyIdentifier=keyid,issuer</span><br><span class="line">basicConstraints=CA:FALSE</span><br><span class="line">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment</span><br><span class="line">extendedKeyUsage = serverAuth</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line"></span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1=myharbor.com</span><br><span class="line">DNS.2=myharbor</span><br><span class="line">DNS.3=hostname</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 使用v3.ext文件为Harbor主机生成证书 </span><br><span class="line">openssl x509 -req -sha512 -days 3650 \</span><br><span class="line">    -extfile v3.ext \</span><br><span class="line">    -CA ca.crt -CAkey ca.key -CAcreateserial \</span><br><span class="line">    -in myharbor.com.csr \</span><br><span class="line">    -out myharbor.com.crt </span><br><span class="line">    </span><br><span class="line"># 向harbor和docker提供证书 </span><br><span class="line"># 将服务器证书和密钥复制到您的Harbor host的证书文件夹中</span><br><span class="line">mkdir /data/cert/ </span><br><span class="line">cp myharbor.com.crt /data/cert/</span><br><span class="line">cp myharbor.com.key /data/cert/</span><br><span class="line"></span><br><span class="line"># 将.crt转换为.cert，以供Docker使用</span><br><span class="line">openssl x509 -inform PEM -in /data/cert/myharbor.com.crt -out /data/cert/myharbor.com.cert</span><br><span class="line"></span><br><span class="line"># 将服务器证书、密钥和CA文件复制到Harbor主机的Docker证书文件夹中 </span><br><span class="line">mkdir -p /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp myharbor.com.cert /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp myharbor.com.key /etc/docker/certs.d/myharbor.com/</span><br><span class="line">cp ca.crt /etc/docker/certs.d/myharbor.com/ </span><br><span class="line"></span><br><span class="line">cp /data/cert/myharbor.com.cert /etc/docker/certs.d/myharbor.com/</span><br><span class="line"># 查看证书</span><br><span class="line">[root@k8s-node02 harbor]# ll -a</span><br><span class="line">-rw-r--r--  1 root root 2029 Dec 23 15:37 ca.crt</span><br><span class="line">-rw-r--r--  1 root root 3243 Dec 23 15:37 ca.key</span><br><span class="line">-rw-r--r--  1 root root   17 Dec 23 15:41 ca.srl</span><br><span class="line">-rw-r--r--  1 root root 2090 Dec 23 15:42 myharbor.com.cert</span><br><span class="line">-rw-r--r--  1 root root 2090 Dec 23 15:41 myharbor.com.crt</span><br><span class="line">-rw-r--r--  1 root root 1704 Dec 23 15:40 myharbor.com.csr</span><br><span class="line">-rw-r--r--  1 root root 3243 Dec 23 15:40 myharbor.com.key</span><br><span class="line">-rw-r--r--  1 root root  261 Dec 23 15:41 v3.ext</span><br><span class="line"></span><br><span class="line"># 重启docker </span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="3-3-下载安装包"><a href="#3-3-下载安装包" class="headerlink" title="3.3 下载安装包"></a>3.3 下载安装包</h3><p>分为在线安装和离线两种， 都是一样的，按需选择。 这里我们直接选择在线安装，安装包小一点</p>
<p>下载<a href="https://github.com/goharbor/harbor/releases">Releases · goharbor/harbor (github.com)</a></p>
<p>这里我选择最新版本，<code> harbor-online-installer-v2.4.1.tgz</code>  ，版本按需选择</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 解压 </span><br><span class="line">[root@k8s-node02 harbor]# tar -xvf  harbor-online-installer-v2.4.1.tgz</span><br><span class="line">[root@k8s-node02 harbor]# ll</span><br><span class="line">total 48</span><br><span class="line">-rw-r--r-- 1 root root 2029 Dec 23 15:37 ca.crt</span><br><span class="line">-rw-r--r-- 1 root root 3243 Dec 23 15:37 ca.key</span><br><span class="line">-rw-r--r-- 1 root root   17 Dec 23 15:41 ca.srl</span><br><span class="line">drwxr-xr-x 2 root root 4096 Dec 23 15:46 harbor</span><br><span class="line">-rw-r--r-- 1 root root 9844 Dec 23 15:45 harbor-online-installer-v2.4.1.tgz</span><br><span class="line">-rw-r--r-- 1 root root 2090 Dec 23 15:42 myharbor.com.cert</span><br><span class="line">-rw-r--r-- 1 root root 2090 Dec 23 15:41 myharbor.com.crt</span><br><span class="line">-rw-r--r-- 1 root root 1704 Dec 23 15:40 myharbor.com.csr</span><br><span class="line">-rw-r--r-- 1 root root 3243 Dec 23 15:40 myharbor.com.key</span><br><span class="line">-rw-r--r-- 1 root root  261 Dec 23 15:41 v3.ext</span><br><span class="line">[root@k8s-node02 harbor]# cd harbor/</span><br><span class="line">[root@k8s-node02 harbor]# ll</span><br><span class="line">total 36</span><br><span class="line">-rw-r--r-- 1 root root  3361 Dec 16 12:24 common.sh</span><br><span class="line">-rw-r--r-- 1 root root  8999 Dec 16 12:24 harbor.yml.tmpl</span><br><span class="line">-rwxr-xr-x 1 root root  2500 Dec 16 12:24 install.sh</span><br><span class="line">-rw-r--r-- 1 root root 11347 Dec 16 12:24 LICENSE</span><br><span class="line">-rwxr-xr-x 1 root root  1881 Dec 16 12:24 prepare</span><br></pre></td></tr></table></figure>



<h3 id="3-4-配置harbor-yml"><a href="#3-4-配置harbor-yml" class="headerlink" title="3.4 配置harbor.yml"></a>3.4 配置harbor.yml</h3><p>在harbor.yml中配置harbor,</p>
<p>这些参数在运行install.sh脚本安装或重新配置Harbor时生效。</p>
<p>在初始部署和启动Harbor之后，也可以在Harbor Web中执行额外的配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp  harbor.yml.tmpl  harbor.yml</span><br><span class="line">vim  harbor.yml</span><br><span class="line"># 至少要配置hostname 与 证书路径</span><br><span class="line">hostname: myharbor.com</span><br><span class="line"># https related config</span><br><span class="line">https:</span><br><span class="line">  # https port for harbor, default is 443</span><br><span class="line">  port: 443</span><br><span class="line">  # The path of cert and key files for nginx</span><br><span class="line">  certificate: /data/cert/myharbor.com.cert</span><br><span class="line">  private_key: /data/cert/myharbor.com.key</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置生效 </span><br><span class="line">./prepare</span><br><span class="line"># 部署</span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure>

<p>然后仓库就搭建好了，本地修改hosts就可以通过域名访问，或直接通过ip访问</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/harbor.png"></p>
<p>参数如下，来自官网<a href="https://goharbor.io/docs/2.4.0/install-config/configure-yml-file/">Harbor docs | Configure the Harbor YML File (goharbor.io)</a></p>
<table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">子参数</th>
<th align="left">用法</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>hostname</code></td>
<td align="left">None</td>
<td align="left">指定要部署Harbor的目标主机的IP地址或完全限定域名(FQDN)。这是您访问harbor和注册服务的地址。例如，“192.168.1.10”或“reg.yourdomain.com”。注册表服务必须能够被外部客户端访问，所以不要指定’ localhost ‘、’ 127.0.0.1 ‘或’ 0.0.0.0 ‘作为主机名。</td>
</tr>
<tr>
<td align="left"><code>http</code></td>
<td align="left"></td>
<td align="left">不要在生产环境中使用HTTP。只有在没有连接到外部internet的测试或开发环境中，才可以接受使用HTTP。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">HTTP的端口号，海港门户和Docker命令。默认值是80。</td>
</tr>
<tr>
<td align="left"><code>https</code></td>
<td align="left"></td>
<td align="left">使用HTTPS访问海港门户和令牌/通知服务。在生产环境和没有气隙隔离的环境中始终使用HTTPS。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">使用HTTPS访问海港门户和令牌/通知服务。在生产环境和没有气隙隔离的环境中始终使用HTTPS。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>certificate</code></td>
<td align="left">SSL证书的路径</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>private_key</code></td>
<td align="left">SSL密钥的路径。</td>
</tr>
<tr>
<td align="left"><code>internal_tls</code></td>
<td align="left"></td>
<td align="left">使用HTTPS在港口组件之间通信</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">将该标志设置为“true”意味着启用了内部tls</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>dir</code></td>
<td align="left">包含内部证书和密钥的目录的路径</td>
</tr>
<tr>
<td align="left"><code>harbor_admin_password</code></td>
<td align="left">None</td>
<td align="left">设置Harbor系统管理员的初始密码。此密码仅在第一次启动Harbor时使用。在随后的登录中，将忽略此设置，并在Harbor Portal中设置管理员密码。默认用户名和密码为“admin”和“Harbor12345”。</td>
</tr>
<tr>
<td align="left"><code>database</code></td>
<td align="left"></td>
<td align="left">使用本地PostgreSQL数据库。您可以选择配置一个外部数据库，在这种情况下，您可以禁用这个选项。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>password</code></td>
<td align="left">使用本地PostgreSQL数据库。您可以选择配置一个外部数据库，在这种情况下，您可以禁用这个选项。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>max_idle_conns</code></td>
<td align="left">空闲连接池中的最大连接数。如果设置为&lt;=0，则不保留空闲连接。缺省值是50。如果不配置，则为2。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>max_open_conns</code></td>
<td align="left">‘数据库的最大打开连接数。如果&lt;= 0，则没有打开连接的数量限制。对于到Harbor数据库的最大连接，默认值是100。如果不配置，则为0。</td>
</tr>
<tr>
<td align="left"><code>data_volume</code></td>
<td align="left">None</td>
<td align="left">**目标主机上存储Harbor数据的位置。即使在移除和/或重新创建Harbor的集装箱时，该数据也保持不变。您可以选择配置外部存储，在这种情况下禁用该选项并启用’ storage_service ‘。默认值是’ /data ‘。</td>
</tr>
<tr>
<td align="left"><code>trivy</code></td>
<td align="left"></td>
<td align="left">配置 Trivy 扫描.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>ignore_unfixed</code></td>
<td align="left">将标志设置为“true”，只显示已修复的漏洞。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>skip_update</code></td>
<td align="left">您可能希望在测试或CI/CD环境中启用此标志，以避免GitHub速率限制问题。如果启用了该标志，你必须手动下载“trivy-offline.tar.gz”存档文件，提取“trivy.db”和“元数据”。Json ‘文件，并将它们挂载到容器的’ /home/scanner/.cache/trivy/db/trivy.db ‘路径下。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>insecure</code></td>
<td align="left">设置标志为true，跳过验证注册表证书。默认值为“false”。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">`github_token</td>
<td align="left">‘设置GitHub访问令牌下载Trivy DB。Trivy DB由Trivy从GitHub发布页面下载。从GitHub匿名下载受每小时60次请求的限制。通常，这样的速率限制对于生产操作来说已经足够了。如果出于任何原因，这还不够，你可以通过指定GitHub访问令牌将速率限制到每小时5000个请求。有关GitHub速率限制的更多信息，请咨询<a href="https://developer.github.com/v3/#rate-limiting%E3%80%82%E6%82%A8%E5%8F%AF%E4%BB%A5%E6%8C%89%E7%85%A7https://help.github.com/en/github/authen%E4%B8%AD%E7%9A%84%E8%AF%B4%E6%98%8E%E5%88%9B%E5%BB%BAGitHub%E4%BB%A4%E7%89%8C">https://developer.github.com/v3/#rate-limiting。您可以按照https://help.github.com/en/github/authen中的说明创建GitHub令牌</a></td>
</tr>
<tr>
<td align="left"><code>jobservice</code></td>
<td align="left"><code>max_job_workers</code></td>
<td align="left">作业服务中复制工作者的最大数量。对于每个映像复制作业，一个工作人员将存储库中的所有标记同步到远程目标。增加这个数量将允许系统中有更多的并发复制作业。但是，由于每个worker都会消耗一定数量的网络/CPU/IO资源，因此需要根据主机的硬件资源来设置该属性的值。默认值是10。</td>
</tr>
<tr>
<td align="left"><code>notification</code></td>
<td align="left"><code>webhook_job_max_retry</code></td>
<td align="left">设置web hook任务的最大重试次数。默认值是10。</td>
</tr>
<tr>
<td align="left"><code>chart</code></td>
<td align="left"><code>absolute_url</code></td>
<td align="left">设置为“启用”，以便Chart使用绝对URL。设置为’ disabled ‘以便Chart使用相对URL。</td>
</tr>
<tr>
<td align="left"><code>log</code></td>
<td align="left"></td>
<td align="left">配置日志记录。Harbor使用’ rsyslog ‘来收集每个容器的日志</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>level</code></td>
<td align="left">将日志级别设置为“debug”、“info”、“warning”、“error”或“fatal”。默认为’ info ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>local</code></td>
<td align="left">设置日志保留参数:’ rotate_count ‘:日志文件在被删除之前会旋转’ rotate_count ‘多次。如果count为0，则删除旧版本而不是旋转。默认值是50。’ rotate_size ‘:日志文件只有在增长大于’ rotate_size ‘字节时才会被旋转。k表示千字节，M表示兆字节，G表示千兆字节。‘100’、‘100k’、‘100M’和‘100G’都是有效值。默认为200M。’ location ‘:设置存储日志的目录。默认值是’ /var/log/harbor ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>external_endpoint</code></td>
<td align="left">启用此选项，将日志转发到syslog服务器。“protocol”:syslog服务器的传输协议。默认是TCP。’ host ‘: syslog服务器的URL。’ port ‘: syslog服务器监听的端口</td>
</tr>
<tr>
<td align="left"><code>proxy</code></td>
<td align="left"></td>
<td align="left"><em>：</em>配置代理以供普通适配器、复制jobservice和Harbor使用。如果不需要代理，请留空。一些代理服务器有白名单设置，如果Trivy是启用的，你需要添加以下url到代理服务器白名单:’ github-releases.githubusercontent.com ‘，和’ *.s3. amazonaws.com/ ‘。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>http_proxy</code></td>
<td align="left">Configure an HTTP proxy, for example, <code>http://my.proxy.com:3128</code>.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>https_proxy</code></td>
<td align="left">Configure an HTTPS proxy, for example, <code>http://my.proxy.com:3128</code>.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>no_proxy</code></td>
<td align="left">Configure when not to use a proxy, for example, <code>127.0.0.1,localhost,core,registry</code>.</td>
</tr>
</tbody></table>
<h2 id="可选参数-Parameters"><a href="#可选参数-Parameters" class="headerlink" title="可选参数 Parameters"></a>可选参数 Parameters</h2><p>The following table lists the additional, optional parameters that you can set to configure your Harbor deployment beyond the minimum required settings. To enable a setting, you must uncomment it in <code>harbor.yml</code> by deleting the leading <code>#</code> character.</p>
<table>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Sub-Parameters</th>
<th align="left">Description and Additional Parameters</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>external_url</code></td>
<td align="left">None</td>
<td align="left">Enable this option to use an external proxy. When enabled, the hostname is no longer used.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>storage_service</code></td>
<td align="left"></td>
<td align="left">By default, Harbor stores images and charts on your local filesystem. In a production environment, you might want to use another storage backend instead of the local filesystem. The parameters listed below are the configurations for the registry. See <em>Configuring Storage Backend</em> below for more information about how to configure a different backend.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>ca_bundle</code></td>
<td align="left">The path to the custom root CA certificate, which is injected into the trust store of registry and chart repository containers. This is usually needed if internal storage uses a self signed certificate.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>filesystem</code></td>
<td align="left">The default is <code>filesystem</code>, but you can set <code>azure</code>, <code>gcs</code>, <code>s3</code>, <code>swift</code> and <code>oss</code>. For information about how to configure other backends, see <a href="https://goharbor.io/docs/2.4.0/install-config/configure-yml-file/#backend">Configuring a Storage Backend</a> below. Set <code>maxthreads</code> to limit the number of threads to the external provider. The default is 100.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>redirect</code></td>
<td align="left">Set <code>disable</code> to <code>true</code> when you want to disable registry redirect</td>
</tr>
<tr>
<td align="left"><code>external_database</code></td>
<td align="left"></td>
<td align="left">Configure external database settings, if you disable the local database option. Currently, Harbor only supports PostgreSQL database. You must create three databases for Harbor core, Notary server, and Notary signer. The tables are generated automatically when Harbor starts up.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>harbor</code></td>
<td align="left">Configure an external database for Harbor data.<code>host</code>: Hostname of the Harbor database.<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the core Harbor database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.<code>max_idle_conns</code>: The maximum number of connections in the idle connection pool. If &lt;=0 no idle connections are retained. The default value is 2.<code>max_open_conns</code>: The maximum number of open connections to the database. If &lt;= 0 there is no limit on the number of open connections. The default value is 0.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>notary_signer</code></td>
<td align="left">Configure an external database for the Notary signer database<code>host</code>: Hostname of the Notary signer database<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the Notary signer database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>notary_server</code></td>
<td align="left"><code>host</code>: Hostname of the Notary server database.<code>port</code>: Database port.<code>db_name</code>: Database name.<code>username</code>: Username to connect to the Notary server database.<code>password</code>: Password for the account you set in <code>username</code>.<code>ssl_mode</code>: Enable SSL mode.e</td>
</tr>
<tr>
<td align="left"><code>external_redis</code></td>
<td align="left"></td>
<td align="left">Configure an external Redis instance.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>host</code></td>
<td align="left">redis_host:redis_port of the external Redis instance. If you are using Sentinel mode, this part should be host_sentinel1:port_sentinel1,host_sentinel2:port_sentinel2</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>sentinel_master_set</code></td>
<td align="left">Only set this when using Sentinel mode</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>password</code></td>
<td align="left">Password to connect to the external Redis instance.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>registry_db_index</code></td>
<td align="left">Database index for Harbor registry.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>jobservice_db_index</code></td>
<td align="left">Database index for jobservice.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>chartmuseum_db_index</code></td>
<td align="left">Database index for Chart museum.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>trivy_db_index</code></td>
<td align="left">Database index for Trivy adapter.</td>
</tr>
<tr>
<td align="left"><code>metric</code></td>
<td align="left"></td>
<td align="left">Configure exposing Harbor instance metrics to a specified port and path</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">Enable exposing metrics on your Harbor instance by setting this to <code>true</code>. Default is <code>false</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>port</code></td>
<td align="left">Port metrics are exposed on. Default is <code>9090</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>path</code></td>
<td align="left">Path metrics are exposed on. Default is <code>/metrics</code></td>
</tr>
<tr>
<td align="left"><code>trace</code></td>
<td align="left"></td>
<td align="left">Configure exposing Distributed tracing data</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>enabled</code></td>
<td align="left">Enable exposing tracing on your Harbor instance by setting this to <code>true</code>. Default is <code>false</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>sample_rate</code></td>
<td align="left">Set the sample rate of tracing. For example, set sample_rate to <code>1</code> if you wanna sampling 100% of trace data; set <code>0.5</code> if you wanna sampling 50% of trace data, and so forth</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>namespace</code></td>
<td align="left">Namespace used to differenciate different harbor services, which will set to attribute with key <code>service.namespace</code></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>attributes</code></td>
<td align="left">The attributes is a key value dict contains user defined customized attributes used to initialize trace provider, and all of these atributes will added to trace data</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>jaeger</code></td>
<td align="left"><code>endpoint</code>: The url of endpoint(for example <code>http://127.0.0.1:14268/api/traces</code>). set endpoint means export to jaeger collector via http.<code>username:</code>: Username used to connect endpoint. Left empty if not needed.<code>password:</code>: Password used to connect endpoint. Left empty if not needed.<code>agent_host</code>: The host name of jaeger agent. Set agent_host means export data to jaeger agent via udp.<code>agent_port:</code>: The port name of jaeger agent.</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"><code>otel</code></td>
<td align="left"><code>endpoint</code>: The hostname and port for otel compitable backend(for example <code>127.0.0.1:4318</code>).<code>url_path:</code>: The url path of endpoint(for example <code>127.0.0.1:4318</code>)<code>compression:</code>: If enabling data compression<code>insecure</code>: Ignore cert verification for otel backend<code>timeout:</code>: The timeout of data transfer</td>
</tr>
</tbody></table>
<h3 id="3-镜像推送"><a href="#3-镜像推送" class="headerlink" title="3 镜像推送"></a>3 镜像推送</h3><p>镜像推送也很方便，现在仓库web中新建账户zhangsan，再新建项mytest, 在项目中添加zhangsan. 就可以在项目-&gt;镜像仓库中看到推拉镜像的参考命令。十分的人性化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/harbor2.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 登陆到harbor </span><br><span class="line">[root@k8s-node02 harbor]# docker login myharbor.com</span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line">Login Succeeded</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#停止</span><br><span class="line">到harbor目录下</span><br><span class="line">docker-compose stop</span><br></pre></td></tr></table></figure>





<p>可能遇到的问题：</p>
<p> <code>because it doesn&#39;t contain any IP SANs</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# docker login https://172.21.39.225:21017</span><br><span class="line">Username: admin</span><br><span class="line">Password:</span><br><span class="line">Error response from daemon: Get &quot;https://172.21.39.225:21017/v2/&quot;: x509: cannot validate certificate for 172.21.39.225 because it doesn&#x27;t contain any IP SANs</span><br><span class="line"></span><br><span class="line">这是因为修改了默认端口， 需要新建 /etc/docker/certs.d/$hostname$port </span><br></pre></td></tr></table></figure>

<p><code>unknown authority</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Harbor docker login x509 certificate signed by unknown authority</span><br><span class="line">因为证书是自签的， 所以本地docker需要添加 insecurity </span><br><span class="line">vim /etc/docker/daemon.json</span><br><span class="line">&quot;insecure-registries&quot;: [&quot;0.0.0.0/0&quot;]</span><br><span class="line">或者&quot;insecure-registries&quot;: [&quot;172.21.39.225/0&quot;]</span><br><span class="line"># 可能添加失败</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>k8s-securitypolicy</title>
    <url>/2022/01/25/2022-01-25-k8s-securitypolicy/</url>
    <content><![CDATA[<h3 id="1-podsecuritypolicy"><a href="#1-podsecuritypolicy" class="headerlink" title="1 podsecuritypolicy"></a>1 podsecuritypolicy</h3><p>podsecurity policy是一种集群级别的资源， 它对用户能否在pod中使用各种安全相关的操作。缩写psp. 维护资源中配置策略的工作由集成在API服务器中podsecurity准入控制插件完成。 </p>
<p>PodSecurityPolicy对象定义一组条件，以限制pod权限，管理员可以控制以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 运行特权容器  privileged</span><br><span class="line"># 主机命名空间的使用	hostPID, hostIPC</span><br><span class="line"># 主机网络和端口的使用	hostNetwork, hostPorts</span><br><span class="line"># 卷类型的使用	volumes</span><br><span class="line"># 主机文件系统的使用	allowedHostPaths</span><br><span class="line"># 允许特定的 FlexVolume 驱动程序	allowedFlexVolumes</span><br><span class="line"># 分配一个拥有 Pod 卷的 FSGroup	fsGroup</span><br><span class="line"># 需要使用只读根文件系统	readOnlyRootFilesystem</span><br><span class="line"># 容器的用户和组 ID	runAsUser, runAsGroup,supplementalGroups</span><br><span class="line"># 限制升级到 root 权限	allowPrivilegeEscalation, defaultAllowPrivilegeEscalation</span><br><span class="line"># Linux 功能	defaultAddCapabilities, requiredDropCapabilities,allowedCapabilities</span><br><span class="line"># 容器的 SELinux 上下文	seLinux</span><br><span class="line"># 容器的 Allowed Proc Mount 类型	allowedProcMountTypes</span><br><span class="line"># 容器使用的 AppArmor 配置文件	注释</span><br><span class="line">###  容器使用的 seccomp 配置文件	注释</span><br><span class="line"># 容器使用的 sysctl 配置文件	forbiddenSysctls,allowedUnsafeSysctls</span><br></pre></td></tr></table></figure>

<h3 id="2-配置psp的预备条件"><a href="#2-配置psp的预备条件" class="headerlink" title="2 配置psp的预备条件"></a>2 配置psp的预备条件</h3><p>PodSecurityPolicy 资源被创建时，并不执行任何操作。为了使用该资源，需要对发出请求的<strong>useraccount</strong>或者需要被限制的Pod 的<strong>service accout</strong>授权, <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/">RBAC</a> 是一种标准的 Kubernetes 鉴权模式，可以很容易地用来授权策略访问。</p>
<h4 id="2-1-rabc是什么？"><a href="#2-1-rabc是什么？" class="headerlink" title="2.1 rabc是什么？"></a>2.1 rabc是什么？</h4><p>K8s api 服务器可以配置使用一个授权插件来检查用户或sa是否有权限执行动作。</p>
<p>什么是<strong>动作</strong>？ </p>
<p>REST客户端发送get, post, put, delete和其他资源的HTTP请求到特定的url路径上，这些路径表示特定的REST资源，如pod, svs,secret等。  动作包含如下： </p>
<table>
<thead>
<tr>
<th>HTTP</th>
<th>单一资源动词</th>
<th>集合动词</th>
</tr>
</thead>
<tbody><tr>
<td>get, head</td>
<td>get、watch</td>
<td>list、watch</td>
</tr>
<tr>
<td>post</td>
<td>create</td>
<td>n/a</td>
</tr>
<tr>
<td>put</td>
<td>update</td>
<td>n/a</td>
</tr>
<tr>
<td>patch</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>patch</td>
<td>n/a</td>
</tr>
<tr>
<td>delete</td>
<td>delete</td>
<td>deletecollection</td>
</tr>
</tbody></table>
<blockquote>
<p>额外的动词use用于podsecurity policy资源</p>
</blockquote>
<p>资源可以通过<code>kubectl api-resources</code>查看, 当前 k8s 支持两类 API Groups：</p>
<ol>
<li>Core Groups（核心组）， 该分组也可以称之为 Legacy Groups，作为 k8s 最核心的 API ，其特点是没有组的概念，例如 “v1”，在资源对象的定义中表示为 “apiVersion: v1”，属于核心组的资源主要有pod， svc等等。</li>
</ol>
<blockquote>
<p>注意核心组没有组名，只有版本，所以apiGroups的值为空。</p>
</blockquote>
<ol start="2">
<li>具有分组信息的 API， 这种 API 接口以/apis/GROUP_NAME/VERSION URL 路径进行标识，在api-resources定义中表示为 “apiVersion: groupname/version”， 例如 “apiVersion: batch/v1”.</li>
</ol>
<blockquote>
<p>如果通过rke部署集群，cluster.yaml需要开启psp与rbac, 经测试1.4版本可用。</p>
<p> kube-api:<br>       pod_security_policy: true<br>authorization:<br>      mode: rbac</p>
</blockquote>
<h4 id="2-2-如何实现rbac"><a href="#2-2-如何实现rbac" class="headerlink" title="2.2 如何实现rbac?"></a>2.2 如何实现rbac?</h4><p>rbac授权通过两组四种资源来配置的： </p>
<ol>
<li> namespace级别的资源， role和rolebinding</li>
<li> 集群级别的资源， clusterrole和clusterrolebinding</li>
</ol>
<p>前一种是ns级别的限制，另一种是全局的、cluster级别的限制。 </p>
<p>role和clusterrole声明一个角色，表明哪些<strong>动作</strong>可以在哪些<strong>资源</strong>上执行。</p>
<p>rolebindings/clusterrolebindings分别用来将role/clusterrole绑定到sa或ua上</p>
<p><code>serviceaccout</code></p>
<p>在k8s中，service account是给集群中的资源使用，用户是不会去使用，是ns级别的资源，缩写为sa。 创建任何pod都需要指定sa，没有指定就使用默认的sa。当集群中的pod需要跟apiserver申请调用资源时， 该pod指定的sa通过一个rolebinding绑定一个role（或者是通过clusterrolebiding绑定clusterole ）, 这个role/clusterrole里的权限就该pod的权限。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node scprittest]# kubectl get sa -o yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">items:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: ServiceAccount</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: &quot;2022-01-29T08:51:33Z&quot;</span><br><span class="line">    name: default</span><br><span class="line">    namespace: default</span><br><span class="line">    resourceVersion: &quot;271&quot;</span><br><span class="line">    selfLink: /api/v1/namespaces/default/serviceaccounts/default</span><br><span class="line">    uid: abc3bd19-dc94-4228-a190-badfc0749e3b</span><br><span class="line">  secrets:</span><br><span class="line">  - name: default-token-qvqbk</span><br><span class="line">kind: List</span><br><span class="line">metadata:</span><br><span class="line">  resourceVersion: &quot;&quot;</span><br><span class="line">  selfLink: &quot;&quot;</span><br></pre></td></tr></table></figure>

<p>每个ns被创建后会自动创建默认sa, 可以看到默认的sa本身啥也没有，一个sa创建后需要授权绑定role/cluserrole才有权限。</p>
<p><code>useraccount</code></p>
<p>k8s中控制集群的用户, 下面是如何创建用户</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建用户证书key</span><br><span class="line">umask 077; openssl genrsa -out user-a.key 2048     </span><br><span class="line"># 创建用户证书请求，-subj指定组和用户，其中O是组名，CN是用户名</span><br><span class="line">openssl req -new -key user-a.key -out user-a.csr -subj &quot;/O=user-a/CN=user-a&quot;   </span><br><span class="line"># 使用k8s的ca签发用户证书</span><br><span class="line">openssl x509 -req -in user-a.csr -CA /etc/kubernetes/ssl/kube-ca.pem -CAkey /etc/kubernetes/ssl/kube-ca-key.pem -CAcreateserial -out user-a.crt -days 3650      </span><br><span class="line"># 用户配置</span><br><span class="line">kubectl config set-credentials user-a --client-certificate=user-a.crt --client-key=user-a.key --embed-certs=true</span><br><span class="line"># context设置 # context上下文，包括用户和集群，即选择哪个用户控制哪个集群。</span><br><span class="line">kubectl config set-context user-a@kubernetes --cluster=kubernetes --user=user-a    </span><br><span class="line"></span><br><span class="line">[root@node psp]# kubectl config get-users</span><br><span class="line">NAME</span><br><span class="line">bob</span><br><span class="line">kube-admin-cluster_10.206.16.3</span><br><span class="line"># 新建的用户没有权限</span><br><span class="line">kubectl config use-context bob@kubernetes</span><br><span class="line"># 用户需要通过rbac授权才能操作</span><br></pre></td></tr></table></figure>

<p>binding和clusterbinding声明哪些用户或者SA被授权这些角色。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node psptest]# kubectl api-resources | grep role</span><br><span class="line">clusterrolebindings                            rbac.authorization.k8s.io/v1      false        ClusterRoleBinding</span><br><span class="line">clusterroles                                   rbac.authorization.k8s.io/v1      false        ClusterRole</span><br><span class="line">rolebindings                                   rbac.authorization.k8s.io/v1      true         RoleBinding</span><br><span class="line">roles                                          rbac.authorization.k8s.io/v1      true         Role</span><br></pre></td></tr></table></figure>

<h4 id="2-3-rbac测试"><a href="#2-3-rbac测试" class="headerlink" title="2.3 rbac测试"></a>2.3 rbac测试</h4><h5 id="2-3-1-role与rolebinding"><a href="#2-3-1-role与rolebinding" class="headerlink" title="2.3.1 role与rolebinding"></a>2.3.1 role与rolebinding</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建一个测试ns ns-test01</span><br><span class="line">[root@node psptest]# kubectl create ns ns-test01</span><br><span class="line">namespace/ns-test01 created</span><br><span class="line"></span><br><span class="line"># 新建一个测试pod </span><br><span class="line">[root@node psptest]# kubectl run test --image=luksa/kubectl-proxy -n ns-test01</span><br><span class="line">pod/test created</span><br><span class="line"></span><br><span class="line"># 集群启用rbac后，默认pod没有访问集群内资源的权限</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;Status&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot;: &quot;Failure&quot;,</span><br><span class="line">  &quot;message&quot;: &quot;service is forbidden: User \&quot;system:serviceaccount:ns-test01:default\&quot; cannot list resource \&quot;service\&quot; in API group \&quot;\&quot; in the namespace \&quot;ns-test01\&quot;&quot;,</span><br><span class="line">  &quot;reason&quot;: &quot;Forbidden&quot;,</span><br><span class="line">  &quot;details&quot;: &#123;</span><br><span class="line">    &quot;kind&quot;: &quot;service&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;code&quot;: 403</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># &quot;Forbidden&quot; 确实不能访问，说明rbac生效了</span><br><span class="line"></span><br><span class="line"># 给定一个可访问pod的role,并绑定到该ns的sa</span><br><span class="line">cat &gt;&gt; role-read-services.yml  &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: role-read-ns-services</span><br><span class="line">  namespace: ns-test01</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;, &#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;services&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 因为资源是多个， services必须是复数，否则不能访问</span><br><span class="line"># 可以通过resourceNames限定具体的资源，做进一步的限制</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f role-read-services.yml </span><br><span class="line">role.rbac.authorization.k8s.io/role-read-ns-services created</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create rolebinding rbd-read-pod-sa --role=role-read-ns-services --serviceaccount=ns-test01:default -n ns-test01</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/rbd-read-pod-sa created</span><br><span class="line"></span><br><span class="line"># 查看rolebinding rbd-read-pod-sa</span><br><span class="line">[root@node scprittest]# kubectl get rolebinding rbd-read-pod-sa -o yaml -n ns-test01</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-read-pod-sa</span><br><span class="line">  namespace: ns-test01</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/namespaces/ns-test01/rolebindings/rbd-read-pod-sa</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: role-read-ns-services</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: default</span><br><span class="line">  namespace: ns-test01</span><br><span class="line"></span><br><span class="line"># roleref字段为被绑定的role </span><br><span class="line"># subjects字段为绑定的sa或用户 </span><br><span class="line"># subjects.Kind有三种：  ServiceAccount/ User(用户) /Group(一组sa或一组用户)</span><br><span class="line"># subject.name为sa名称</span><br><span class="line"></span><br><span class="line"># 再pod中再次访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/namespaces/ns-test01/services</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;ServiceList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/namespaces/ns-test01/services&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;129667&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;items&quot;: []</span><br><span class="line"># 说明rbac授权成功</span><br></pre></td></tr></table></figure>

<h5 id="2-3-2-clusterrole与clusterrolebinding"><a href="#2-3-2-clusterrole与clusterrolebinding" class="headerlink" title="2.3.2 clusterrole与clusterrolebinding"></a>2.3.2 clusterrole与clusterrolebinding</h5><p>clusterrole是集群级别资源， 它允许访问没有命名空间级别的资源或者非资源型的URL。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建clusterrole可以访问集群级别资源node</span><br><span class="line">[root@node psptest]# cat &gt;&gt; clusterrole-node-reader.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">kind: ClusterRole </span><br><span class="line">metadata: </span><br><span class="line">  name: node-reader</span><br><span class="line">rules: </span><br><span class="line">- apiGroups: [&#x27;&#x27;]</span><br><span class="line">  verbs: [&#x27;get&#x27;,&#x27;list&#x27;]</span><br><span class="line">  resources: [&#x27;nodes&#x27;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node psptest]# kubectl create -f clusterrole-node-reader.yaml </span><br><span class="line">clusterrole.rbac.authorization.k8s.io/node-reader created</span><br><span class="line"></span><br><span class="line"># 新建clusterrolebinding  </span><br><span class="line">[root@node psptest]# kubectl create clusterrolebinding crb-node-read --clusterrole=node-reader --serviceaccount=ns-test01:default</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/crb-node-read created</span><br><span class="line"></span><br><span class="line"># 未绑定之前无法访问，绑定之后可以访问</span><br><span class="line">[root@node psptest]# kubectl exec test -n ns-test01 curl localhost:8001/api/v1/nodes</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;NodeList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/api/v1/nodes&quot;,</span><br><span class="line">    &quot;resourceVersion&quot;: &quot;144316&quot;</span><br><span class="line">    ---</span><br></pre></td></tr></table></figure>

<h3 id="3-如何使用psp"><a href="#3-如何使用psp" class="headerlink" title="3  如何使用psp"></a>3  如何使用psp</h3><h4 id="3-1-psp能做什么？"><a href="#3-1-psp能做什么？" class="headerlink" title="3.1 psp能做什么？"></a>3.1 psp能做什么？</h4><p>通过psp配合rbac授权，我们可以做以下策略：</p>
<ul>
<li>通过psp做两个方面的限权。 </li>
</ul>
<ol>
<li> 给用户绑定特定psp, 限制用户权限</li>
<li> 给资源指定特定的psp，限制pod权限</li>
</ol>
<ul>
<li><p>给sa或UA分组，统一分级管理。</p>
</li>
<li><p>通过区别使用role和clusterrole可以做的命名空间级别和集群级别的限制。</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 首先我们看超级管理员admin用户是如何授权的</span><br><span class="line"># 为了方便查看某类资源的所有实例，写个脚本 get-resourecs-yaml.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">resourceName=$1</span><br><span class="line">echo $resourceName</span><br><span class="line">tempfile=&quot;$resourceName.txt&quot;</span><br><span class="line">resfile=&quot;all-yaml-$tempfile&quot;</span><br><span class="line">echo &quot;&quot; &gt; $resfile</span><br><span class="line">linecount=0</span><br><span class="line">echo $resfile</span><br><span class="line">echo $tempfile</span><br><span class="line"># 判断是否为Namespaced</span><br><span class="line">whetherNamespaced=`kubectl api-resources | grep $resourceName  | grep true | cut -d &quot; &quot; -f 1` </span><br><span class="line">kubectl get $resourceName --all-namespaces  &gt; $tempfile</span><br><span class="line">echo $whetherNamespaced</span><br><span class="line">sed -i &#x27;1d&#x27; $tempfile</span><br><span class="line">if [ $whetherNamespaced ]</span><br><span class="line">then </span><br><span class="line">  echo &quot;this is  Namespaced resource&quot;</span><br><span class="line">  cat $tempfile | while read line</span><br><span class="line">  do</span><br><span class="line">    let linecount++ </span><br><span class="line">    namespace=`echo $line | cut -d &quot; &quot; -f 1`</span><br><span class="line">    lineresourceName=`echo $line | cut -d &quot; &quot; -f 2`</span><br><span class="line">    echo &quot;here get $resourceName $lineresourceName&quot;</span><br><span class="line">    echo &quot;------------------------------$resourceName $linecount-------------------------&quot; &gt;&gt; $resfile</span><br><span class="line">    echo &quot;------------------------------$namespace-------------------------&quot; &gt;&gt; $resfile</span><br><span class="line">    echo &quot;------------------------------$lineresourceName-------------------------&quot; &gt;&gt; $resfile</span><br><span class="line">    kubectl get   $resourceName $lineresourceName -n $namespace -o yaml &gt;&gt; $resfile</span><br><span class="line">    echo &gt;&gt; $resfile</span><br><span class="line">    echo &gt;&gt; $resfile</span><br><span class="line">  done</span><br><span class="line">else </span><br><span class="line">  echo &quot;this is NOT  Namespaced resource&quot;</span><br><span class="line">  cat $tempfile | while read line</span><br><span class="line">  do</span><br><span class="line">    let linecount++ </span><br><span class="line">    lineresourceName=`echo $line | cut -d &quot; &quot; -f 1`</span><br><span class="line">    echo &quot;here get  $lineresourceName&quot;</span><br><span class="line">    echo &quot;------------------------------$resourceName $linecount-------------------------&quot; &gt;&gt; $resfile</span><br><span class="line">    echo &quot;------------------------------$lineresourceName-------------------------&quot; &gt;&gt;$resfile</span><br><span class="line">    kubectl get   $resourceName $lineresourceName  -o yaml &gt;&gt; $resfile</span><br><span class="line">    echo &gt;&gt; $resfile</span><br><span class="line">    echo &gt;&gt; $resfile</span><br><span class="line">  done</span><br><span class="line">fi </span><br><span class="line">rm -f $tempfile</span><br><span class="line"></span><br><span class="line">[root@node scprittest]# ./get-resourecs-yaml.sh  clusterroles</span><br><span class="line"></span><br><span class="line"># clusterrole </span><br><span class="line">------------------------------cluster-admin-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-01-29T07:28:07Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  resourceVersion: &quot;40&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin</span><br><span class="line">  uid: c65bce3d-8503-4d9a-b9d9-dd2f99753eae</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  resources:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  verbs:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  verbs:</span><br><span class="line">  - &#x27;*&#x27; </span><br><span class="line"></span><br><span class="line"># 所有动作所有资源皆开放</span><br><span class="line"></span><br><span class="line"># clusterrolebinding </span><br><span class="line">------------------------------cluster-admin-------------------------</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  creationTimestamp: &quot;2022-01-29T07:28:07Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  resourceVersion: &quot;93&quot;</span><br><span class="line">  selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin</span><br><span class="line">  uid: b27ae5b3-e59e-4301-8873-f8987db9bb65</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:masters</span><br><span class="line"># 绑定到masters组</span><br></pre></td></tr></table></figure>

<h4 id="3-2-psp用户限权"><a href="#3-2-psp用户限权" class="headerlink" title="3.2 psp用户限权"></a>3.2 psp用户限权</h4><p>假如现在的需求是给user-a用户启动privileged pod的权利， 而user-b用户没有该权限。<br><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/psp-ua2drawio.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 先创建两个用户user-a， user-b， 过程省略</span><br><span class="line"># 创建两个psp: psp-priv, psp-nopriv </span><br><span class="line">cat  &gt; psp-priv.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata: </span><br><span class="line">  name: psp-priv</span><br><span class="line">spec: </span><br><span class="line">  hostIPC: false</span><br><span class="line">  hostPID: false</span><br><span class="line">  hostNetwork: false</span><br><span class="line">  hostPorts: </span><br><span class="line">  - min: 10000</span><br><span class="line">    max: 11000</span><br><span class="line">  privileged: true</span><br><span class="line">  readOnlyRootFilesystem: true</span><br><span class="line">  runAsUser: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux: </span><br><span class="line">    rule: RunAsAny </span><br><span class="line">  volumes: </span><br><span class="line">  - &#x27;*&#x27; </span><br><span class="line">EOF</span><br><span class="line">cat  &gt; psp-nopriv.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata: </span><br><span class="line">  name: psp-nopriv</span><br><span class="line">spec: </span><br><span class="line">  hostIPC: false</span><br><span class="line">  hostPID: false</span><br><span class="line">  hostNetwork: false</span><br><span class="line">  hostPorts: </span><br><span class="line">  - min: 10000</span><br><span class="line">    max: 11000</span><br><span class="line">  privileged: false</span><br><span class="line">  readOnlyRootFilesystem: true</span><br><span class="line">  runAsUser: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups: </span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux: </span><br><span class="line">    rule: RunAsAny </span><br><span class="line">  volumes: </span><br><span class="line">  - &#x27;*&#x27; </span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建两个clusterrole, cr-psp-priv, cr-psp-nopriv</span><br><span class="line">cat &gt; cr-psp-priv.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: cr-psp-priv</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;policy&#x27;]</span><br><span class="line">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class="line">  verbs:     [&#x27;use&#x27;]</span><br><span class="line">  resourceNames:</span><br><span class="line">  - psp-priv</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; cr-psp-nopriv.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: cr-psp-nopriv</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;policy&#x27;]</span><br><span class="line">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class="line">  verbs:     [&#x27;use&#x27;]</span><br><span class="line">  resourceNames:</span><br><span class="line">  - psp-nopriv</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建两个clusterrolebinding: crb-psp-priv-user-a, crb-psp-nopriv-user-b</span><br><span class="line"></span><br><span class="line">cat &gt; crb-psp-priv-user-a.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: crb-psp-priv-user-a</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cr-psp-priv</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: User</span><br><span class="line">  name: user-a:user-a</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; crb-psp-nopriv-user-b.yml &lt;&lt; EOF </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: crb-psp-nopriv-user-b</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cr-psp-nopriv</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: User</span><br><span class="line">  name: user-b</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@node uapriv]# kubectl create   -f .</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/cr-psp-nopriv created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/cr-psp-priv created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/crb-psp-priv-user-a created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/crb-psp-nopriv-user-a created</span><br><span class="line"></span><br><span class="line">[root@node uapriv]# kubectl --user user-b create -f pod-privileged1.yml </span><br><span class="line">Error from server (Forbidden): error when creating &quot;pod-privileged1.yml&quot;: pods is forbidden: User &quot;user-b&quot; cannot create resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot;</span><br><span class="line"></span><br><span class="line">[root@node uapriv]# kubectl --user user-a  create -f pod-privileged1.yml </span><br><span class="line">pod/pod-privileged created</span><br><span class="line"># 可以看到权限生效了</span><br></pre></td></tr></table></figure>

<h4 id="3-3-psp-资源权限限制"><a href="#3-3-psp-资源权限限制" class="headerlink" title="3.3 psp 资源权限限制"></a>3.3 psp 资源权限限制</h4><p>假如我们现在的需求是有一个pod需要hostPID, 另一个不需要则根据最小权限原则禁止使用。 那么设计思路如下图。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Yuanwanli1995/markdown_pic@main/blogpic/psp-sa2.drawio.png"></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>python-paramiko</title>
    <url>/2022/01/25/2022-01-25-python-paramiko/</url>
    <content><![CDATA[<h3 id="1-paramiko"><a href="#1-paramiko" class="headerlink" title="1 paramiko"></a>1 paramiko</h3><p>ssh是一个协议，OpenSSH是其中一个开源实现，paramiko是Python的一个库，实现了SSHv2协议(底层使用cryptography)。</p>
<p><a href="https://docs.paramiko.org/en/stable/#welcome-to-paramiko-s-documentation">官网</a></p>
<p>有了Paramiko以后，我们就可以在Python代码中直接使用SSH协议对远程服务器执行操作，而不是通过ssh命令对远程服务器进行操作。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install paramiko </span><br></pre></td></tr></table></figure>

<h3 id="2-介绍"><a href="#2-介绍" class="headerlink" title="2 介绍"></a>2 介绍</h3><p>paramiko包含两个核心组件：SSHClient和SFTPClient。</p>
<ul>
<li>SSHClient的作用类似于Linux的ssh命令，是对SSH会话的封装，该类封装了传输(Transport)，通道(Channel)及SFTPClient建立的方法(open_sftp)，通常用于执行远程命令。</li>
<li>SFTPClient的作用类似与Linux的sftp命令，是对SFTP客户端的封装，用以实现远程文件操作，如文件上传、下载、修改文件权限等操作。</li>
</ul>
<p> <strong>Paramiko中的几个基础名词：</strong></p>
<blockquote>
<p>1 Channel：是一种类Socket，一种安全的SSH传输通道；<br>2 Transport：是一种加密的会话，使用时会同步创建了一个加密的Tunnels(通道)，这个Tunnels叫做Channel；<br>3 Session：是client与Server保持连接的对象，用connect()<code>/</code>start_client()<code>/</code>start_server()开始会话</p>
</blockquote>
<h3 id="3-使用"><a href="#3-使用" class="headerlink" title="3 使用"></a>3 使用</h3><h4 id="3-1-sshclient"><a href="#3-1-sshclient" class="headerlink" title="3.1 sshclient"></a>3.1 sshclient</h4><p>**connect()**：实现远程服务器的连接与认证，对于该方法只有hostname是必传参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用参数</span><br><span class="line">hostname 连接的目标主机</span><br><span class="line">port=SSH_PORT 指定端口</span><br><span class="line">username=None 验证的用户名</span><br><span class="line">password=None 验证的用户密码</span><br><span class="line">pkey=None 私钥方式用于身份验证</span><br><span class="line">key_filename=None 一个文件名或文件列表，指定私钥文件</span><br><span class="line">timeout=None 可选的tcp连接超时时间</span><br><span class="line">allow_agent=True, 是否允许连接到ssh代理，默认为True 允许</span><br><span class="line">look_for_keys=True 是否在~/.ssh中搜索私钥文件，默认为True 允许</span><br><span class="line">compress=False, 是否打开压缩</span><br></pre></td></tr></table></figure>

<p>**set_missing_host_key_policy()**：设置远程服务器没有在know_hosts文件中记录时的应对策略。目前支持三种策略：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">设置连接的远程主机没有本地主机密钥或HostKeys对象时的策略，目前支持三种：</span><br><span class="line"></span><br><span class="line">1 AutoAddPolicy 自动添加主机名及主机密钥到本地HostKeys对象，不依赖load_system_host_key的配置。即新建立ssh连接时不需要再输入yes或no进行确认</span><br><span class="line">2 WarningPolicy 用于记录一个未知的主机密钥的python警告。并接受，功能上和AutoAddPolicy类似，但是会提示是新连接</span><br><span class="line">4 RejectPolicy 自动拒绝未知的主机名和密钥，依赖load_system_host_key的配置。此为默认选项</span><br></pre></td></tr></table></figure>

<p>**exec_command()**：在远程服务器执行Linux命令的方法。</p>
<p>**open_sftp()**：在当前ssh会话的基础上创建一个sftp会话。该方法会返回一个SFTPClient对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 利用SSHClient对象的open_sftp()方法，可以直接返回一个基于当前连接的sftp对象，可以进行文件的上传等操作.</span><br><span class="line"></span><br><span class="line">sftp = client.open_sftp()</span><br><span class="line">sftp.put(&#x27;test.txt&#x27;,&#x27;text.txt&#x27;)</span><br></pre></td></tr></table></figure>



<p>用法示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import paramiko</span><br><span class="line"> </span><br><span class="line"># 实例化SSHClient</span><br><span class="line">client = paramiko.SSHClient()</span><br><span class="line"></span><br><span class="line"># 自动添加策略，保存服务器的主机名和密钥信息，如果不添加，那么不再本地know_hosts文件中记录的主机将无法连接</span><br><span class="line">client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line"></span><br><span class="line"># 连接SSH服务端，以用户名和密码进行认证</span><br><span class="line">client.connect(hostname=&#x27;192.168.1.105&#x27;, port=22, username=&#x27;root&#x27;, password=&#x27;123456&#x27;)</span><br><span class="line"></span><br><span class="line"># 打开一个Channel并执行命令</span><br><span class="line">stdin, stdout, stderr = client.exec_command(&#x27;ls -h &#x27;)  # stdout 为正确输出，stderr为错误输出，同时是有1个变量有值</span><br><span class="line"></span><br><span class="line"># 打印执行结果</span><br><span class="line">print(stdout.read().decode(&#x27;utf-8&#x27;))</span><br><span class="line"></span><br><span class="line"># 关闭SSHClient</span><br><span class="line">client.close()</span><br></pre></td></tr></table></figure>

<h4 id="3-2-如果用密钥连接"><a href="#3-2-如果用密钥连接" class="headerlink" title="3.2 如果用密钥连接"></a>3.2 如果用密钥连接</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置私人密钥文件位置</span><br><span class="line">private = paramiko.RSAKey.from_private_key_file(&#x27;/Users/ch/.ssh/id_rsa&#x27;)</span><br><span class="line"># 在与主机中公钥要添加 cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">#实例化SSHClient</span><br><span class="line">client = paramiko.SSHClient()</span><br><span class="line"> </span><br><span class="line">#自动添加策略，保存服务器的主机名和密钥信息，如果不添加，那么不再本地know_hosts文件中记录的主机将无法连接</span><br><span class="line">client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line"> </span><br><span class="line">#连接SSH服务端，以用户名和密码进行认证</span><br><span class="line">client.connect(hostname=&#x27;10.0.0.1&#x27;,port=22,username=&#x27;root&#x27;,pkey=private)</span><br></pre></td></tr></table></figure>

<h4 id="3-3-sftpclient"><a href="#3-3-sftpclient" class="headerlink" title="3.3  sftpclient"></a>3.3  sftpclient</h4><p>SFTPCLient作为一个sftp的客户端对象，根据ssh传输协议的sftp会话，实现远程文件操作，如上传、下载、权限、状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from_transport(cls,t) 创建一个已连通的SFTP客户端通道</span><br><span class="line">put(localpath, remotepath, callback=None, confirm=True) 将本地文件上传到服务器 参数confirm：是否调用stat()方法检查文件状态，返回ls -l的结果</span><br><span class="line">get(remotepath, localpath, callback=None) 从服务器下载文件到本地</span><br><span class="line">mkdir() 在服务器上创建目录</span><br><span class="line">remove() 在服务器上删除目录</span><br><span class="line">rename() 在服务器上重命名目录</span><br><span class="line">stat() 查看服务器文件状态</span><br><span class="line">listdir() 列出服务器目录下的文件</span><br></pre></td></tr></table></figure>

<p>用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import paramiko</span><br><span class="line"> </span><br><span class="line"># 获取Transport实例</span><br><span class="line">tran = paramiko.Transport((&#x27;1.117.61.155&#x27;, 22))</span><br><span class="line"> </span><br><span class="line"># 连接SSH服务端，使用password</span><br><span class="line">#tran.connect(username=&quot;root&quot;, password=&#x27;1ddgbyhddcB&#x27;)</span><br><span class="line"># 或使用</span><br><span class="line"># 配置私人密钥文件位置</span><br><span class="line">private = paramiko.RSAKey.from_private_key_file(&#x27;id_rsa&#x27;)</span><br><span class="line"># 连接SSH服务端，使用pkey指定私钥</span><br><span class="line">tran.connect(username=&quot;root&quot;, pkey=private)</span><br><span class="line"> </span><br><span class="line"># 获取SFTP实例</span><br><span class="line">sftp = paramiko.SFTPClient.from_transport(tran)</span><br><span class="line"> </span><br><span class="line"># 设置上传的本地/远程文件路径</span><br><span class="line">localpath = &quot;test.py&quot;</span><br><span class="line">remotepath = &quot;/root/test.py&quot;</span><br><span class="line"> </span><br><span class="line"># 执行上传动作</span><br><span class="line">sftp.put(localpath, remotepath)</span><br><span class="line"></span><br><span class="line"># 执行下载动作#</span><br><span class="line"># sftp.get(&quot;/root/requirements.txt&quot;, &#x27;requirements.txt&#x27;)</span><br><span class="line"># sftp.mkdir(&quot;paramikotest1&quot;)</span><br><span class="line">sftp.remove(&quot;requirements.txt&quot;)</span><br><span class="line">tran.close()</span><br></pre></td></tr></table></figure>

<p><a href="https://docs.paramiko.org/en/stable/api/sftp.html">SFTP 详细用法</a></p>
<p>这里提供了基本所有的文件操作</p>
<p>集成交互类示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class SSHConnection(object):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, host_dict):</span><br><span class="line">        self.host = host_dict[&#x27;host&#x27;]</span><br><span class="line">        self.port = host_dict[&#x27;port&#x27;]</span><br><span class="line">        self.username = host_dict[&#x27;username&#x27;]</span><br><span class="line">        self.pwd = host_dict[&#x27;pwd&#x27;]</span><br><span class="line">        self.__k = None</span><br><span class="line"> </span><br><span class="line">    def connect(self):</span><br><span class="line">        transport = paramiko.Transport((self.host,self.port))</span><br><span class="line">        transport.connect(username=self.username,password=self.pwd)</span><br><span class="line">        self.__transport = transport</span><br><span class="line"> </span><br><span class="line">    def close(self):</span><br><span class="line">        self.__transport.close()</span><br><span class="line"> </span><br><span class="line">    def run_cmd(self, command):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">         执行shell命令,返回字典</span><br><span class="line">         return &#123;&#x27;color&#x27;: &#x27;red&#x27;,&#x27;res&#x27;:error&#125;或</span><br><span class="line">         return &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;res&#x27;:res&#125;</span><br><span class="line">        :param command:</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        ssh = paramiko.SSHClient()</span><br><span class="line">        ssh._transport = self.__transport</span><br><span class="line">        # 执行命令</span><br><span class="line">        stdin, stdout, stderr = ssh.exec_command(command)</span><br><span class="line">        # 获取命令结果</span><br><span class="line">        res = unicode_utils.to_str(stdout.read())</span><br><span class="line">        # 获取错误信息</span><br><span class="line">        error = unicode_utils.to_str(stderr.read())</span><br><span class="line">        # 如果有错误信息，返回error</span><br><span class="line">        # 否则返回res</span><br><span class="line">        if error.strip():</span><br><span class="line">            return &#123;&#x27;color&#x27;:&#x27;red&#x27;,&#x27;res&#x27;:error&#125;</span><br><span class="line">        else:</span><br><span class="line">            return &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;res&#x27;:res&#125;</span><br><span class="line"> </span><br><span class="line">    def upload(self,local_path, target_path):</span><br><span class="line">        # 连接，上传</span><br><span class="line">        sftp = paramiko.SFTPClient.from_transport(self.__transport)</span><br><span class="line">        # 将location.py 上传至服务器 /tmp/test.py</span><br><span class="line">        sftp.put(local_path, target_path, confirm=True)</span><br><span class="line">        # print(os.stat(local_path).st_mode)</span><br><span class="line">        # 增加权限</span><br><span class="line">        # sftp.chmod(target_path, os.stat(local_path).st_mode)</span><br><span class="line">        sftp.chmod(target_path, 0o755)  # 注意这里的权限是八进制的，八进制需要使用0o作为前缀</span><br><span class="line"> </span><br><span class="line">    def download(self,target_path, local_path):</span><br><span class="line">        # 连接，下载</span><br><span class="line">        sftp = paramiko.SFTPClient.from_transport(self.__transport)</span><br><span class="line">        # 将location.py 下载至服务器 /tmp/test.py</span><br><span class="line">        sftp.get(target_path, local_path)</span><br><span class="line"> </span><br><span class="line">    # 销毁</span><br><span class="line">    def __del__(self):</span><br><span class="line">        self.close()</span><br><span class="line"> </span><br><span class="line">　　</span><br><span class="line">#unicode_utils.py</span><br><span class="line">def to_str(bytes_or_str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    把byte类型转换为str</span><br><span class="line">    :param bytes_or_str:</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if isinstance(bytes_or_str, bytes):</span><br><span class="line">        value = bytes_or_str.decode(&#x27;utf-8&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        value = bytes_or_str</span><br><span class="line">    return value</span><br></pre></td></tr></table></figure>

<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<h1 id="224a31b93706e3592cb8961318638e3dca071f41"><a href="#224a31b93706e3592cb8961318638e3dca071f41" class="headerlink" title="224a31b93706e3592cb8961318638e3dca071f41"></a>224a31b93706e3592cb8961318638e3dca071f41</h1></blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<hr>
<p>title: python-paramiko<br>date: 2022-01-25<br>categories: 编程笔记</p>
<hr>
<h3 id="1-paramiko-1"><a href="#1-paramiko-1" class="headerlink" title="1 paramiko"></a>1 paramiko</h3><p>ssh是一个协议，OpenSSH是其中一个开源实现，paramiko是Python的一个库，实现了SSHv2协议(底层使用cryptography)。</p>
<p><a href="https://docs.paramiko.org/en/stable/#welcome-to-paramiko-s-documentation">官网</a></p>
<p>有了Paramiko以后，我们就可以在Python代码中直接使用SSH协议对远程服务器执行操作，而不是通过ssh命令对远程服务器进行操作。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install paramiko </span><br></pre></td></tr></table></figure>

<h3 id="2-介绍-1"><a href="#2-介绍-1" class="headerlink" title="2 介绍"></a>2 介绍</h3><p>paramiko包含两个核心组件：SSHClient和SFTPClient。</p>
<ul>
<li>SSHClient的作用类似于Linux的ssh命令，是对SSH会话的封装，该类封装了传输(Transport)，通道(Channel)及SFTPClient建立的方法(open_sftp)，通常用于执行远程命令。</li>
<li>SFTPClient的作用类似与Linux的sftp命令，是对SFTP客户端的封装，用以实现远程文件操作，如文件上传、下载、修改文件权限等操作。</li>
</ul>
<p> <strong>Paramiko中的几个基础名词：</strong></p>
<blockquote>
<p>1 Channel：是一种类Socket，一种安全的SSH传输通道；<br>2 Transport：是一种加密的会话，使用时会同步创建了一个加密的Tunnels(通道)，这个Tunnels叫做Channel；<br>3 Session：是client与Server保持连接的对象，用connect()<code>/</code>start_client()<code>/</code>start_server()开始会话</p>
</blockquote>
<h3 id="3-使用-1"><a href="#3-使用-1" class="headerlink" title="3 使用"></a>3 使用</h3><h4 id="3-1-sshclient-1"><a href="#3-1-sshclient-1" class="headerlink" title="3.1 sshclient"></a>3.1 sshclient</h4><p>**connect()**：实现远程服务器的连接与认证，对于该方法只有hostname是必传参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用参数</span><br><span class="line">hostname 连接的目标主机</span><br><span class="line">port=SSH_PORT 指定端口</span><br><span class="line">username=None 验证的用户名</span><br><span class="line">password=None 验证的用户密码</span><br><span class="line">pkey=None 私钥方式用于身份验证</span><br><span class="line">key_filename=None 一个文件名或文件列表，指定私钥文件</span><br><span class="line">timeout=None 可选的tcp连接超时时间</span><br><span class="line">allow_agent=True, 是否允许连接到ssh代理，默认为True 允许</span><br><span class="line">look_for_keys=True 是否在~/.ssh中搜索私钥文件，默认为True 允许</span><br><span class="line">compress=False, 是否打开压缩</span><br></pre></td></tr></table></figure>

<p>**set_missing_host_key_policy()**：设置远程服务器没有在know_hosts文件中记录时的应对策略。目前支持三种策略：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">设置连接的远程主机没有本地主机密钥或HostKeys对象时的策略，目前支持三种：</span><br><span class="line"></span><br><span class="line">1 AutoAddPolicy 自动添加主机名及主机密钥到本地HostKeys对象，不依赖load_system_host_key的配置。即新建立ssh连接时不需要再输入yes或no进行确认</span><br><span class="line">2 WarningPolicy 用于记录一个未知的主机密钥的python警告。并接受，功能上和AutoAddPolicy类似，但是会提示是新连接</span><br><span class="line">4 RejectPolicy 自动拒绝未知的主机名和密钥，依赖load_system_host_key的配置。此为默认选项</span><br></pre></td></tr></table></figure>

<p>**exec_command()**：在远程服务器执行Linux命令的方法。</p>
<p>**open_sftp()**：在当前ssh会话的基础上创建一个sftp会话。该方法会返回一个SFTPClient对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 利用SSHClient对象的open_sftp()方法，可以直接返回一个基于当前连接的sftp对象，可以进行文件的上传等操作.</span><br><span class="line"></span><br><span class="line">sftp = client.open_sftp()</span><br><span class="line">sftp.put(&#x27;test.txt&#x27;,&#x27;text.txt&#x27;)</span><br></pre></td></tr></table></figure>



<p>用法示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import paramiko</span><br><span class="line"> </span><br><span class="line"># 实例化SSHClient</span><br><span class="line">client = paramiko.SSHClient()</span><br><span class="line"></span><br><span class="line"># 自动添加策略，保存服务器的主机名和密钥信息，如果不添加，那么不再本地know_hosts文件中记录的主机将无法连接</span><br><span class="line">client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line"></span><br><span class="line"># 连接SSH服务端，以用户名和密码进行认证</span><br><span class="line">client.connect(hostname=&#x27;192.168.1.105&#x27;, port=22, username=&#x27;root&#x27;, password=&#x27;123456&#x27;)</span><br><span class="line"></span><br><span class="line"># 打开一个Channel并执行命令</span><br><span class="line">stdin, stdout, stderr = client.exec_command(&#x27;ls -h &#x27;)  # stdout 为正确输出，stderr为错误输出，同时是有1个变量有值</span><br><span class="line"></span><br><span class="line"># 打印执行结果</span><br><span class="line">print(stdout.read().decode(&#x27;utf-8&#x27;))</span><br><span class="line"></span><br><span class="line"># 关闭SSHClient</span><br><span class="line">client.close()</span><br></pre></td></tr></table></figure>

<h4 id="3-2-如果用密钥连接-1"><a href="#3-2-如果用密钥连接-1" class="headerlink" title="3.2 如果用密钥连接"></a>3.2 如果用密钥连接</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置私人密钥文件位置</span><br><span class="line">private = paramiko.RSAKey.from_private_key_file(&#x27;/Users/ch/.ssh/id_rsa&#x27;)</span><br><span class="line"># 在与主机中公钥要添加 cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">#实例化SSHClient</span><br><span class="line">client = paramiko.SSHClient()</span><br><span class="line"> </span><br><span class="line">#自动添加策略，保存服务器的主机名和密钥信息，如果不添加，那么不再本地know_hosts文件中记录的主机将无法连接</span><br><span class="line">client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line"> </span><br><span class="line">#连接SSH服务端，以用户名和密码进行认证</span><br><span class="line">client.connect(hostname=&#x27;10.0.0.1&#x27;,port=22,username=&#x27;root&#x27;,pkey=private)</span><br></pre></td></tr></table></figure>

<h4 id="3-3-sftpclient-1"><a href="#3-3-sftpclient-1" class="headerlink" title="3.3  sftpclient"></a>3.3  sftpclient</h4><p>SFTPCLient作为一个sftp的客户端对象，根据ssh传输协议的sftp会话，实现远程文件操作，如上传、下载、权限、状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from_transport(cls,t) 创建一个已连通的SFTP客户端通道</span><br><span class="line">put(localpath, remotepath, callback=None, confirm=True) 将本地文件上传到服务器 参数confirm：是否调用stat()方法检查文件状态，返回ls -l的结果</span><br><span class="line">get(remotepath, localpath, callback=None) 从服务器下载文件到本地</span><br><span class="line">mkdir() 在服务器上创建目录</span><br><span class="line">remove() 在服务器上删除目录</span><br><span class="line">rename() 在服务器上重命名目录</span><br><span class="line">stat() 查看服务器文件状态</span><br><span class="line">listdir() 列出服务器目录下的文件</span><br></pre></td></tr></table></figure>

<p>用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import paramiko</span><br><span class="line"> </span><br><span class="line"># 获取Transport实例</span><br><span class="line">tran = paramiko.Transport((&#x27;1.117.61.155&#x27;, 22))</span><br><span class="line"> </span><br><span class="line"># 连接SSH服务端，使用password</span><br><span class="line">#tran.connect(username=&quot;root&quot;, password=&#x27;1ddgbyhddcB&#x27;)</span><br><span class="line"># 或使用</span><br><span class="line"># 配置私人密钥文件位置</span><br><span class="line">private = paramiko.RSAKey.from_private_key_file(&#x27;id_rsa&#x27;)</span><br><span class="line"># 连接SSH服务端，使用pkey指定私钥</span><br><span class="line">tran.connect(username=&quot;root&quot;, pkey=private)</span><br><span class="line"> </span><br><span class="line"># 获取SFTP实例</span><br><span class="line">sftp = paramiko.SFTPClient.from_transport(tran)</span><br><span class="line"> </span><br><span class="line"># 设置上传的本地/远程文件路径</span><br><span class="line">localpath = &quot;test.py&quot;</span><br><span class="line">remotepath = &quot;/root/test.py&quot;</span><br><span class="line"> </span><br><span class="line"># 执行上传动作</span><br><span class="line">sftp.put(localpath, remotepath)</span><br><span class="line"></span><br><span class="line"># 执行下载动作#</span><br><span class="line"># sftp.get(&quot;/root/requirements.txt&quot;, &#x27;requirements.txt&#x27;)</span><br><span class="line"># sftp.mkdir(&quot;paramikotest1&quot;)</span><br><span class="line">sftp.remove(&quot;requirements.txt&quot;)</span><br><span class="line">tran.close()</span><br></pre></td></tr></table></figure>

<p><a href="https://docs.paramiko.org/en/stable/api/sftp.html">SFTP 详细用法</a></p>
<p>这里提供了基本所有的文件操作</p>
<p>集成交互类示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class SSHConnection(object):</span><br><span class="line"> </span><br><span class="line">    def __init__(self, host_dict):</span><br><span class="line">        self.host = host_dict[&#x27;host&#x27;]</span><br><span class="line">        self.port = host_dict[&#x27;port&#x27;]</span><br><span class="line">        self.username = host_dict[&#x27;username&#x27;]</span><br><span class="line">        self.pwd = host_dict[&#x27;pwd&#x27;]</span><br><span class="line">        self.__k = None</span><br><span class="line"> </span><br><span class="line">    def connect(self):</span><br><span class="line">        transport = paramiko.Transport((self.host,self.port))</span><br><span class="line">        transport.connect(username=self.username,password=self.pwd)</span><br><span class="line">        self.__transport = transport</span><br><span class="line"> </span><br><span class="line">    def close(self):</span><br><span class="line">        self.__transport.close()</span><br><span class="line"> </span><br><span class="line">    def run_cmd(self, command):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">         执行shell命令,返回字典</span><br><span class="line">         return &#123;&#x27;color&#x27;: &#x27;red&#x27;,&#x27;res&#x27;:error&#125;或</span><br><span class="line">         return &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;res&#x27;:res&#125;</span><br><span class="line">        :param command:</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        ssh = paramiko.SSHClient()</span><br><span class="line">        ssh._transport = self.__transport</span><br><span class="line">        # 执行命令</span><br><span class="line">        stdin, stdout, stderr = ssh.exec_command(command)</span><br><span class="line">        # 获取命令结果</span><br><span class="line">        res = unicode_utils.to_str(stdout.read())</span><br><span class="line">        # 获取错误信息</span><br><span class="line">        error = unicode_utils.to_str(stderr.read())</span><br><span class="line">        # 如果有错误信息，返回error</span><br><span class="line">        # 否则返回res</span><br><span class="line">        if error.strip():</span><br><span class="line">            return &#123;&#x27;color&#x27;:&#x27;red&#x27;,&#x27;res&#x27;:error&#125;</span><br><span class="line">        else:</span><br><span class="line">            return &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;res&#x27;:res&#125;</span><br><span class="line"> </span><br><span class="line">    def upload(self,local_path, target_path):</span><br><span class="line">        # 连接，上传</span><br><span class="line">        sftp = paramiko.SFTPClient.from_transport(self.__transport)</span><br><span class="line">        # 将location.py 上传至服务器 /tmp/test.py</span><br><span class="line">        sftp.put(local_path, target_path, confirm=True)</span><br><span class="line">        # print(os.stat(local_path).st_mode)</span><br><span class="line">        # 增加权限</span><br><span class="line">        # sftp.chmod(target_path, os.stat(local_path).st_mode)</span><br><span class="line">        sftp.chmod(target_path, 0o755)  # 注意这里的权限是八进制的，八进制需要使用0o作为前缀</span><br><span class="line"> </span><br><span class="line">    def download(self,target_path, local_path):</span><br><span class="line">        # 连接，下载</span><br><span class="line">        sftp = paramiko.SFTPClient.from_transport(self.__transport)</span><br><span class="line">        # 将location.py 下载至服务器 /tmp/test.py</span><br><span class="line">        sftp.get(target_path, local_path)</span><br><span class="line"> </span><br><span class="line">    # 销毁</span><br><span class="line">    def __del__(self):</span><br><span class="line">        self.close()</span><br><span class="line"> </span><br><span class="line">　　</span><br><span class="line">#unicode_utils.py</span><br><span class="line">def to_str(bytes_or_str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    把byte类型转换为str</span><br><span class="line">    :param bytes_or_str:</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if isinstance(bytes_or_str, bytes):</span><br><span class="line">        value = bytes_or_str.decode(&#x27;utf-8&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        value = bytes_or_str</span><br><span class="line">    return value</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>psp-seccomp实验记录</title>
    <url>/2022/02/16/2022-02-16-psp-seccomp%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">内网ip 节点角色</span><br><span class="line">172.21.42.59 管理节点</span><br><span class="line">172.21.42.13 worker</span><br><span class="line">172.21.42.221 worker</span><br><span class="line">172.21.42.86 worker</span><br><span class="line">172.21.42.125 worker</span><br><span class="line">172.21.42.165 worker</span><br><span class="line">172.21.42.20 worker</span><br><span class="line">172.21.42.179 worker</span><br><span class="line">172.21.42.230 worker</span><br><span class="line">172.21.42.217 worker</span><br><span class="line"></span><br><span class="line">控制节点：</span><br><span class="line">172.21.42.59</span><br><span class="line"></span><br><span class="line">主机登录密码：</span><br><span class="line">Cmcc!234</span><br><span class="line"></span><br><span class="line"># 环境查看 </span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get node</span><br><span class="line">NAME            STATUS   ROLES                      AGE   VERSION</span><br><span class="line">172.21.42.125   Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.13    Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.165   Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.179   Ready    controlplane,etcd,worker   33d   v1.15.5</span><br><span class="line">172.21.42.20    Ready    controlplane,etcd,worker   33d   v1.15.5</span><br><span class="line">172.21.42.217   Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.221   Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.230   Ready    worker                     33d   v1.15.5</span><br><span class="line">172.21.42.59    Ready    controlplane,etcd,worker   33d   v1.15.5</span><br><span class="line">172.21.42.86    Ready    worker                     33d   v1.15.5</span><br><span class="line"></span><br><span class="line"># </span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get cs</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get po --all-namespaces</span><br><span class="line">NAMESPACE       NAME                                                         READY   STATUS      RESTARTS   AGE</span><br><span class="line">argame          argame-admin-89bdfd874-9phjk                                 1/1     Running     0          4d17h</span><br><span class="line">argame          argame-center-6c6897c4d5-8v64w                               1/1     Running     0          4d21h</span><br><span class="line">argame          argame-front-admin-89f79748c-g2hrj                           1/1     Running     0          20h</span><br><span class="line">argame          argame-front-creator-c9648c8db-6c2db                         1/1     Running     0          20h</span><br><span class="line">argame          argame-front-h5-b4cb9874b-sk597                              1/1     Running     0          20h</span><br><span class="line">argame          argame-ws-668d98bf8-mpj6p                                    1/1     Running     0          44h</span><br><span class="line">argame          broker-a-0                                                   1/1     Running     0          5d22h</span><br><span class="line">argame          broker-a-s-0                                                 1/1     Running     0          5d22h</span><br><span class="line">argame          broker-b-0                                                   1/1     Running     0          5d22h</span><br><span class="line">argame          broker-b-s-0                                                 1/1     Running     0          5d22h</span><br><span class="line">argame          deploy-tool-7db578d688-ckbp2                                 1/1     Running     0          29d</span><br><span class="line">argame          mongodb-ar-0                                                 1/1     Running     0          26d</span><br><span class="line">argame          mq-externals-bd5c8d8fd-hhhs9                                 1/1     Running     0          5d22h</span><br><span class="line">argame          mq-namesrv-0                                                 1/1     Running     0          5d22h</span><br><span class="line">argame          mq-namesrv-1                                                 1/1     Running     0          5d22h</span><br><span class="line">argame          mysql-ar-0                                                   3/3     Running     1          27d</span><br><span class="line">argame          mysql-ar-1                                                   3/3     Running     0          27d</span><br><span class="line">argame          nginx-nas-666d78d975-vf6s6                                   1/1     Running     0          26d</span><br><span class="line">argame          redis-node-0                                                 2/2     Running     0          26d</span><br><span class="line">argame          redis-node-1                                                 2/2     Running     0          26d</span><br><span class="line">argame          redis-node-2                                                 2/2     Running     0          26d</span><br><span class="line">cattle-system   cattle-cluster-agent-7bdd7469bb-smqgp                        1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-2s2cb                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-475vj                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-fnnn5                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-h7x6l                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-hdsr6                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-nkrcv                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-nl282                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-rrq8b                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-ss6s4                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   cattle-node-agent-tr2m6                                      1/1     Running     0          33d</span><br><span class="line">cattle-system   rancher-58f96d87d7-87p96                                     1/1     Running     2          33d</span><br><span class="line">cattle-system   rancher-58f96d87d7-8khc6                                     1/1     Running     1          33d</span><br><span class="line">cattle-system   rancher-58f96d87d7-khltj                                     1/1     Running     3          33d</span><br><span class="line">default         ai-audit-service-6d7fd6cd97-kvrd6                            1/1     Running     0          6d20h</span><br><span class="line">default         av-processor-6cb6486b9c-4r8bw                                1/1     Running     0          6d19h</span><br><span class="line">default         av-service-d9879dddb-lpwnn                                   1/1     Running     0          8h</span><br><span class="line">default         chat-service-6846f69dd6-6vkrw                                1/1     Running     0          8h</span><br><span class="line">default         data-generator-1644973200-2cllb                              0/1     Error       0          137m</span><br><span class="line">default         data-generator-1644973200-fstln                              0/1     Error       0          136m</span><br><span class="line">default         data-generator-1644973200-jhn6n                              0/1     Error       0          138m</span><br><span class="line">default         data-generator-1644973200-st2qx                              0/1     Error       0          138m</span><br><span class="line">default         data-generator-1644973200-vsr29                              0/1     Error       0          133m</span><br><span class="line">default         data-generator-1644973200-xfbgv                              0/1     Error       0          139m</span><br><span class="line">default         data-generator-1644973200-zlx28                              0/1     Error       0          139m</span><br><span class="line">default         deploy-tool-66f865dcc-js8zc                                  1/1     Running     0          29d</span><br><span class="line">default         elasticsearch-master-0                                       1/1     Running     0          29d</span><br><span class="line">default         elasticsearch-master-1                                       1/1     Running     0          29d</span><br><span class="line">default         elasticsearch-master-2                                       1/1     Running     0          29d</span><br><span class="line">default         file-service-599f77db77-fvfmz                                1/1     Running     0          8h</span><br><span class="line">default         kafka-master-0                                               1/1     Running     1          29d</span><br><span class="line">default         kafka-master-1                                               1/1     Running     0          29d</span><br><span class="line">default         kafka-master-2                                               1/1     Running     1          29d</span><br><span class="line">default         kafka-master-zookeeper-0                                     1/1     Running     0          29d</span><br><span class="line">default         kibana-kibana-97bd7bff6-c6mks                                1/1     Running     0          19h</span><br><span class="line">default         kong-kong-2gbfm                                              2/2     Running     0          7h53m</span><br><span class="line">default         kong-kong-5fsn8                                              2/2     Running     0          7h52m</span><br><span class="line">default         kong-kong-645tk                                              2/2     Running     0          7h58m</span><br><span class="line">default         kong-kong-8dzlf                                              2/2     Running     0          7h57m</span><br><span class="line">default         kong-kong-j5m54                                              2/2     Running     0          7h57m</span><br><span class="line">default         kong-kong-kmd55                                              2/2     Running     0          7h54m</span><br><span class="line">default         kong-kong-kvlzg                                              2/2     Running     0          7h56m</span><br><span class="line">default         kong-kong-m9wkn                                              2/2     Running     0          7h51m</span><br><span class="line">default         kong-kong-nsmxz                                              2/2     Running     0          7h55m</span><br><span class="line">default         kong-kong-zgvd5                                              2/2     Running     0          7h54m</span><br><span class="line">default         live-service-777c5458cd-l2752                                1/1     Running     0          8h</span><br><span class="line">default         media-platform-ruiyue-service-854f85888f-ltbnj               1/1     Running     0          6d20h</span><br><span class="line">default         mysql-vr-0                                                   3/3     Running     0          29d</span><br><span class="line">default         mysql-vr-1                                                   3/3     Running     0          29d</span><br><span class="line">default         nginx-nas-6cd898cb5f-gkklh                                   1/1     Running     0          28d</span><br><span class="line">default         redis609-node-0                                              2/2     Running     0          29d</span><br><span class="line">default         redis609-node-1                                              2/2     Running     0          29d</span><br><span class="line">default         redis609-node-2                                              2/2     Running     0          29d</span><br><span class="line">default         srs-edge-cfc4f6d89-ph724                                     1/1     Running     0          29d</span><br><span class="line">default         srs-source-0                                                 2/2     Running     0          29d</span><br><span class="line">default         vod-service-6f5dbb9cb6-kvqsj                                 1/1     Running     0          8h</span><br><span class="line">default         vr-cms-activity-5848b97955-4nfbg                             1/1     Running     0          8h</span><br><span class="line">default         vr-cms-admin-microservice-consumer-745c8cffc7-bkl9x          1/1     Running     0          8h</span><br><span class="line">default         vr-cms-admin-microservice-consumer-745c8cffc7-r9jnc          1/1     Running     0          8h</span><br><span class="line">default         vr-cms-auth-server-79f57bbfbb-jvtjv                          1/1     Running     0          8h</span><br><span class="line">default         vr-cms-auth-server-79f57bbfbb-jwvtk                          1/1     Running     0          8h</span><br><span class="line">default         vr-cms-config-server-767df5989b-4gkkk                        1/1     Running     0          18h</span><br><span class="line">default         vr-cms-config-server-767df5989b-9b8sp                        1/1     Running     0          18h</span><br><span class="line">default         vr-cms-content-sync-1644804000-l4n4v                         0/1     Completed   0          2d1h</span><br><span class="line">default         vr-cms-content-sync-1644890400-b2b78                         0/1     Completed   0          25h</span><br><span class="line">default         vr-cms-content-sync-1644976800-qnsvz                         0/1     Completed   0          79m</span><br><span class="line">default         vr-cms-customer-microservice-consumer-fb9df8bd6-5dpgd        1/1     Running     0          8h</span><br><span class="line">default         vr-cms-customer-microservice-consumer-fb9df8bd6-gxkpp        1/1     Running     0          8h</span><br><span class="line">default         vr-cms-front-client-76b464f7c8-ts8ps                         1/1     Running     0          8h</span><br><span class="line">default         vr-cms-front-mgr-6c77cbff68-dnfvq                            1/1     Running     0          21m</span><br><span class="line">default         vr-cms-front-portal-6cdc959586-2x8vq                         1/1     Running     0          116m</span><br><span class="line">default         vr-cms-front-svc-598774556-cxm4q                             1/1     Running     0          7h59m</span><br><span class="line">default         vr-cms-media-microservice-provider-6bcd4f7c54-fqzrf          1/1     Running     0          8h</span><br><span class="line">default         vr-cms-primary-data-microservice-provider-7ff77df5db-92qkg   1/1     Running     0          8h</span><br><span class="line">default         vr-cms-primary-data-microservice-provider-7ff77df5db-mzlwn   1/1     Running     0          8h</span><br><span class="line">default         vr-cms-primary-data-microservice-provider-7ff77df5db-n8dq6   1/1     Running     0          8h</span><br><span class="line">default         vr-cms-statistics-85494c478-d5kdx                            1/1     Running     0          8h</span><br><span class="line">default         vr-cms-task-74d94c9fb4-zb8hc                                 1/1     Running     0          8h</span><br><span class="line">default         vr-cms-user-microservice-provider-8ccb95449-nlmdh            1/1     Running     0          8h</span><br><span class="line">ingress-nginx   default-http-backend-5bcc9fd598-tmkb8                        1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-2wln7                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-b5j7p                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-d7f94                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-fz9vp                               1/1     Running     1          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-phgpx                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-pmstz                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-qczwd                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-v5kzw                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-vjb78                               1/1     Running     0          33d</span><br><span class="line">ingress-nginx   nginx-ingress-controller-x9r2s                               1/1     Running     0          33d</span><br><span class="line">kube-system     calico-kube-controllers-77cd95cb44-czv9l                     1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-2ft58                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-46ztz                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-4lfwb                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-7z42b                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-7zvvk                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-hbqch                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-lvszp                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-m5bbq                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-qj6qj                                            1/1     Running     0          33d</span><br><span class="line">kube-system     calico-node-w54qv                                            1/1     Running     0          33d</span><br><span class="line">kube-system     coredns-7ddb5877d9-4m7lw                                     1/1     Running     0          30d</span><br><span class="line">kube-system     coredns-7ddb5877d9-ldvrg                                     1/1     Running     0          30d</span><br><span class="line">kube-system     coredns-7ddb5877d9-r9fpl                                     1/1     Running     0          30d</span><br><span class="line">kube-system     coredns-autoscaler-84766fbb4-c5rz8                           1/1     Running     0          33d</span><br><span class="line">kube-system     metrics-server-59c6fd6767-mfzvt                              1/1     Running     0          33d</span><br><span class="line">kube-system     rke-coredns-addon-deploy-job-8fzgq                           0/1     Completed   0          33d</span><br><span class="line">kube-system     rke-ingress-controller-deploy-job-tv8xf                      0/1     Completed   0          33d</span><br><span class="line">kube-system     rke-metrics-addon-deploy-job-5nml9                           0/1     Completed   0          33d</span><br><span class="line">kube-system     rke-network-plugin-deploy-job-6nhbh                          0/1     Completed   0          33d</span><br><span class="line">kube-system     tiller-deploy-6658594489-kjcpk                               1/1     Running     0          33d</span><br><span class="line">upsource        upsource-697d5f8f68-d6tt8                                    1/1     Running     0          29d</span><br><span class="line">vr-center       vr-center-auth-server-798cbdd476-nw2qz                       1/1     Running     0          8h</span><br><span class="line">vr-center       vr-center-config-server-5b646545b8-gdxwp                     1/1     Running     0          4d21h</span><br><span class="line">vr-center       vr-center-front-mgr-86d77b499b-gbpm7                         1/1     Running     0          8h</span><br><span class="line">vr-center       vr-center-platform-consumer-5f5fdf77dc-g8gvc                 1/1     Running     0          8h</span><br><span class="line">vr-center       vr-center-statistics-df68f4774-gs6nk                         1/1     Running     0          8h</span><br><span class="line">vr-center       vr-center-user-server-584d7955ff-fjnr9                       1/1     Running     0          8h</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get deploy  --all-namespaces</span><br><span class="line">NAMESPACE       NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">argame          argame-admin                                1/1     1            1           4d17h</span><br><span class="line">argame          argame-center                               1/1     1            1           25d</span><br><span class="line">argame          argame-front-admin                          1/1     1            1           26d</span><br><span class="line">argame          argame-front-creator                        1/1     1            1           26d</span><br><span class="line">argame          argame-front-h5                             1/1     1            1           26d</span><br><span class="line">argame          argame-ws                                   1/1     1            1           25d</span><br><span class="line">argame          deploy-tool                                 1/1     1            1           29d</span><br><span class="line">argame          mq-externals                                1/1     1            1           5d22h</span><br><span class="line">argame          nginx-nas                                   1/1     1            1           26d</span><br><span class="line">cattle-system   cattle-cluster-agent                        1/1     1            1           33d</span><br><span class="line">cattle-system   rancher                                     3/3     3            3           33d</span><br><span class="line">default         ai-audit-service                            1/1     1            1           29d</span><br><span class="line">default         av-processor                                1/1     1            1           29d</span><br><span class="line">default         av-service                                  1/1     1            1           29d</span><br><span class="line">default         chat-service                                1/1     1            1           29d</span><br><span class="line">default         deploy-tool                                 1/1     1            1           29d</span><br><span class="line">default         file-service                                1/1     1            1           29d</span><br><span class="line">default         kibana-kibana                               1/1     1            1           19h</span><br><span class="line">default         live-service                                1/1     1            1           29d</span><br><span class="line">default         media-platform-ruiyue-service               1/1     1            1           29d</span><br><span class="line">default         nginx-nas                                   1/1     1            1           29d</span><br><span class="line">default         srs-edge                                    1/1     1            1           29d</span><br><span class="line">default         vod-service                                 1/1     1            1           29d</span><br><span class="line">default         vr-cms-activity                             1/1     1            1           29d</span><br><span class="line">default         vr-cms-admin-microservice-consumer          2/2     2            2           29d</span><br><span class="line">default         vr-cms-auth-server                          2/2     2            2           29d</span><br><span class="line">default         vr-cms-config-server                        2/2     2            2           29d</span><br><span class="line">default         vr-cms-customer-microservice-consumer       2/2     2            2           29d</span><br><span class="line">default         vr-cms-front-client                         1/1     1            1           29d</span><br><span class="line">default         vr-cms-front-mgr                            1/1     1            1           29d</span><br><span class="line">default         vr-cms-front-portal                         1/1     1            1           29d</span><br><span class="line">default         vr-cms-front-svc                            1/1     1            1           29d</span><br><span class="line">default         vr-cms-media-microservice-provider          1/1     1            1           29d</span><br><span class="line">default         vr-cms-primary-data-microservice-provider   3/3     3            3           29d</span><br><span class="line">default         vr-cms-statistics                           1/1     1            1           29d</span><br><span class="line">default         vr-cms-task                                 1/1     1            1           29d</span><br><span class="line">default         vr-cms-user-microservice-provider           1/1     1            1           29d</span><br><span class="line">ingress-nginx   default-http-backend                        1/1     1            1           33d</span><br><span class="line">kube-system     calico-kube-controllers                     1/1     1            1           33d</span><br><span class="line">kube-system     coredns                                     3/3     3            3           33d</span><br><span class="line">kube-system     coredns-autoscaler                          1/1     1            1           33d</span><br><span class="line">kube-system     metrics-server                              1/1     1            1           33d</span><br><span class="line">kube-system     tiller-deploy                               1/1     1            1           33d</span><br><span class="line">upsource        upsource                                    1/1     1            1           29d</span><br><span class="line">vr-center       vr-center-auth-server                       1/1     1            1           28d</span><br><span class="line">vr-center       vr-center-config-server                     1/1     1            1           27d</span><br><span class="line">vr-center       vr-center-front-mgr                         1/1     1            1           29d</span><br><span class="line">vr-center       vr-center-platform-consumer                 1/1     1            1           7d20h</span><br><span class="line">vr-center       vr-center-statistics                        1/1     1            1           27d</span><br><span class="line">vr-center       vr-center-user-server                       1/1     1            1           22d</span><br><span class="line"></span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get sts  --all-namespaces</span><br><span class="line">NAMESPACE   NAME                     READY   AGE</span><br><span class="line">argame      broker-a                 1/1     5d22h</span><br><span class="line">argame      broker-a-s               1/1     5d22h</span><br><span class="line">argame      broker-b                 1/1     5d22h</span><br><span class="line">argame      broker-b-s               1/1     5d22h</span><br><span class="line">argame      mongodb-ar               1/1     26d</span><br><span class="line">argame      mq-namesrv               2/2     5d22h</span><br><span class="line">argame      mysql-ar                 2/2     27d</span><br><span class="line">argame      redis-node               3/3     26d</span><br><span class="line">default     elasticsearch-master     3/3     29d</span><br><span class="line">default     kafka-master             3/3     29d</span><br><span class="line">default     kafka-master-zookeeper   1/1     29d</span><br><span class="line">default     mysql-vr                 2/2     29d</span><br><span class="line">default     redis609-node            3/3     29d</span><br><span class="line">default     srs-source               1/1     29d</span><br><span class="line">[root@guoyangyong5-2 ~]# kubectl get svc  --all-namespaces</span><br><span class="line">NAMESPACE       NAME                                        TYPE        CLUSTER-IP      EXTERNAL-IP     PORT(S)                         AGE</span><br><span class="line">argame          argame-admin-service                        ClusterIP   10.43.207.157   &lt;none&gt;          80/TCP                          4d17h</span><br><span class="line">argame          argame-center                               ClusterIP   10.43.194.255   &lt;none&gt;          80/TCP                          25d</span><br><span class="line">argame          argame-front-admin                          ClusterIP   10.43.112.47    &lt;none&gt;          80/TCP                          26d</span><br><span class="line">argame          argame-front-creator-service                ClusterIP   10.43.8.255     &lt;none&gt;          80/TCP                          26d</span><br><span class="line">argame          argame-front-h5-service                     ClusterIP   10.43.174.74    &lt;none&gt;          80/TCP                          26d</span><br><span class="line">argame          argame-ws-service                           ClusterIP   10.43.137.49    &lt;none&gt;          82/TCP                          25d</span><br><span class="line">argame          broker-a                                    NodePort    10.43.186.31    &lt;none&gt;          20911:30911/TCP                 5d22h</span><br><span class="line">argame          broker-a-s                                  NodePort    10.43.76.110    &lt;none&gt;          20911:30912/TCP                 5d22h</span><br><span class="line">argame          broker-b                                    NodePort    10.43.164.81    &lt;none&gt;          20911:30913/TCP                 5d22h</span><br><span class="line">argame          broker-b-s                                  NodePort    10.43.105.36    &lt;none&gt;          20911:30914/TCP                 5d22h</span><br><span class="line">argame          deploy-tool                                 ClusterIP   10.43.133.72    &lt;none&gt;          8000/TCP                        29d</span><br><span class="line">argame          mongodb-ar                                  ClusterIP   10.43.215.195   &lt;none&gt;          27017/TCP                       26d</span><br><span class="line">argame          mq-externals                                NodePort    10.43.94.18     &lt;none&gt;          80:30916/TCP                    5d22h</span><br><span class="line">argame          mq-namesrv                                  NodePort    10.43.152.233   &lt;none&gt;          20901:30915/TCP                 5d22h</span><br><span class="line">argame          mysql-ar                                    ClusterIP   10.43.198.144   &lt;none&gt;          3306/TCP                        27d</span><br><span class="line">argame          nginx-nas                                   ClusterIP   10.43.172.184   &lt;none&gt;          80/TCP                          26d</span><br><span class="line">argame          redis                                       ClusterIP   10.43.173.9     &lt;none&gt;          6379/TCP,26379/TCP              26d</span><br><span class="line">argame          redis-headless                              ClusterIP   None            &lt;none&gt;          6379/TCP,26379/TCP              26d</span><br><span class="line">cattle-system   rancher                                     ClusterIP   10.43.163.76    &lt;none&gt;          80/TCP                          33d</span><br><span class="line">default         ai-audit-service                            NodePort    10.43.80.242    &lt;none&gt;          80:31199/TCP                    29d</span><br><span class="line">default         av-processor                                NodePort    10.43.17.113    &lt;none&gt;          80:31196/TCP                    29d</span><br><span class="line">default         av-service                                  NodePort    10.43.244.44    &lt;none&gt;          80:31195/TCP                    29d</span><br><span class="line">default         chat-service                                ClusterIP   10.43.135.113   &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         chat-service-ws                             ClusterIP   10.43.86.245    &lt;none&gt;          81/TCP,82/TCP                   29d</span><br><span class="line">default         deploy-tool                                 ClusterIP   10.43.255.23    &lt;none&gt;          8000/TCP                        29d</span><br><span class="line">default         elasticsearch-master                        ClusterIP   10.43.30.102    &lt;none&gt;          9200/TCP,9300/TCP               29d</span><br><span class="line">default         elasticsearch-master-dev                    NodePort    10.43.179.22    &lt;none&gt;          9200:30029/TCP,9300:30871/TCP   29d</span><br><span class="line">default         elasticsearch-master-headless               ClusterIP   None            &lt;none&gt;          9200/TCP,9300/TCP               29d</span><br><span class="line">default         file-service                                ClusterIP   10.43.171.87    &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         gd-upstream-service                         ClusterIP   10.43.67.1      &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         kafka-master                                ClusterIP   10.43.188.87    &lt;none&gt;          9092/TCP                        29d</span><br><span class="line">default         kafka-master-headless                       ClusterIP   None            &lt;none&gt;          9092/TCP,9093/TCP               29d</span><br><span class="line">default         kafka-master-zookeeper                      ClusterIP   10.43.65.89     &lt;none&gt;          2181/TCP,2888/TCP,3888/TCP      29d</span><br><span class="line">default         kafka-master-zookeeper-headless             ClusterIP   None            &lt;none&gt;          2181/TCP,2888/TCP,3888/TCP      29d</span><br><span class="line">default         kibana-kibana                               ClusterIP   10.43.149.102   &lt;none&gt;          5601/TCP                        19h</span><br><span class="line">default         kibana-kibana-dev                           NodePort    10.43.243.8     &lt;none&gt;          5601:31065/TCP                  19h</span><br><span class="line">default         kong-kong-admin                             ClusterIP   10.43.97.140    &lt;none&gt;          8001/TCP                        29d</span><br><span class="line">default         kong-kong-proxy                             ClusterIP   10.43.188.65    &lt;none&gt;          80/TCP,443/TCP                  29d</span><br><span class="line">default         kubernetes                                  ClusterIP   10.43.0.1       &lt;none&gt;          443/TCP                         33d</span><br><span class="line">default         live-service                                NodePort    10.43.141.213   &lt;none&gt;          80:31193/TCP                    29d</span><br><span class="line">default         media-platform-ruiyue-service               NodePort    10.43.160.183   &lt;none&gt;          8080:30201/TCP                  29d</span><br><span class="line">default         mysql-vr                                    NodePort    10.43.10.12     &lt;none&gt;          3306:30308/TCP                  29d</span><br><span class="line">default         nginx-nas                                   ClusterIP   10.43.101.41    &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         redis609                                    ClusterIP   10.43.164.54    &lt;none&gt;          6379/TCP,26379/TCP              29d</span><br><span class="line">default         redis609-headless                           ClusterIP   None            &lt;none&gt;          6379/TCP,26379/TCP              29d</span><br><span class="line">default         srs-edge                                    ClusterIP   10.43.73.138    172.21.42.251   1935/TCP                        29d</span><br><span class="line">default         srs-source                                  ClusterIP   10.43.55.227    172.21.42.251   1936/TCP,1985/TCP,8000/TCP      29d</span><br><span class="line">default         srs-source-headless                         ClusterIP   None            &lt;none&gt;          &lt;none&gt;                          29d</span><br><span class="line">default         vod-service                                 NodePort    10.43.184.189   &lt;none&gt;          80:31198/TCP                    29d</span><br><span class="line">default         vr-cms-activity                             NodePort    10.43.191.67    &lt;none&gt;          80:31188/TCP                    29d</span><br><span class="line">default         vr-cms-admin-microservice-consumer          NodePort    10.43.197.62    &lt;none&gt;          80:30113/TCP                    29d</span><br><span class="line">default         vr-cms-auth-server                          NodePort    10.43.153.174   &lt;none&gt;          80:30110/TCP                    29d</span><br><span class="line">default         vr-cms-config-server                        NodePort    10.43.15.27     &lt;none&gt;          80:30111/TCP                    29d</span><br><span class="line">default         vr-cms-customer-microservice-consumer       NodePort    10.43.230.134   &lt;none&gt;          80:30114/TCP                    29d</span><br><span class="line">default         vr-cms-front-client-server                  ClusterIP   10.43.48.58     &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         vr-cms-front-client-svc                     ClusterIP   10.43.128.77    &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         vr-cms-front-mgr-server                     ClusterIP   10.43.153.149   &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         vr-cms-front-portal-server                  ClusterIP   10.43.233.216   &lt;none&gt;          80/TCP                          29d</span><br><span class="line">default         vr-cms-media-microservice-provider          NodePort    10.43.242.130   &lt;none&gt;          80:30131/TCP                    29d</span><br><span class="line">default         vr-cms-primary-data-microservice-provider   NodePort    10.43.125.27    &lt;none&gt;          80:30141/TCP                    29d</span><br><span class="line">default         vr-cms-statistics                           NodePort    10.43.94.53     &lt;none&gt;          80:30151/TCP                    29d</span><br><span class="line">default         vr-cms-task                                 NodePort    10.43.143.132   &lt;none&gt;          80:30115/TCP                    29d</span><br><span class="line">default         vr-cms-user-microservice-provider           NodePort    10.43.161.237   &lt;none&gt;          80:30120/TCP                    29d</span><br><span class="line">ingress-nginx   default-http-backend                        ClusterIP   10.43.253.136   &lt;none&gt;          80/TCP                          33d</span><br><span class="line">kube-system     kube-dns                                    ClusterIP   10.43.0.10      &lt;none&gt;          53/UDP,53/TCP,9153/TCP          33d</span><br><span class="line">kube-system     metrics-server                              ClusterIP   10.43.244.182   &lt;none&gt;          443/TCP                         33d</span><br><span class="line">kube-system     tiller-deploy                               ClusterIP   10.43.130.160   &lt;none&gt;          44134/TCP                       33d</span><br><span class="line">upsource        upsource-svc                                ClusterIP   10.43.223.22    &lt;none&gt;          8080/TCP                        29d</span><br><span class="line">vr-center       vr-center-auth-server                       NodePort    10.43.236.60    &lt;none&gt;          80:32003/TCP                    28d</span><br><span class="line">vr-center       vr-center-config-server                     NodePort    10.43.220.77    &lt;none&gt;          80:32001/TCP                    27d</span><br><span class="line">vr-center       vr-center-front-mgr-server                  NodePort    10.43.142.56    &lt;none&gt;          80:32101/TCP                    29d</span><br><span class="line">vr-center       vr-center-platform-consumer                 NodePort    10.43.250.139   &lt;none&gt;          80:32002/TCP                    7d20h</span><br><span class="line">vr-center       vr-center-statistics                        NodePort    10.43.121.78    &lt;none&gt;          80:32005/TCP                    27d</span><br><span class="line">vr-center       vr-center-user-server                       NodePort    10.43.79.150    &lt;none&gt;          80:32004/TCP                    22d</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ansible </span><br><span class="line">#修改cluster.yml 修改 psp: true </span><br><span class="line">rke up 失败， --&gt; 版本不对</span><br><span class="line"></span><br><span class="line">使用rke032， 失败， 部分节点公钥被改，不能免密</span><br><span class="line">172.21.42.221</span><br><span class="line">172.21.42.230,</span><br><span class="line">172.21.42.179,</span><br><span class="line">172.21.42.165,</span><br><span class="line">172.21.42.125,</span><br><span class="line">172.21.42.217,</span><br><span class="line">172.21.42.20,</span><br><span class="line">172.21.42.13</span><br><span class="line">--&gt;添加公钥</span><br><span class="line">按照172.21.42.59的公钥拷贝，主机登录密码Cmcc!234 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>docker学习笔记</title>
    <url>/2021/10/01/2021-10-01-docker-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="1-docker概述"><a href="#1-docker概述" class="headerlink" title="1  docker概述"></a>1  docker概述</h2><h3 id="1-1-docker是什么？"><a href="#1-1-docker是什么？" class="headerlink" title="1.1 docker是什么？"></a>1.1 docker是什么？</h3><p>开发和运维的环境不同，可能导致程序在开发的环境中可以正常运行而在运维的环境中出错。为了解决这个问题， docker可以将项目和环境一起打包，可以保持项目和环境保持一致。（问题驱动，需求驱动）</p>
<h3 id="1-2-docker发展"><a href="#1-2-docker发展" class="headerlink" title="1.2 docker发展"></a>1.2 docker发展</h3><pre><code>1. Docker 公司位于旧金山，由法裔美籍开发者和企业家 Solumon Hykes 创立，起初是一家名为 dotCloud 的提供Paas的公司。
2. 2013年，dotCloud 的 PaaS 业务并不景气，公司需要寻求新的突破。于是他们聘请了 Ben Golub 作为新的 CEO，将公司重命名为“Docker”，放弃dotCloud PaaS 平台，怀揣着“将 Docker 和容器技术推向全世界”的使命，开启了一段新的征程。
</code></pre>
<ol start="3">
<li>现今的Docker 公司已经通过多轮融资，吸纳了来自硅谷的几家风投公司的累计超过 2.4 亿美元的投资。</li>
<li>docker相比于虚拟机，十分的小巧，启动快速 </li>
</ol>
<h3 id="1-3-docker的特点"><a href="#1-3-docker的特点" class="headerlink" title="1.3 docker的特点"></a>1.3 docker的特点</h3><p>与传统虚拟化方法相比， 传统的虚拟机虚拟完整的硬件， 然后在系统上运行软件，而容器没有硬件和内核，所以非常轻便， 而且容器之间隔离的。</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qmn5vXcT-1632447380520)(E:\blogpic\docker1.png)][外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-eRa8IowA-1632447380524)(E:\blogpic\docker2.png)]</p>
<h3 id="1-4-使用docker后-DevOps-开发与运维的变化"><a href="#1-4-使用docker后-DevOps-开发与运维的变化" class="headerlink" title="1.4  使用docker后 DevOps 开发与运维的变化"></a>1.4  使用docker后 DevOps 开发与运维的变化</h3><ol>
<li> 应用更快速的交付和部署，传统一堆帮助文档需要安装环境，现在一键部署</li>
<li> 更便捷的升级和扩缩容，项目打包成一个镜像，像搭积木一样部署</li>
<li> 更简单的系统运维，开发测试运维的环境高度一致</li>
<li> 更高效的计算资源利用，一个服务器上可以运行多个容器，提高资源利用效率。 </li>
</ol>
<h2 id="2-docker的使用"><a href="#2-docker的使用" class="headerlink" title="2 docker的使用"></a>2 docker的使用</h2><h3 id="2-1-docker基本概念"><a href="#2-1-docker基本概念" class="headerlink" title="2.1 docker基本概念"></a>2.1 docker基本概念</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/0e7c35e8d9a60f643d6dda8d7de66fe9.png"></p>
<ul>
<li>镜像(image)</li>
</ul>
<p>docker镜像就像模板，可以通过模板来创建容器服务，</p>
<ul>
<li>容器(container)</li>
</ul>
<p>通过容器可以独立运行一个或一组应用，就像一个简易的linux系统</p>
<ul>
<li>仓库(repository)</li>
</ul>
<p>仓库就是存放镜像的地方，分为共有仓库和私有仓库</p>
<h3 id="2-2安装docker"><a href="#2-2安装docker" class="headerlink" title="2.2安装docker"></a>2.2安装docker</h3><h4 id="2-2-1环境准备"><a href="#2-2-1环境准备" class="headerlink" title="2.2.1环境准备"></a>2.2.1环境准备</h4><blockquote>
<p>服务器：腾讯云服务器</p>
<p>系统: centos 7 </p>
<p>内核版本: 3.10.0-1160.31.1.el7.x86_64 </p>
<p>系统版本：[root@VM-4-6-centos ~]$ cat /etc/os-release<br>NAME=”CentOS Linux”<br>VERSION=”7 (Core)”<br>ID=”centos”<br>ID_LIKE=”rhel fedora”<br>VERSION_ID=”7”<br>PRETTY_NAME=”CentOS Linux 7 (Core)”<br>ANSI_COLOR=”0;31”<br>CPE_NAME=”cpe:/o:centos:centos:7”<br>HOME_URL=”<a href="https://www.centos.org/&quot;">https://www.centos.org/&quot;</a><br>BUG_REPORT_URL=”<a href="https://bugs.centos.org/&quot;">https://bugs.centos.org/&quot;</a></p>
<p>CENTOS_MANTISBT_PROJECT=”CentOS-7”<br>CENTOS_MANTISBT_PROJECT_VERSION=”7”<br>REDHAT_SUPPORT_PRODUCT=”centos”<br>REDHAT_SUPPORT_PRODUCT_VERSION=”7”</p>
</blockquote>
<h4 id="2-2-2-安装"><a href="#2-2-2-安装" class="headerlink" title="2.2.2 安装"></a>2.2.2 安装</h4><ol>
<li><p>[docker官网](<a href="https://docs.docker.com/get-docker/">Get Docker | Docker Documentation</a>)选择适合的系统，版本 </p>
</li>
<li><p>若安装过，卸载旧的版本 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                 docker-client \</span><br><span class="line">                 docker-client-latest \</span><br><span class="line">                 docker-common \</span><br><span class="line">                 docker-latest \</span><br><span class="line">                 docker-latest-logrotate \</span><br><span class="line">                 docker-logrotate \</span><br><span class="line">                 docker-engine</span><br></pre></td></tr></table></figure></li>
<li><p>通过库安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1 安装依赖库</span><br><span class="line"> sudo yum install -y yum-utils</span><br><span class="line"> </span><br><span class="line"># 2 安装docker仓库</span><br><span class="line"> sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">   </span><br><span class="line"># 国外的仓库很慢，可以使用国内的镜像快一点 </span><br><span class="line"> sudo yum-config-manager \</span><br><span class="line">	--add-repo \</span><br><span class="line">	http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"># 3 安装docker</span><br><span class="line"> sudo yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line"></span><br><span class="line"># 安装docker compose </span><br><span class="line">curl -L https://get.daocloud.io/docker/compose/releases/download/1.19.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose</span><br><span class="line"></span><br><span class="line">chmod +x /usr/local/bin/docker-compose</span><br><span class="line"></span><br><span class="line">　　docker-compose version # 查看版本号，测试是否安装成功</span><br><span class="line">      你可以通过修改URL中的版本，可以自定义您的需要的版本。</span><br></pre></td></tr></table></figure></li>
<li><p>启动docker</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">  <span class="comment"># 1 启动  </span></span><br><span class="line">  sudo systemctl start docker</span><br><span class="line">  <span class="comment"># 2 参看版本</span></span><br><span class="line">  docker version</span><br><span class="line">  <span class="comment"># 成功以后会出现以下信息:</span></span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           20.10.8</span><br><span class="line"> API version:       1.41</span><br><span class="line"> Go version:        go1.16.6</span><br><span class="line"> Git commit:        3967b7d</span><br><span class="line"> Built:             Fri Jul 30 19:55:49 2021</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Context:           default</span><br><span class="line"> Experimental:      <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          20.10.8</span><br><span class="line">  API version:      1.41 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.16.6</span><br><span class="line">  Git commit:       75249d8</span><br><span class="line">  Built:            Fri Jul 30 19:54:13 2021</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     <span class="literal">false</span></span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.4.9</span><br><span class="line">  GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.1</span><br><span class="line">  GitCommit:        v1.0.1-0-g4144b63</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.19.0</span><br><span class="line">  GitCommit:        de40ad0</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>docker hello word </li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>



<h3 id="2-2-3-卸载dcoker"><a href="#2-2-3-卸载dcoker" class="headerlink" title="2.2.3 卸载dcoker"></a>2.2.3 卸载dcoker</h3><blockquote>
<p>分为两步，卸载docekr,删除文件 </p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1 卸载</span><br><span class="line">  sudo yum remove docker-ce docker-ce-cli containerd.io</span><br><span class="line"># 2删除文件</span><br><span class="line">  sudo rm -rf /var/lib/docker</span><br><span class="line">  sudo rm -rf /var/lib/containerd</span><br></pre></td></tr></table></figure>

<h3 id="2-2-4-配置腾讯云镜像加速"><a href="#2-2-4-配置腾讯云镜像加速" class="headerlink" title="2.2.4 配置腾讯云镜像加速"></a>2.2.4 配置腾讯云镜像加速</h3><h3 id="使用腾讯云-Docker-镜像源加速镜像下载"><a href="#使用腾讯云-Docker-镜像源加速镜像下载" class="headerlink" title="使用腾讯云 Docker 镜像源加速镜像下载"></a>使用腾讯云 Docker 镜像源加速镜像下载</h3><p>安装 Docker 软件后，如果未配置镜像加速源，直接拉取 DockerHub 中的镜像，通常下载速度会比较慢。<br>为此，我们推荐您使用腾讯云 Docker 镜像源加速镜像下载。</p>
<blockquote>
<p>适用于 Linux 操作系统实例：    </p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#1 找到配置文件</span><br><span class="line"> cd /etc/docker/daemon.json</span><br><span class="line">#2 vim编辑配置文件</span><br><span class="line"> vim /etc/docker/daemon.json</span><br><span class="line">#3 添加以下内容并保存</span><br><span class="line">    &#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [</span><br><span class="line">     &quot;https://mirror.ccs.tencentyun.com&quot;</span><br><span class="line">    ]</span><br><span class="line">    &#125;</span><br><span class="line">#4 重启docker生效</span><br><span class="line"> systemctl restart docker</span><br></pre></td></tr></table></figure>

<h2 id="3-docker是如何工作的？"><a href="#3-docker是如何工作的？" class="headerlink" title="3 docker是如何工作的？"></a>3 docker是如何工作的？</h2><h3 id="3-1运行docker-run-image发生什么"><a href="#3-1运行docker-run-image发生什么" class="headerlink" title="3.1运行docker run image发生什么"></a>3.1运行docker run image发生什么</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/ebcff54d9e066f086c0ccee88831f2cc.png"></p>
<h3 id="3-2-docker-底层原理"><a href="#3-2-docker-底层原理" class="headerlink" title="3.2 docker 底层原理"></a>3.2 docker 底层原理</h3><p>docker是一个client-server结构的系统，docker的守护进程运行在宿主机上，通过socket连接。</p>
<p>dockerserver 接收到dockerclient的指令，就好执行这个命令。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/dcf0532a3fdcab47c3f9e55610f72ecf.png"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/f9fc6ab580adc10823714351cfba8864.png"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/70165617fe4144021e8e40b7f79d3e82.png"></p>
<ul>
<li>docker比vm更少的抽象层，不需要guest os,省去了很多启动引导过程。</li>
</ul>
<h2 id="4-docker-命令"><a href="#4-docker-命令" class="headerlink" title="4 docker 命令"></a>4 docker 命令</h2><p>docker官网有所有的命令说明(<a href="https://docs.docker.com/reference/">Reference documentation | Docker Documentation</a>)， 菜鸟网也有中文版本的命令说明。命令详细用法在help和文档中都可以查到，这个不再赘述，主要给出常用命令，对docker能做什么以及怎么做有个概念。</p>
<h3 id="4-1基础命令"><a href="#4-1基础命令" class="headerlink" title="4.1基础命令"></a>4.1基础命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker command --help # 帮助命令</span><br><span class="line">docker info # 系统信息</span><br><span class="line">docker version # 版本信息</span><br></pre></td></tr></table></figure>

<h3 id="4-2-镜像命令"><a href="#4-2-镜像命令" class="headerlink" title="4.2 镜像命令"></a>4.2 镜像命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker images # 查看镜像</span><br><span class="line">docker search image # 搜索镜像</span><br><span class="line">decher pull image # 下载镜像</span><br><span class="line">docker rmi image # 删除镜像</span><br></pre></td></tr></table></figure>

<h3 id="4-3-容器命令"><a href="#4-3-容器命令" class="headerlink" title="4.3 容器命令"></a>4.3 容器命令</h3><blockquote>
<p>有了镜像才可以下载容器</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run container # 启动容器</span><br><span class="line">exit # 停止运行并退出容器</span><br><span class="line">ctrl + p + q # 退出容器</span><br><span class="line">docker ps # 查看运行的容器</span><br><span class="line">docker rm container # 删除容器</span><br><span class="line">docker start container # 启动容器</span><br><span class="line">docker restart # 重启容器</span><br><span class="line">docker stop container # 停止容器运行</span><br><span class="line">docker kill container # 强制停止容器</span><br></pre></td></tr></table></figure>

<h3 id="4-4-其他常用命令"><a href="#4-4-其他常用命令" class="headerlink" title="4.4 其他常用命令"></a>4.4 其他常用命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker logs # 查看日志</span><br><span class="line">docker ps # 查看容器进程</span><br><span class="line">docker top # 查看容器内进程</span><br><span class="line">docker inspect # 查看镜像的元数据</span><br><span class="line">docker exec container_id # 进入在执行的容器打开新的终端</span><br><span class="line">docker attach container_id # 进入容器正在执行的终端</span><br><span class="line">docker ps container_id:path hostpath # 容器内复制文件到宿主机</span><br></pre></td></tr></table></figure>

<p>按照字母排序总结： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">attach    Attach to a running container  #当前shell下attach连接指定运行镜像</span><br><span class="line">build     Build an image from a Dockerfile  #通过Dockerfile定制镜像</span><br><span class="line">commit    Create a new image from a containers changes  #提交当前容器为新的镜像</span><br><span class="line">cp    Copy files/folders from a container to a HOSTDIR or to STDOUT  #从容器中拷贝指定文件或者目录到宿主机中</span><br><span class="line">create    Create a new container  #创建一个新的容器，同run 但不启动容器</span><br><span class="line">diff    Inspect changes on a containers filesystem  #查看docker容器变化</span><br><span class="line">events    Get real time events from the server#从docker服务获取容器实时事件</span><br><span class="line">exec    Run a command in a running container#在已存在的容器上运行命令</span><br><span class="line">export    Export a containers filesystem as a tar archive  #导出容器的内容流作为一个tar归档文件(对应import)</span><br><span class="line">history    Show the history of an image  #展示一个镜像形成历史</span><br><span class="line">images    List images  #列出系统当前镜像</span><br><span class="line">import    Import the contents from a tarball to create a filesystem image  #从tar包中的内容创建一个新的文件系统映像(对应export)</span><br><span class="line">info    Display system-wide information  #显示系统相关信息</span><br><span class="line">inspect    Return low-level information on a container or image  #查看容器详细信息</span><br><span class="line">kill    Kill a running container  #kill指定docker容器</span><br><span class="line">load    Load an image from a tar archive or STDIN  #从一个tar包中加载一个镜像(对应save)</span><br><span class="line">login    Register or log in to a Docker registry#注册或者登陆一个docker源服务器</span><br><span class="line">logout    Log out from a Docker registry  #从当前Docker registry退出</span><br><span class="line">logs    Fetch the logs of a container  #输出当前容器日志信息</span><br><span class="line">pause    Pause all processes within a container#暂停容器</span><br><span class="line">port    List port mappings or a specific mapping for the CONTAINER  #查看映射端口对应的容器内部源端口</span><br><span class="line">ps    List containers  #列出容器列表</span><br><span class="line">pull    Pull an image or a repository from a registry  #从docker镜像源服务器拉取指定镜像或者库镜像</span><br><span class="line">push    Push an image or a repository to a registry  #推送指定镜像或者库镜像至docker源服务器</span><br><span class="line">rename    Rename a container  #重命名容器</span><br><span class="line">restart    Restart a running container  #重启运行的容器</span><br><span class="line">rm    Remove one or more containers  #移除一个或者多个容器</span><br><span class="line">rmi    Remove one or more images  #移除一个或多个镜像(无容器使用该镜像才可以删除，否则需要删除相关容器才可以继续或者-f强制删除)</span><br><span class="line">run    Run a command in a new container  #创建一个新的容器并运行一个命令</span><br><span class="line">save    Save an image(s) to a tar archive#保存一个镜像为一个tar包(对应load)</span><br><span class="line">search    Search the Docker Hub for images  #在docker</span><br><span class="line">hub中搜索镜像</span><br><span class="line">start    Start one or more stopped containers#启动容器</span><br><span class="line">stats    Display a live stream of container(s) resource usage statistics  #统计容器使用资源</span><br><span class="line">stop    Stop a running container  #停止容器</span><br><span class="line">tag         Tag an image into a repository  #给源中镜像打标签</span><br><span class="line">top       Display the running processes of a container #查看容器中运行的进程信息</span><br><span class="line">unpause    Unpause all processes within a container  #取消暂停容器</span><br><span class="line">version    Show the Docker version information#查看容器版本号</span><br><span class="line">wait         Block until a container stops, then print its exit code  #截取容器停止时的退出状态值</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/img_convert/39eb949eeb5bd5d4556599bb612867ef.png"></p>
<h2 id="5-docker实例操作"><a href="#5-docker实例操作" class="headerlink" title="5 docker实例操作"></a>5 docker实例操作</h2><h3 id="5-1-部署Nginx"><a href="#5-1-部署Nginx" class="headerlink" title="5.1 部署Nginx"></a>5.1 部署Nginx</h3><p><code>1 搜索nginx镜像 </code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@VM-4-6-centos /]# docker search nginx</span><br><span class="line">NAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED</span><br><span class="line">nginx                             Official build of Nginx.                        15374     [OK]       </span><br><span class="line">jwilder/nginx-proxy               Automated Nginx reverse proxy for docker con…   2060                 [OK]</span><br><span class="line">richarvey/nginx-php-fpm           Container running Nginx + PHP-FPM capable of…   816                  [OK]</span><br><span class="line">jc21/nginx-proxy-manager          Docker container for managing Nginx proxy ho…   236   </span><br></pre></td></tr></table></figure>

<blockquote>
<p>docker hub可以看大更详细的镜像信息</p>
</blockquote>
<p><code>2 下载镜像</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos /]# docker pull nginx</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/nginx</span><br><span class="line">e1acddbe380c: Pull complete </span><br><span class="line">e21006f71c6f: Pull complete </span><br><span class="line">f3341cc17e58: Pull complete </span><br><span class="line">2a53fa598ee2: Pull complete </span><br><span class="line">12455f71a9b5: Pull complete </span><br><span class="line">b86f2ba62d17: Pull complete </span><br><span class="line">Digest: sha256:4d4d96ac750af48c6a551d757c1cbfc071692309b491b70b2b8976e102dd3fef</span><br><span class="line">Status: Downloaded newer image for nginx:latest</span><br><span class="line">docker.io/library/nginx:latest </span><br><span class="line"># 下载成功</span><br></pre></td></tr></table></figure>

<p><code>3 查看镜像</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker images </span><br><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">nginx         latest    dd34e67e3371   10 days ago    133MB</span><br></pre></td></tr></table></figure>

<p><code>4  运行容器</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker run -d --name nginx001 -p 80:80 nginx</span><br><span class="line">44c86d145d151622d0e7512050c4fead714047be0256c7f6af098ec0452ba428</span><br></pre></td></tr></table></figure>

<p><code>5 查看容器</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                               NAMES</span><br><span class="line">44c86d145d15   nginx     &quot;/docker-entrypoint.…&quot;   35 minutes ago   Up 35 minutes   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx001</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>6 测试</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker exec -it nginx001 /bin/bash</span><br><span class="line">root@44c86d145d15:/# ls</span><br><span class="line">bin   dev                  docker-entrypoint.sh  home  lib64  mnt  proc  run   srv  tmp  var</span><br><span class="line">boot  docker-entrypoint.d  etc                   lib   media  opt  root  sbin  sys  usr</span><br></pre></td></tr></table></figure>

<p>外网访问：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/97843e56232d1d4cfb59d6ba53a48d01.png"></p>
<p><code>7关闭容器</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker stop nginx001</span><br><span class="line">nginx001</span><br></pre></td></tr></table></figure>



<h3 id="5-2-部署tomcat"><a href="#5-2-部署tomcat" class="headerlink" title="5.2 部署tomcat"></a>5.2 部署tomcat</h3><p><code>1 搜索nginx镜像 </code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker search tomcat </span><br><span class="line">NAME                          DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED</span><br><span class="line">tomcat                        Apache Tomcat is an open source implementati…   3106      [OK]       </span><br><span class="line">tomee                         Apache TomEE is an all-Apache Java EE certif…   92        [OK]       </span><br><span class="line">dordoka/tomcat                Ubuntu 14.04, Oracle JDK 8 and Tomcat 8 base…   58                   [OK]</span><br><span class="line">kubeguide/tomcat-app          Tomcat image for Chapter 1                      30                   </span><br><span class="line">consol/tomcat-7.0             Tomcat 7.0.57, 8080, &quot;admin/admin&quot;              18                   [OK]</span><br><span class="line">cloudesire/tomcat             Tomcat server, 6/7/8                            15                   [OK]</span><br><span class="line">aallam/tomcat-mysql           Debian, Oracle JDK, Tomcat &amp; MySQL              13                   [OK]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>docker hub可以看大更详细的镜像信息</p>
</blockquote>
<p><code>2 下载镜像</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker pull tomcat Using default tag: latestlatest: Pulling from library/tomcat1cfaf5c6f756: Pull complete c4099a935a96: Pull complete f6e2960d8365: Pull complete dffd4e638592: Pull complete a60431b16af7: Pull complete 4869c4e8de8d: Pull complete 9815a275e5d0: Pull complete c36aa3d16702: Pull complete cc2e74b6c3db: Pull complete 1827dd5c8bb0: Pull complete Digest: sha256:1af502b6fd35c1d4ab6f24dc9bd36b58678a068ff1206c25acc129fb90b2a76aStatus: Downloaded newer image for tomcat:latestdocker.io/library/tomcat:latest# 下载成功</span><br></pre></td></tr></table></figure>

<p><code>3 查看镜像</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED        SIZEtomcat        latest    266d1269bb29   9 days ago     668MBnginx         latest    dd34e67e3371   10 days ago    133MB</span><br></pre></td></tr></table></figure>

<p><code>4  运行容器</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker run -d --name tomcat001 -p 80:8080 tomcat4400a14a931baa9fbc324d003ce26e06debba3456435b233ed5b77eccf7b4379</span><br></pre></td></tr></table></figure>

<p><code>5 查看容器</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker psCONTAINER ID   IMAGE     COMMAND             CREATED          STATUS          PORTS                                         NAMES4400a14a931b   tomcat    &quot;catalina.sh run&quot;   25 seconds ago   Up 25 seconds   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp, 8080/tcp   tomcat001</span><br></pre></td></tr></table></figure>

<p><code>6 测试</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker exec -it tomcat001 /bin/bashroot@4400a14a931b:/usr/local/tomcat# lsBUILDING.txt     LICENSE  README.md      RUNNING.txt  conf  logs            temp     webapps.distCONTRIBUTING.md  NOTICE   RELEASE-NOTES  bin          lib   native-jni-lib  webapps  workroot@4400a14a931b:/usr/local/tomcat# cp -r  webapps.dist/*  webapps</span><br></pre></td></tr></table></figure>

<p>外网访问：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/82aabf75dda02775eef5b166dd6f0e4f.png"></p>
<p>7关闭容器`</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker stop tomcat001tomcat001</span><br></pre></td></tr></table></figure>

<p>经过实例的练习之后，前面学的命令熟练了许多。</p>
<h2 id="6-图形交互面板"><a href="#6-图形交互面板" class="headerlink" title="6 图形交互面板"></a>6 图形交互面板</h2><h3 id="6-1portainer"><a href="#6-1portainer" class="headerlink" title="6.1portainer"></a>6.1portainer</h3><ol>
<li>portainer是什么？</li>
</ol>
<p>Portainer是一个可视化的容器镜像的图形管理工具，利用Portainer可以轻松构建，管理和维护Docker环境。 而且完全免费，基于容器化的安装方式，方便高效部署。</p>
<ol start="2">
<li><p>安装 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1. 下载镜像</span><br><span class="line">docker pull portainer/portainer</span><br><span class="line"># 2. 启动服务</span><br><span class="line">docker run -d --name portainerUI -p 80:9000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer</span><br></pre></td></tr></table></figure>

<p>示例： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker pull portainer/portainer</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from portainer/portainer</span><br><span class="line">94cfa856b2b1: Pull complete </span><br><span class="line">49d59ee0881a: Pull complete </span><br><span class="line">a2300fd28637: Pull complete </span><br><span class="line">Digest: sha256:fb45b43738646048a0a0cc74fcee2865b69efde857e710126084ee5de9be0f3f</span><br><span class="line">Status: Downloaded newer image for portainer/portainer:latest</span><br><span class="line">docker.io/portainer/portainer:latest</span><br><span class="line">[root@VM-4-6-centos lighthouse]# docker run -d --name portainerUI -p 80:9000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer</span><br><span class="line">b9be7097fe79eecbff8f201103c641692684cad7726a5103dbc33a68bfff8e71</span><br></pre></td></tr></table></figure></li>
<li><p>使用 </p>
<p>使用服务器ip:端口，即可打开</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1f56411b989346c08a2c9e290be195a5.png"></p>
</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/726c21817579deb8ec8074da769e8640.png"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/58e4f7f86f810e15d8c18893f525b3be.png"></p>
<h2 id="7-docker镜像加载原理"><a href="#7-docker镜像加载原理" class="headerlink" title="7 docker镜像加载原理"></a>7 docker镜像加载原理</h2><h3 id="7-1联合文件系统-Union-Filesystem"><a href="#7-1联合文件系统-Union-Filesystem" class="headerlink" title="7.1联合文件系统(Union Filesystem)"></a>7.1联合文件系统(Union Filesystem)</h3><p>联合文件系统是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。<br>联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d17c361c9fc9b847164489e6ad28cdef.png"></p>
<p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</p>
<h3 id="7-2-docker-镜像加载"><a href="#7-2-docker-镜像加载" class="headerlink" title="7.2 docker 镜像加载"></a>7.2 docker 镜像加载</h3><p>docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。<br>boots(boot file system）主要包含 bootloader和 Kernel, bootloader主要是引导加 kernel, Linux刚启动时会加bootfs文件系统，在 Docker镜像的最底层是 boots。这一层与我们典型的Linux/Unix系统是一样的，包含boot加載器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由 bootfs转交给内核，此时系统也会卸载bootfs。<br>rootfs（root file system),在 bootfs之上。包含的就是典型 Linux系统中的/dev,/proc,/bin,/etc等标准目录和文件。 rootfs就是各种不同的操作系统发行版，比如 Ubuntu, Centos等等。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/dc540ea7f18314b12ec4fd0b71a83f55.png"></p>
<p>对于个精简的OS,rootfs可以很小，只需要包合最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的Linux发行版， boots基本是一致的， rootfs会有差別，因此不同的发行版可以公用bootfs.</p>
<p>虚拟机是分钟级别，容器是秒级！</p>
<h3 id="7-3-分层"><a href="#7-3-分层" class="headerlink" title="7.3 分层"></a>7.3 分层</h3><p>当我们去观察镜像的下载的输出日志，是在一层一层下载。这中分层最大的好处就是资源共享。比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享。</p>
<p>查看镜像分层的方式可以通过<code>docker image inspect</code> 命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lighthouse]# docker image inspect tomcat</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;sha256:266d1269bb298d6a3259fc2c2a9deaedf8be945482a2d596b64f73343289a56c&quot;,</span><br><span class="line">        &quot;RepoTags&quot;: [</span><br><span class="line">            &quot;tomcat:latest&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;tomcat@sha256:1af502b6fd35c1d4ab6f24dc9bd36b58678a068ff1206c25acc129fb90b2a76a&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;Parent&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Comment&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2021-08-18T20:48:04.549796116Z&quot;,</span><br><span class="line">        &quot;Container&quot;: &quot;d2ecb6a64fdc3e7fef05d7909154d295574519fa144d8507cf7c9a5a6c5ea8b3&quot;,</span><br><span class="line">        &quot;ContainerConfig&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;d2ecb6a64fdc&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">                &quot;8080/tcp&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [</span><br><span class="line">                &quot;PATH=/usr/local/tomcat/bin:/usr/local/openjdk-11/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">                &quot;JAVA_HOME=/usr/local/openjdk-11&quot;,</span><br><span class="line">                &quot;LANG=C.UTF-8&quot;,</span><br><span class="line">                &quot;JAVA_VERSION=11.0.12&quot;,</span><br><span class="line">                &quot;CATALINA_HOME=/usr/local/tomcat&quot;,</span><br><span class="line">                &quot;TOMCAT_NATIVE_LIBDIR=/usr/local/tomcat/native-jni-lib&quot;,</span><br><span class="line">                &quot;LD_LIBRARY_PATH=/usr/local/tomcat/native-jni-lib&quot;,</span><br><span class="line">                &quot;GPG_KEYS=48F8E69F6390C9F25CFEDCD268248959359E722B A9C5DF4D22E99998D9875A5110C01C5A2F6059E7 DCFD35E0BF8CA7344752DE8B6FB21E8933C60243&quot;,</span><br><span class="line">                &quot;TOMCAT_MAJOR=9&quot;,</span><br><span class="line">                &quot;TOMCAT_VERSION=9.0.52&quot;,</span><br><span class="line">                &quot;TOMCAT_SHA512=35e007e8e30e12889da27f9c71a6f4997b9cb5023b703d99add5de9271828e7d8d4956bf34dd2f48c7c71b4f8480f318c9067a4cd2a6d76eaae466286db4897b&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;#(nop) &quot;,</span><br><span class="line">                &quot;CMD [\&quot;catalina.sh\&quot; \&quot;run\&quot;]&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Image&quot;: &quot;sha256:5196276371ce4bad78ffcbb6032a04d381437b0719075d11ae1c24f496303f32&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;/usr/local/tomcat&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: null,</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;DockerVersion&quot;: &quot;20.10.7&quot;,</span><br><span class="line">        &quot;Author&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">                &quot;8080/tcp&quot;: &#123;&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [</span><br><span class="line">                &quot;PATH=/usr/local/tomcat/bin:/usr/local/openjdk-11/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">                &quot;JAVA_HOME=/usr/local/openjdk-11&quot;,</span><br><span class="line">                &quot;LANG=C.UTF-8&quot;,</span><br><span class="line">                &quot;JAVA_VERSION=11.0.12&quot;,</span><br><span class="line">                &quot;CATALINA_HOME=/usr/local/tomcat&quot;,</span><br><span class="line">                &quot;TOMCAT_NATIVE_LIBDIR=/usr/local/tomcat/native-jni-lib&quot;,</span><br><span class="line">                &quot;LD_LIBRARY_PATH=/usr/local/tomcat/native-jni-lib&quot;,</span><br><span class="line">                &quot;GPG_KEYS=48F8E69F6390C9F25CFEDCD268248959359E722B A9C5DF4D22E99998D9875A5110C01C5A2F6059E7 DCFD35E0BF8CA7344752DE8B6FB21E8933C60243&quot;,</span><br><span class="line">                &quot;TOMCAT_MAJOR=9&quot;,</span><br><span class="line">                &quot;TOMCAT_VERSION=9.0.52&quot;,</span><br><span class="line">                &quot;TOMCAT_SHA512=35e007e8e30e12889da27f9c71a6f4997b9cb5023b703d99add5de9271828e7d8d4956bf34dd2f48c7c71b4f8480f318c9067a4cd2a6d76eaae466286db4897b&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;catalina.sh&quot;,</span><br><span class="line">                &quot;run&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Image&quot;: &quot;sha256:5196276371ce4bad78ffcbb6032a04d381437b0719075d11ae1c24f496303f32&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;/usr/local/tomcat&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: null,</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: null</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">        &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">        &quot;Size&quot;: 667866261,</span><br><span class="line">        &quot;VirtualSize&quot;: 667866261,</span><br><span class="line">        &quot;GraphDriver&quot;: &#123;</span><br><span class="line">            &quot;Data&quot;: &#123;</span><br><span class="line">                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/14d6effb2d8347a8f2140b8eb6bb914ffe5209cc9ed880c55657cb8e6c30f0b4/diff:/var/lib/docker/overlay2/304d8484e5dd5fd4386fd5fefcd8e32ef38743801a7bf3ba513fb3ff8f38ad89/diff:/var/lib/docker/overlay2/bd7bfc9ebc87f6f5c11e110877e54b7e2180aac478637a207b105b4b319e925e/diff:/var/lib/docker/overlay2/00ca651a87602d2e11175f932c6f32fd7b43ae98159416ad908fa050b47b3fed/diff:/var/lib/docker/overlay2/aa5cce0f487b2a05c13bb8929a2411314690d2b4d305cd3e1bc171cb1b173089/diff:/var/lib/docker/overlay2/3815d6dbfabe611f9dc4ffac4690fb4c72870794c7ea9d2e930487d0eaa6d5f4/diff:/var/lib/docker/overlay2/f14c65162848b2a6061d043343db3ccff14c64bf99d6fe3bb947331fc7882778/diff:/var/lib/docker/overlay2/7acfe353937d2289e2cbf8b63e938e579b5a5d952cefe0973125b38555c04416/diff:/var/lib/docker/overlay2/67693c8b74406bd5c6603fe38ce5e5ac9380eca61504103ae70e35c5703d8d57/diff&quot;,</span><br><span class="line">                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/517208d37dec0c6abf702063df2aec59802520e1e5ef5b6bcefce7a6f3a379aa/merged&quot;,</span><br><span class="line">                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/517208d37dec0c6abf702063df2aec59802520e1e5ef5b6bcefce7a6f3a379aa/diff&quot;,</span><br><span class="line">                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/517208d37dec0c6abf702063df2aec59802520e1e5ef5b6bcefce7a6f3a379aa/work&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Name&quot;: &quot;overlay2&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;RootFS&quot;: &#123;</span><br><span class="line">            &quot;Type&quot;: &quot;layers&quot;,</span><br><span class="line">            &quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:c2ddc1bc2645ab5d982c60434d8bbc6aecee1bd4e8eee0df7fd08c96df2d58bb&quot;,</span><br><span class="line">                &quot;sha256:62d14713f2e98841ec3927e3ab611b13e414a21fb82fc0e604a9008ac53e45dc&quot;,</span><br><span class="line">                &quot;sha256:1235daf38153d083ae5b4f605acc54f9401143b5fbd033801ba373a8cfb04845&quot;,</span><br><span class="line">                &quot;sha256:7d890913ab6955350bdd25d04c60dd444db13890c401cbcdc8e00e9bd29c90fc&quot;,</span><br><span class="line">                &quot;sha256:c2e2307780ac2fa0d39cec874c4545156da890c1bcc42b3259114ac29bb598f1&quot;,</span><br><span class="line">                &quot;sha256:75f6a0e6e441cd3d74125443fc73eb26bf9ceb557b269b25bddaa2ef459227f7&quot;,</span><br><span class="line">                &quot;sha256:b19f17003e5ae07f7aba99f95736627aaa1ff3c92832f7d6920158dc6b138bcf&quot;,</span><br><span class="line">                &quot;sha256:2dad09b8a57e12408adc0366cbd2a642eaab1c82bbfb2b442245928b60d337f1&quot;,</span><br><span class="line">                &quot;sha256:83a14c3e974e700768197a3061f840618a924d3154fcb338a85b6da5fd4eb886&quot;,</span><br><span class="line">                &quot;sha256:19f8bd134bcf7c5870f8294b1d3bba4c970d0b622772865e44d200d248ed2676&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Metadata&quot;: &#123;</span><br><span class="line">            &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>理解：</p>
</blockquote>
<p>所有的 Docker镜像都起始于一个基础镜像层，当进行修改或培加新的内容时，就会在当前镜像层之上，创建新的镜像层。举一个简单的例子，假如基于 Ubuntu Linux16.04创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创健第三个镜像层该像当前已经包含3个镜像层，如下图所示,在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/10a1a3a8998077f4e4f6c3497c6c513e.png"></p>
<p>在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含3个文件，而镜像包含了来自两个镜像层的6个文件。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7d14f1ac3365d88d607298f5167d0ac3.png"></p>
<p>上图中的镜像层跟之前图中的略有区別，主要目的是便于展示文件<br>下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有6个文件，这是因为最上层中的文件7是文件5的一个更新版。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7ce12a7eee33d7c7ca8080acabc20302.png"></p>
<p>文种情況下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中</p>
<p>Docker通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统</p>
<p>Linux上可用的存储引撃有AUFS、 Overlay2、 Device Mapper、Btrfs以及ZFS。顾名思义，每种存储引擎都基于 Linux中对应的件系统或者块设备技术，井且每种存储引擎都有其独有的性能特点。</p>
<p>Docker在 Windows上仅支持 windowsfilter 一种存储引擎，该引擎基于NTFS文件系统之上实现了分层和CoW [1]。</p>
<p>下图展示了与系统显示相同的三层镜像。所有镜像层堆并合井，对外提供统一的视图。<br><img src="https://img-blog.csdnimg.cn/img_convert/10a1332519d3223be103297272a0978f.png"></p>
<blockquote>
<p>特点</p>
</blockquote>
<p>Docker 镜像都是只读的，当容器启动时，一个新的可写层加载到镜像的顶部！</p>
<p>这一层就是我们通常说的容器层，容器之下的都叫镜像层！</p>
<h2 id="第八讲-docker容器数据卷"><a href="#第八讲-docker容器数据卷" class="headerlink" title="第八讲 docker容器数据卷"></a>第八讲 docker容器数据卷</h2><h3 id="8-1-容器数据卷是什么"><a href="#8-1-容器数据卷是什么" class="headerlink" title="8.1 容器数据卷是什么"></a>8.1 容器数据卷是什么</h3><p>当我们在使用docker容器的时候，会产生一系列的数据文件，这些数据文件在我们关闭docker容器时是会消失的，但是其中产生的部分内容我们是希望能够把它给保存起来另作用途的，Docker将应用与运行环境打包成容器发布，我们希望在运行过程钟产生的部分数据是可以持久化的的，而且容器之间我们希望能够实现数据共享。容器数据卷可以帮助我们实现这个需求。docker容器数据卷可以看成使我们生活中常用的u盘，它存在于一个或多个的容器中，由docker挂载到容器，但不属于联合文件系统，Docker不会在容器删除时删除其挂载的数据卷。</p>
<blockquote>
<p>特点：</p>
</blockquote>
<p>1：数据卷可以在容器之间共享或重用数据</p>
<p>2：数据卷中的更改可以直接生效</p>
<p>3：数据卷中的更改不会包含在镜像的更新中</p>
<p>4：数据卷的生命周期一直持续到没有容器使用它为止</p>
<h3 id="8-2-如何添加容器数据卷"><a href="#8-2-如何添加容器数据卷" class="headerlink" title="8.2 如何添加容器数据卷"></a>8.2 如何添加容器数据卷</h3><h4 id="8-2-1-通过命令挂载"><a href="#8-2-1-通过命令挂载" class="headerlink" title="8.2.1 通过命令挂载"></a>8.2.1 通过命令挂载</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1 通过docker run -v 挂载 </span><br><span class="line">[root@VM-4-6-centos lighthouse]# docker run -it -v /home/test:/home centos </span><br><span class="line">[root@672f22246a83 /]# [root@VM-4-6-centos lighthouse]# </span><br><span class="line">[root@VM-4-6-centos lighthouse]# docker ps </span><br><span class="line">CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES</span><br><span class="line">672f22246a83   centos    &quot;/bin/bash&quot;   22 seconds ago   Up 22 seconds             # 2 通过</span><br><span class="line"># 2 docker inspect containerID 查看挂载是否成功</span><br><span class="line">[root@VM-4-6-centos lighthouse]# docker inspect 672f22246a83</span><br><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/home/test&quot;,  </span><br><span class="line">                &quot;Destination&quot;: &quot;/home&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line"># 3手动查看挂载是否成功，能否同步文件</span><br><span class="line">[root@VM-4-6-centos lighthouse]# cd /home/test </span><br><span class="line"># 新建测试文件mounttest.tet</span><br><span class="line">[root@VM-4-6-centos test]# touch mounttest.tet </span><br><span class="line">[root@VM-4-6-centos test]# ls</span><br><span class="line">mounttest.tet</span><br><span class="line">[root@VM-4-6-centos test]# docker exec -it 672f22246a83 /bin/bash </span><br><span class="line">[root@672f22246a83 /]# cd /home </span><br><span class="line"># 查看容器对应文件是否同步</span><br><span class="line">[root@672f22246a83 home]# ls</span><br><span class="line">mounttest.tet</span><br><span class="line"># 生成反向同步测试文件</span><br><span class="line">[root@672f22246a83 home]# touch mounttest111.tet </span><br><span class="line">[root@672f22246a83 home]# read escape sequence</span><br><span class="line">[root@VM-4-6-centos test]# ls </span><br><span class="line">mounttest111.tet  mounttest.tet</span><br><span class="line"># 双向同步 </span><br></pre></td></tr></table></figure>

<blockquote>
<p>案例： 部署mysql容器数据卷</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 启动mysql容器并挂载文件</span><br><span class="line">[root@VM-4-6-centos ~]# docker images </span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">tomcat                latest    266d1269bb29   2 weeks ago    668MB</span><br><span class="line">nginx                 latest    dd34e67e3371   2 weeks ago    133MB</span><br><span class="line">mysql                 latest    5a4e492065c7   2 weeks ago    514MB</span><br><span class="line">centos                latest    300e315adb2f   8 months ago   209MB</span><br><span class="line"></span><br><span class="line">[root@VM-4-6-centos ~]# docker run -d -p 1433:3306 -v /home/mysql/conf:/etc/mysql/conf.d </span><br><span class="line">-v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql001 mysql:latest</span><br><span class="line">8988e75401bcbbc73d018ae14c8fce9f53ae3e9e4f15058436f839039dd9cdcf</span><br><span class="line"></span><br><span class="line">[root@VM-4-6-centos ~]# docker ps </span><br><span class="line">CONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS                                              NAMES</span><br><span class="line">8988e75401bc   mysql:latest   &quot;docker-entrypoint.s…&quot;   12 seconds ago   Up 11 seconds   33060/tcp, 0.0.0.0:80-&gt;3306/tcp, :::80-&gt;3306/tcp   mysql001</span><br><span class="line">672f22246a83   centos         &quot;/bin/bash&quot;              6 hours ago      Up 6 hours                                                         interesting_tu</span><br><span class="line"></span><br><span class="line">[root@VM-4-6-centos ~]# docker inspect mysql001</span><br><span class="line"></span><br><span class="line">        &quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/home/mysql/data&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;/var/lib/mysql&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/home/mysql/conf&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;/etc/mysql/conf.d&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>具名挂载和匿名挂载 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 匿名挂载</span><br><span class="line">-v 容器内路径!</span><br><span class="line">$ docker run -d -P --name nginx01 -v /etc/nginx nginx</span><br><span class="line"></span><br><span class="line"># 查看所有的volume(卷)的情况</span><br><span class="line">$ docker volume ls    </span><br><span class="line">DRIVER              VOLUME NAME # 容器内的卷名(匿名卷挂载)</span><br><span class="line">local               21159a8518abd468728cdbe8594a75b204a10c26be6c36090cde1ee88965f0d0</span><br><span class="line">local               b17f52d38f528893dd5720899f555caf22b31bf50b0680e7c6d5431dbda2802c</span><br><span class="line">         </span><br><span class="line"># 这里发现，这种就是匿名挂载，我们在 -v只写了容器内的路径，没有写容器外的路径！</span><br><span class="line"></span><br><span class="line"># 具名挂载 -P:表示随机映射端口</span><br><span class="line">$ docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx</span><br><span class="line">9663cfcb1e5a9a1548867481bfddab9fd7824a6dc4c778bf438a040fe891f0ee</span><br><span class="line"></span><br><span class="line"># 查看所有的volume(卷)的情况</span><br><span class="line">$ docker volume ls                  </span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               21159a8518abd468728cdbe8594a75b204a10c26be6c36090cde1ee88965f0d0</span><br><span class="line">local               b17f52d38f528893dd5720899f555caf22b31bf50b0680e7c6d5431dbda2802c</span><br><span class="line">local               juming-nginx #多了一个名字</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 通过 -v 卷名：查看容器内路径</span><br><span class="line"># 查看一下这个卷</span><br><span class="line">$ docker volume inspect juming-nginx</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;CreatedAt&quot;: &quot;2020-05-23T13:55:34+08:00&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Labels&quot;: null,</span><br><span class="line">        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/juming-nginx/_data&quot;, #默认目录</span><br><span class="line">        &quot;Name&quot;: &quot;juming-nginx&quot;,</span><br><span class="line">        &quot;Options&quot;: null,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>所有的docker容器内的卷，没有指定目录的情况下都是在**/var/lib/docker/volumes/自定义的卷名/_data**下，<br><strong>如果指定了目录，docker volume ls 是查看不到的</strong>。</p>
<p><strong>区分三种挂载方式</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 三种挂载： 匿名挂载、具名挂载、指定路径挂载</span><br><span class="line">-v 容器内路径			#匿名挂载</span><br><span class="line">-v 卷名：容器内路径		  #具名挂载</span><br><span class="line">-v /宿主机路径：容器内路径 #指定路径挂载 docker volume ls 是查看不到的</span><br></pre></td></tr></table></figure>

<p>拓展：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 通过 -v 容器内路径： ro rw 改变读写权限</span><br><span class="line">ro #readonly 只读</span><br><span class="line">rw #readwrite 可读可写</span><br><span class="line">$ docker run -d -P --name nginx05 -v juming:/etc/nginx:ro nginx</span><br><span class="line">$ docker run -d -P --name nginx05 -v juming:/etc/nginx:rw nginx</span><br><span class="line"># ro 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作！</span><br></pre></td></tr></table></figure>

<h3 id="8-3-通过dockerfile挂载"><a href="#8-3-通过dockerfile挂载" class="headerlink" title="8.3 通过dockerfile挂载"></a>8.3 通过dockerfile挂载</h3><p>dockerfile就是是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建一个dockerfile文件，名字可以随便建议Dockerfile</span><br><span class="line"># 文件中的内容： 指令(大写) + 参数</span><br><span class="line">$ vim dockerfile1</span><br><span class="line">    FROM centos 					# 当前这个镜像是以centos为基础的</span><br><span class="line"></span><br><span class="line">    VOLUME [&quot;volume01&quot;,&quot;volume02&quot;] 	# 挂载卷的卷目录列表(多个目录)</span><br><span class="line"></span><br><span class="line">    CMD echo &quot;-----end-----&quot;		# 输出一下用于测试</span><br><span class="line">    CMD /bin/bash					# 默认走bash控制台</span><br><span class="line"></span><br><span class="line"># 这里的每个命令，就是镜像的一层！</span><br><span class="line"># 构建出这个镜像 </span><br><span class="line">-f dockerfile1 			# f代表file，指这个当前文件的地址(这里是当前目录下的dockerfile1)</span><br><span class="line">-t caoshipeng/centos 	# t就代表target，指目标目录(注意caoshipeng镜像名前不能加斜杠‘/’)</span><br><span class="line">. 						# 表示生成在当前目录下</span><br><span class="line">$ docker build -f dockerfile1 -t caoshipeng/centos .</span><br><span class="line">Sending build context to Docker daemon   2.56kB</span><br><span class="line">Step 1/4 : FROM centos</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">8a29a15cefae: Already exists </span><br><span class="line">Digest: sha256:fe8d824220415eed5477b63addf40fb06c3b049404242b31982106ac204f6700</span><br><span class="line">Status: Downloaded newer image for centos:latest</span><br><span class="line"> ---&gt; 470671670cac</span><br><span class="line">Step 2/4 : VOLUME [&quot;volume01&quot;,&quot;volume02&quot;] 			# 卷名列表</span><br><span class="line"> ---&gt; Running in c18eefc2c233</span><br><span class="line">Removing intermediate container c18eefc2c233</span><br><span class="line"> ---&gt; 623ae1d40fb8</span><br><span class="line">Step 3/4 : CMD echo &quot;-----end-----&quot;					# 输出 脚本命令</span><br><span class="line"> ---&gt; Running in 70e403669f3c</span><br><span class="line">Removing intermediate container 70e403669f3c</span><br><span class="line"> ---&gt; 0eba1989c4e6</span><br><span class="line">Step 4/4 : CMD /bin/bash</span><br><span class="line"> ---&gt; Running in 4342feb3a05b</span><br><span class="line">Removing intermediate container 4342feb3a05b</span><br><span class="line"> ---&gt; f4a6b0d4d948</span><br><span class="line">Successfully built f4a6b0d4d948</span><br><span class="line">Successfully tagged caoshipeng/centos:latest</span><br><span class="line"></span><br><span class="line"># 查看自己构建的镜像</span><br><span class="line">$ docker images</span><br><span class="line">REPOSITORY          TAG          IMAGE ID            CREATED              SIZE</span><br><span class="line">caoshipeng/centos   latest       f4a6b0d4d948        About a minute ago   237MB</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>启动新建的镜像 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos lib]#docker run -it new/centos /bin/bash</span><br><span class="line">#</span><br><span class="line">[root@VM-4-6-centos lib]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE        COMMAND                  CREATED         STATUS         PORTS                 NAMES</span><br><span class="line">d0da4c77e1a9   new/centos   &quot;/bin/bash&quot;              5 minutes ago   Up 5 minutes                         priceless_hawking</span><br><span class="line"></span><br><span class="line"># 查看挂载</span><br><span class="line">[root@VM-4-6-centos lib]# docker inspect d0da4c77e1a9</span><br><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;volume&quot;,</span><br><span class="line">                &quot;Name&quot;: &quot;575269012a409d421b59c45cc5591a7ac7b44d4fa5cbf80a196817c589ea3848&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/var/lib/docker/volumes/575269012a409d421b59c45cc5591a7ac7b44d4fa5cbf80a196817c589ea3848/_data&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;colume2&quot;,#  挂载成功</span><br><span class="line">                &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;volume&quot;,</span><br><span class="line">                &quot;Name&quot;: &quot;099c9f4fe900e5550ca4ad2aff381b09e969c158ca62591b1817d9a8b26d1967&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/var/lib/docker/volumes/099c9f4fe900e5550ca4ad2aff381b09e969c158ca62591b1817d9a8b26d1967/_data&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;volume1&quot;,</span><br><span class="line">                &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>

<h4 id="8-4-数据卷容器"><a href="#8-4-数据卷容器" class="headerlink" title="8.4 数据卷容器"></a>8.4 数据卷容器</h4><p>多个容器数据之间实现数据共享 。 实例： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos /]# docker images</span><br><span class="line">hello-world           latest    d1165f221234   6 months ago     13.3kB</span><br><span class="line">centos                latest    300e315adb2f   9 months ago     209MB</span><br><span class="line"></span><br><span class="line"># 容器1 </span><br><span class="line">[root@VM-4-6-centos /]# docker run -it --name centos01 new/centos </span><br><span class="line">[root@fff6b286c371 /]# ls</span><br><span class="line">bin  colume2  dev  etc	home  lib  lib64  lost+found  media  mnt  opt  proc  root  run	sbin  srv  sys	tmp  usr  var  volume1</span><br><span class="line">[root@fff6b286c371 /]# cd volume1/</span><br><span class="line"></span><br><span class="line"># 容器1 挂载目录下 新建测试文件</span><br><span class="line">[root@fff6b286c371 volume1]# touch test.txt </span><br><span class="line">[root@fff6b286c371 volume1]# ls</span><br><span class="line">test.txt</span><br><span class="line">[root@fff6b286c371 volume1]# [root@VM-4-6-centos /]# </span><br><span class="line"></span><br><span class="line"># 容器2继承容器1 </span><br><span class="line">[root@VM-4-6-centos /]# docker run -it --name centos02 --volumes-from  centos01 new/centos</span><br><span class="line">[root@41f919150a90 /]# ls</span><br><span class="line">bin  colume2  dev  etc	home  lib  lib64  lost+found  media  mnt  opt  proc  root  run	sbin  srv  sys	tmp  usr  var  volume1</span><br><span class="line">[root@41f919150a90 /]# cd volume1</span><br><span class="line">[root@41f919150a90 volume1]# ls</span><br><span class="line">test.txt</span><br><span class="line"># 容器2 与容器1 实现数据共享</span><br><span class="line">[root@41f919150a90 volume1]# [root@VM-4-6-centos /]# </span><br><span class="line"></span><br><span class="line"># 查看挂载宿主机地址 </span><br><span class="line">[root@VM-4-6-centos /]# docker inspect centos01 </span><br><span class="line">        &quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;volume&quot;,</span><br><span class="line">                &quot;Name&quot;: &quot;b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/var/lib/docker/volumes/b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b/_data&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;volume1&quot;,</span><br><span class="line">                &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">[root@VM-4-6-centos /]# docker inspect centos01 </span><br><span class="line">        &quot;Mounts&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;Type&quot;: &quot;volume&quot;,</span><br><span class="line">                &quot;Name&quot;: &quot;b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b&quot;,</span><br><span class="line">                &quot;Source&quot;: &quot;/var/lib/docker/volumes/b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b/_data&quot;,</span><br><span class="line">                &quot;Destination&quot;: &quot;volume1&quot;,</span><br><span class="line">                &quot;Driver&quot;: &quot;local&quot;,</span><br><span class="line">                &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">                &quot;RW&quot;: true,</span><br><span class="line">                &quot;Propagation&quot;: &quot;&quot;</span><br><span class="line">            &#125;,</span><br><span class="line"># 发现两个容器挂载在宿主机的同一位置 </span><br><span class="line"># 即使所有挂载的容器被删除， 宿主机的文件不受影响 </span><br><span class="line">[root@VM-4-6-centos /]# docker rm  centos02</span><br><span class="line">centos02</span><br><span class="line">[root@VM-4-6-centos /]# docker rm  centos01</span><br><span class="line">centos01</span><br><span class="line">[root@VM-4-6-centos home]# cd /var/lib/docker/volumes/</span><br><span class="line">[root@VM-4-6-centos volumes]# cd b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b/</span><br><span class="line">[root@VM-4-6-centos b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b]# ls</span><br><span class="line">_data</span><br><span class="line">[root@VM-4-6-centos b83567b3f8e3818762cd87e5dc7c48a98846929f4c035d5eadc3c89ea364746b]# cd _data</span><br><span class="line">[root@VM-4-6-centos _data]# ls</span><br><span class="line">test.txt</span><br><span class="line"># 测试表明， 即使删除所有容器，宿主机上的文件也会持久化储存。</span><br></pre></td></tr></table></figure>

<h2 id="第九讲-dockerfile-开发"><a href="#第九讲-dockerfile-开发" class="headerlink" title="第九讲 dockerfile 开发"></a>第九讲 dockerfile 开发</h2><h3 id="9-1-什么是dockerfile"><a href="#9-1-什么是dockerfile" class="headerlink" title="9.1 什么是dockerfile"></a>9.1 什么是dockerfile</h3><p>Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。</p>
<h3 id="9-2-dockerfile构建镜像的流程"><a href="#9-2-dockerfile构建镜像的流程" class="headerlink" title="9.2 dockerfile构建镜像的流程"></a>9.2 dockerfile构建镜像的流程</h3><ol>
<li> 编写一个dockerfile文本</li>
<li> docker bulild构建一个镜像</li>
<li> docker run 运行镜像 </li>
<li> docker push 发布镜像(dockerhub， 阿里云镜像仓库)</li>
</ol>
<h3 id="9-3-dockerfile-命令"><a href="#9-3-dockerfile-命令" class="headerlink" title="9.3 dockerfile 命令"></a>9.3 dockerfile 命令</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/9b638ef392015ca96221200f883b96c4.png"></p>
<h4 id="9-4-实例测试——新建一个带vim和net-tools的centos镜像"><a href="#9-4-实例测试——新建一个带vim和net-tools的centos镜像" class="headerlink" title="9.4 实例测试——新建一个带vim和net-tools的centos镜像"></a>9.4 实例测试——新建一个带vim和net-tools的centos镜像</h4><ol>
<li><p>编写dockerfle </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos mydocker]# vim dockerfile1 </span><br><span class="line">FROM centos </span><br><span class="line">MAINTAINER ywl&lt;yuan.wanli@qq.com&gt;</span><br><span class="line">ENV MYPATH /usr/local </span><br><span class="line">WORKDIR $MYPATH </span><br><span class="line">RUN yum -y install vim </span><br><span class="line">RUN yum -y install net-tools </span><br><span class="line">EXPOSE 80 </span><br><span class="line">CMD ehco $MYPATH</span><br><span class="line">CMD /bin/bash </span><br></pre></td></tr></table></figure></li>
<li><p>构建镜像 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos mydocker]# docker build --help </span><br><span class="line"></span><br><span class="line">Usage:  docker build [OPTIONS] PATH | URL | -</span><br><span class="line"></span><br><span class="line">Build an image from a Dockerfile</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">      --add-host list           Add a custom host-to-IP mapping (host:ip)</span><br><span class="line">      --build-arg list          Set build-time variables</span><br><span class="line">      --cache-from strings      Images to consider as cache sources</span><br><span class="line">      --cgroup-parent string    Optional parent cgroup for the container</span><br><span class="line">      --compress                Compress the build context using gzip</span><br><span class="line">      --cpu-period int          Limit the CPU CFS (Completely Fair Scheduler) period</span><br><span class="line">      --cpu-quota int           Limit the CPU CFS (Completely Fair Scheduler) quota</span><br><span class="line">  -c, --cpu-shares int          CPU shares (relative weight)</span><br><span class="line">      --cpuset-cpus string      CPUs in which to allow execution (0-3, 0,1)</span><br><span class="line">      --cpuset-mems string      MEMs in which to allow execution (0-3, 0,1)</span><br><span class="line">      --disable-content-trust   Skip image verification (default true)</span><br><span class="line">  -f, --file string             Name of the Dockerfile (Default is &#x27;PATH/Dockerfile&#x27;)</span><br><span class="line">      --force-rm                Always remove intermediate containers</span><br><span class="line">      --iidfile string          Write the image ID to the file</span><br><span class="line">      --isolation string        Container isolation technology</span><br><span class="line">      --label list              Set metadata for an image</span><br><span class="line">  -m, --memory bytes            Memory limit</span><br><span class="line">      --memory-swap bytes       Swap limit equal to memory plus swap: &#x27;-1&#x27; to enable unlimited swap</span><br><span class="line">      --network string          Set the networking mode for the RUN instructions during build (default &quot;default&quot;)</span><br><span class="line">      --no-cache                Do not use cache when building the image</span><br><span class="line">      --pull                    Always attempt to pull a newer version of the image</span><br><span class="line">  -q, --quiet                   Suppress the build output and print image ID on success</span><br><span class="line">      --rm                      Remove intermediate containers after a successful build (default true)</span><br><span class="line">      --security-opt strings    Security options</span><br><span class="line">      --shm-size bytes          Size of /dev/shm</span><br><span class="line">  -t, --tag list                Name and optionally a tag in the &#x27;name:tag&#x27; format</span><br><span class="line">      --target string           Set the target build stage to build.</span><br><span class="line">      --ulimit ulimit           Ulimit options (default [])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@VM-4-6-centos mydocker]# docker build -f dockerfile1 -t mycentos:1.0 .</span><br><span class="line">Sending build context to Docker daemon  2.048kB</span><br><span class="line">Step 1/9 : FROM centos</span><br><span class="line"> ---&gt; 300e315adb2f</span><br><span class="line">Step 2/9 : MAINTAINER ywl&lt;yuan.wanli@qq.com&gt;</span><br><span class="line"> ---&gt; Running in 2f009ebbce45</span><br><span class="line">Removing intermediate container 2f009ebbce45</span><br><span class="line"> ---&gt; 3e039c5d5963</span><br><span class="line">Step 3/9 : ENV MYPATH /usr/local</span><br><span class="line"> ---&gt; Running in 902ec92baf9a</span><br><span class="line">Removing intermediate container 902ec92baf9a</span><br><span class="line"> ---&gt; 0d77fd7a4baf</span><br><span class="line">Step 4/9 : WORKDIR $MYPATH</span><br><span class="line"> ---&gt; Running in 9d8012ef4523</span><br><span class="line">Removing intermediate container 9d8012ef4523</span><br><span class="line"> ---&gt; 7f363b93ec76</span><br><span class="line">Step 5/9 : RUN yum -y install vim</span><br><span class="line"> ---&gt; Running in 9e54c5f8edfe</span><br><span class="line">CentOS Linux 8 - AppStream                      6.7 MB/s | 8.8 MB     00:01    </span><br><span class="line">CentOS Linux 8 - BaseOS                         4.6 MB/s | 5.6 MB     00:01    </span><br><span class="line">CentOS Linux 8 - Extras                          21 kB/s |  10 kB     00:00    </span><br><span class="line">Dependencies resolved.</span><br><span class="line">================================================================================</span><br><span class="line"> Package             Arch        Version                   Repository      Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> vim-enhanced        x86_64      2:8.0.1763-15.el8         appstream      1.4 M</span><br><span class="line">Installing dependencies:</span><br><span class="line"> gpm-libs            x86_64      1.20.7-17.el8             appstream       39 k</span><br><span class="line"> vim-common          x86_64      2:8.0.1763-15.el8         appstream      6.3 M</span><br><span class="line"> vim-filesystem      noarch      2:8.0.1763-15.el8         appstream       48 k</span><br><span class="line"> which               x86_64      2.21-12.el8               baseos          49 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  5 Packages</span><br><span class="line"></span><br><span class="line">Total download size: 7.8 M</span><br><span class="line">Installed size: 30 M</span><br><span class="line">Downloading Packages:</span><br><span class="line">(1/5): gpm-libs-1.20.7-17.el8.x86_64.rpm        425 kB/s |  39 kB     00:00    </span><br><span class="line">(2/5): vim-filesystem-8.0.1763-15.el8.noarch.rp 1.6 MB/s |  48 kB     00:00    </span><br><span class="line">(3/5): vim-enhanced-8.0.1763-15.el8.x86_64.rpm  4.6 MB/s | 1.4 MB     00:00    </span><br><span class="line">(4/5): which-2.21-12.el8.x86_64.rpm             280 kB/s |  49 kB     00:00    </span><br><span class="line">(5/5): vim-common-8.0.1763-15.el8.x86_64.rpm    9.4 MB/s | 6.3 MB     00:00    </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">Total                                           5.2 MB/s | 7.8 MB     00:01     </span><br><span class="line">warning: /var/cache/dnf/appstream-02e86d1c976ab532/packages/gpm-libs-1.20.7-17.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: NOKEY</span><br><span class="line">CentOS Linux 8 - AppStream                      1.6 MB/s | 1.6 kB     00:00    </span><br><span class="line">Importing GPG key 0x8483C65D:</span><br><span class="line"> Userid     : &quot;CentOS (CentOS Official Signing Key) &lt;security@centos.org&gt;&quot;</span><br><span class="line"> Fingerprint: 99DB 70FA E1D7 CE22 7FB6 4882 05B5 55B3 8483 C65D</span><br><span class="line"> From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial</span><br><span class="line">Key imported successfully</span><br><span class="line">Running transaction check</span><br><span class="line">Transaction check succeeded.</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded.</span><br><span class="line">Running transaction</span><br><span class="line">  Preparing        :                                                        1/1 </span><br><span class="line">  Installing       : which-2.21-12.el8.x86_64                               1/5 </span><br><span class="line">  Installing       : vim-filesystem-2:8.0.1763-15.el8.noarch                2/5 </span><br><span class="line">  Installing       : vim-common-2:8.0.1763-15.el8.x86_64                    3/5 </span><br><span class="line">  Installing       : gpm-libs-1.20.7-17.el8.x86_64                          4/5 </span><br><span class="line">  Running scriptlet: gpm-libs-1.20.7-17.el8.x86_64                          4/5 </span><br><span class="line">  Installing       : vim-enhanced-2:8.0.1763-15.el8.x86_64                  5/5 </span><br><span class="line">  Running scriptlet: vim-enhanced-2:8.0.1763-15.el8.x86_64                  5/5 </span><br><span class="line">  Running scriptlet: vim-common-2:8.0.1763-15.el8.x86_64                    5/5 </span><br><span class="line">  Verifying        : gpm-libs-1.20.7-17.el8.x86_64                          1/5 </span><br><span class="line">  Verifying        : vim-common-2:8.0.1763-15.el8.x86_64                    2/5 </span><br><span class="line">  Verifying        : vim-enhanced-2:8.0.1763-15.el8.x86_64                  3/5 </span><br><span class="line">  Verifying        : vim-filesystem-2:8.0.1763-15.el8.noarch                4/5 </span><br><span class="line">  Verifying        : which-2.21-12.el8.x86_64                               5/5 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  gpm-libs-1.20.7-17.el8.x86_64         vim-common-2:8.0.1763-15.el8.x86_64    </span><br><span class="line">  vim-enhanced-2:8.0.1763-15.el8.x86_64 vim-filesystem-2:8.0.1763-15.el8.noarch</span><br><span class="line">  which-2.21-12.el8.x86_64             </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line">Removing intermediate container 9e54c5f8edfe</span><br><span class="line"> ---&gt; 5dea379858f6</span><br><span class="line">Step 6/9 : RUN yum -y install net-tools</span><br><span class="line"> ---&gt; Running in a238f0f61bd1</span><br><span class="line">Last metadata expiration check: 0:00:11 ago on Wed Sep  8 05:20:26 2021.</span><br><span class="line">Dependencies resolved.</span><br><span class="line">================================================================================</span><br><span class="line"> Package         Architecture Version                        Repository    Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> net-tools       x86_64       2.0-0.52.20160912git.el8       baseos       322 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 322 k</span><br><span class="line">Installed size: 942 k</span><br><span class="line">Downloading Packages:</span><br><span class="line">net-tools-2.0-0.52.20160912git.el8.x86_64.rpm   1.1 MB/s | 322 kB     00:00    </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">Total                                           547 kB/s | 322 kB     00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Transaction check succeeded.</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded.</span><br><span class="line">Running transaction</span><br><span class="line">  Preparing        :                                                        1/1 </span><br><span class="line">  Installing       : net-tools-2.0-0.52.20160912git.el8.x86_64              1/1 </span><br><span class="line">  Running scriptlet: net-tools-2.0-0.52.20160912git.el8.x86_64              1/1 </span><br><span class="line">  Verifying        : net-tools-2.0-0.52.20160912git.el8.x86_64              1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  net-tools-2.0-0.52.20160912git.el8.x86_64                                     </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line">Removing intermediate container a238f0f61bd1</span><br><span class="line"> ---&gt; fe15f2802369</span><br><span class="line">Step 7/9 : EXPOSE 80</span><br><span class="line"> ---&gt; Running in dd05e3d35f52</span><br><span class="line">Removing intermediate container dd05e3d35f52</span><br><span class="line"> ---&gt; 8b2ed813e0cc</span><br><span class="line">Step 8/9 : CMD ehco $MYPATH</span><br><span class="line"> ---&gt; Running in 3abafde69c99</span><br><span class="line">Removing intermediate container 3abafde69c99</span><br><span class="line"> ---&gt; 7a93ce354052</span><br><span class="line">Step 9/9 : CMD /bin/bash</span><br><span class="line"> ---&gt; Running in 0737c0226cf2</span><br><span class="line">Removing intermediate container 0737c0226cf2</span><br><span class="line"> ---&gt; b531a51cbc3e</span><br><span class="line">Successfully built b531a51cbc3e</span><br><span class="line">Successfully tagged mycentos:1.0</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>测试 </p>
<p>查看镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos mydocker]# docker images </span><br><span class="line">REPOSITORY            TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">mycentos              1.0       b531a51cbc3e   4 minutes ago   307MB</span><br><span class="line">centos                latest    300e315adb2f   9 months ago    209MB</span><br></pre></td></tr></table></figure>

<p>运行一个容器 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos mydocker]# docker run -it b531a51cbc3e</span><br><span class="line">[root@915fe46d200b local]# ls</span><br><span class="line">bin  etc  games  include  lib  lib64  libexec  sbin  share  src</span><br><span class="line">[root@915fe46d200b local]# pwd </span><br><span class="line">/usr/local</span><br><span class="line">[root@915fe46d200b local]# vim test.txt</span><br></pre></td></tr></table></figure></li>
<li><p>查看镜像构建历史 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos mydocker]# docker history --human b531a51cbc3e</span><br><span class="line">IMAGE          CREATED          CREATED BY                                      SIZE      COMMENT</span><br><span class="line">b531a51cbc3e   14 minutes ago   /bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;/bin…   0B     </span><br><span class="line">7a93ce354052   14 minutes ago   /bin/sh -c #(nop)  CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;ehco…   0B     </span><br><span class="line">8b2ed813e0cc   14 minutes ago   /bin/sh -c #(nop)  EXPOSE 80                    0B     </span><br><span class="line">fe15f2802369   14 minutes ago   /bin/sh -c yum -y install net-tools             29.5M </span><br><span class="line">5dea379858f6   14 minutes ago   /bin/sh -c yum -y install vim                   68.1MB </span><br><span class="line">7f363b93ec76   14 minutes ago   /bin/sh -c #(nop) WORKDIR /usr/local            0B     </span><br><span class="line">0d77fd7a4baf   14 minutes ago   /bin/sh -c #(nop)  ENV MYPATH=/usr/local        0B     </span><br><span class="line">3e039c5d5963   14 minutes ago   /bin/sh -c #(nop)  MAINTAINER ywl&lt;yuan.wanli…   0B     </span><br><span class="line">300e315adb2f   9 months ago     /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0B     </span><br><span class="line">&lt;missing&gt;      9 months ago     /bin/sh -c #(nop)  LABEL org.label-schema.sc…   0B     </span><br><span class="line">&lt;missing&gt;      9 months ago     /bin/sh -c #(nop) ADD file:bd7a2aed6ede423b7…   209MB </span><br></pre></td></tr></table></figure></li>
</ol>
<p>9.5 CMD 于 ENTRYPOINT区别 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMD				# 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代。</span><br><span class="line">ENTRYPOINT	   # 指定这个容器启动的时候要运行的命令，可以追加命令*</span><br></pre></td></tr></table></figure>

<p>测试CMD </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 编写dockerfile文件</span><br><span class="line">$ vim dockerfile-test-cmd</span><br><span class="line">FROM centos</span><br><span class="line">CMD [&quot;ls&quot;,&quot;-a&quot;]					# 启动后执行 ls -a 命令</span><br><span class="line"></span><br><span class="line"># 构建镜像</span><br><span class="line">$ docker build  -f dockerfile-test-cmd -t cmd-test:0.1 .</span><br><span class="line"></span><br><span class="line"># 运行镜像</span><br><span class="line">$ docker run cmd-test:0.1		# 由结果可得，运行后就执行了 ls -a 命令</span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">.dockerenv</span><br><span class="line">bin</span><br><span class="line">dev</span><br><span class="line">etc</span><br><span class="line">home</span><br><span class="line"></span><br><span class="line"># 想追加一个命令  -l 成为ls -al：展示列表详细数据</span><br><span class="line">$ docker run cmd-test:0.1 -l</span><br><span class="line">docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \&quot;-l\&quot;:</span><br><span class="line">executable file not found in $PATH&quot;: unknown.</span><br><span class="line">ERRO[0000] error waiting for container: context canceled </span><br><span class="line"></span><br><span class="line"># cmd的情况下 -l 替换了CMD[&quot;ls&quot;,&quot;-l&quot;] 而 -l  不是命令所以报错</span><br></pre></td></tr></table></figure>

<p>测试ENTRYPOINT </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 编写dockerfile文件</span><br><span class="line">$ vim dockerfile-test-entrypoint</span><br><span class="line">FROM centos</span><br><span class="line">ENTRYPOINT [&quot;ls&quot;,&quot;-a&quot;]</span><br><span class="line"></span><br><span class="line"># 构建镜像</span><br><span class="line">$ docker build  -f dockerfile-test-entrypoint -t cmd-test:0.1 .</span><br><span class="line"></span><br><span class="line"># 运行镜像</span><br><span class="line">$ docker run entrypoint-test:0.1</span><br><span class="line">.</span><br><span class="line">..</span><br><span class="line">.dockerenv</span><br><span class="line">bin</span><br><span class="line">dev</span><br><span class="line">etc</span><br><span class="line">home</span><br><span class="line">lib</span><br><span class="line">lib64</span><br><span class="line">lost+found ...</span><br><span class="line"></span><br><span class="line"># 我们的命令，是直接拼接在我们得ENTRYPOINT命令后面的</span><br><span class="line">$ docker run entrypoint-test:0.1 -l</span><br><span class="line">total 56</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 .</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 ..</span><br><span class="line">-rwxr-xr-x   1 root root    0 May 16 06:32 .dockerenv</span><br><span class="line">lrwxrwxrwx   1 root root    7 May 11  2019 bin -&gt; usr/bin</span><br><span class="line">drwxr-xr-x   5 root root  340 May 16 06:32 dev</span><br><span class="line">drwxr-xr-x   1 root root 4096 May 16 06:32 etc</span><br><span class="line">drwxr-xr-x   2 root root 4096 May 11  2019 home</span><br><span class="line">lrwxrwxrwx   1 root root    7 May 11  2019 lib -&gt; usr/lib</span><br><span class="line">lrwxrwxrwx   1 root root    9 May 11  2019 lib64 -&gt; usr/lib64 ....</span><br></pre></td></tr></table></figure>

<p>Dockerfile中很多命令都十分的相似，我们需要了解它们的区别，我们最好的学习就是对比他们然后测试效果！</p>
<h2 id="实战：Tomcat镜像"><a href="#实战：Tomcat镜像" class="headerlink" title="实战：Tomcat镜像"></a>实战：Tomcat镜像</h2><h5 id="1、准备镜像文件"><a href="#1、准备镜像文件" class="headerlink" title="1、准备镜像文件"></a>1、准备镜像文件</h5><p>准备tomcat 和 jdk 到当前目录，编写好README</p>
<h5 id="2、编写dokerfile"><a href="#2、编写dokerfile" class="headerlink" title="2、编写dokerfile"></a>2、编写dokerfile</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ vim dockerfileFROM centos 										# 基础镜像centosMAINTAINER cao&lt;1165680007@qq.com&gt;					# 作者COPY README /usr/local/README 						# 复制README文件ADD jdk-8u231-linux-x64.tar.gz /usr/local/ 			# 添加jdk，ADD 命令会自动解压ADD apache-tomcat-9.0.35.tar.gz /usr/local/ 		# 添加tomcat，ADD 命令会自动解压RUN yum -y install vim								# 安装 vim 命令ENV MYPATH /usr/local 								# 环境变量设置 工作目录WORKDIR $MYPATHENV JAVA_HOME /usr/local/jdk1.8.0_231 				# 环境变量： JAVA_HOME环境变量ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.35 	# 环境变量： tomcat环境变量ENV CATALINA_BASH /usr/local/apache-tomcat-9.0.35# 设置环境变量 分隔符是：ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin 	EXPOSE 8080 										# 设置暴露的端口CMD /usr/local/apache-tomcat-9.0.35/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.35/logs/catalina.out 					# 设置默认命令</span><br></pre></td></tr></table></figure>



<h5 id="3、构建镜像"><a href="#3、构建镜像" class="headerlink" title="3、构建镜像"></a>3、构建镜像</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 因为dockerfile命名使用默认命名 因此不用使用-f 指定文件$ docker build -t mytomcat:0.1 .</span><br></pre></td></tr></table></figure>



<h5 id="4、run镜像"><a href="#4、run镜像" class="headerlink" title="4、run镜像"></a>4、run镜像</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># -d:后台运行 -p:暴露端口 --name:别名 -v:绑定路径 $ docker run -d -p 8080:8080 --name tomcat01 -v /home/kuangshen/build/tomcat/test:/usr/local/apache-tomcat-9.0.35/webapps/test -v /home/kuangshen/build/tomcat/tomcatlogs/:/usr/local/apache-tomcat-9.0.35/logs mytomcat:0.1</span><br></pre></td></tr></table></figure>

<h5 id="5、访问测试"><a href="#5、访问测试" class="headerlink" title="5、访问测试"></a>5、访问测试</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker exec -it 自定义容器的id /bin/bash$ cul localhost:8080</span><br></pre></td></tr></table></figure>

<h5 id="6、发布项目"><a href="#6、发布项目" class="headerlink" title="6、发布项目"></a>6、发布项目</h5><p>(由于做了卷挂载，我们直接在本地编写项目就可以发布了！)</p>
<p>发现：项目部署成功，可以直接访问！</p>
<p>我们以后开发的步骤：需要掌握Dockerfile的编写！我们之后的一切都是使用docker镜像来发布运行！</p>
<h2 id="第十讲-发布docker镜像"><a href="#第十讲-发布docker镜像" class="headerlink" title="第十讲 发布docker镜像"></a>第十讲 发布docker镜像</h2><h4 id="10-1-发布到dockerhub"><a href="#10-1-发布到dockerhub" class="headerlink" title="10.1 发布到dockerhub"></a>10.1 发布到dockerhub</h4><p>1、地址 <a href="https://hub.docker.com/">https://hub.docker.com/</a></p>
<p>2、确定这个账号可以登录</p>
<p>3、登录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker login --help</span><br><span class="line">Usage:  docker login [OPTIONS] [SERVER]</span><br><span class="line"></span><br><span class="line">Log in to a Docker registry.</span><br><span class="line">If no server is specified, the default is defined by the daemon.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --password string   Password</span><br><span class="line">      --password-stdin    Take the password from stdin</span><br><span class="line">  -u, --username string   Username</span><br><span class="line"></span><br><span class="line">$ docker login -u 你的用户名 -p 你的密码</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4、提交 push镜像</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6880624df46a68aa5a4fb4f44d3ac93b.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 会发现push不上去，因为如果没有前缀的话默认是push到 官方的library</span><br><span class="line"># 解决方法：</span><br><span class="line"># 第一种 build的时候添加你的dockerhub用户名，然后在push就可以放到自己的仓库了</span><br><span class="line">$ docker build -t kuangshen/mytomcat:0.1 .</span><br><span class="line"></span><br><span class="line"># 第二种 使用docker tag #然后再次push</span><br><span class="line">$ docker tag 容器id kuangshen/mytomcat:1.0 #然后再次push</span><br><span class="line">$ docker push kuangshen/mytomcat:1.0</span><br></pre></td></tr></table></figure>

<p>10.2 发布到阿里云镜像</p>
<p>看官网 很详细<a href="https://cr.console.aliyun.com/repository/">https://cr.console.aliyun.com/repository/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo docker login --username=zchengx registry.cn-shenzhen.aliyuncs.com</span><br><span class="line">$ sudo docker tag [ImageId] registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:[镜像版本号]</span><br><span class="line"></span><br><span class="line"># 修改id 和 版本</span><br><span class="line">sudo docker tag a5ef1f32aaae registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:1.0</span><br><span class="line"># 修改版本</span><br><span class="line">$ sudo docker push registry.cn-shenzhen.aliyuncs.com/dsadxzc/cheng:[镜像版本号]</span><br></pre></td></tr></table></figure>

<p>总结：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/5fcac2393e232435f2fbe109bf54c461.png"></p>
<h2 id="第十一讲-docker网络"><a href="#第十一讲-docker网络" class="headerlink" title="第十一讲 docker网络"></a>第十一讲 docker网络</h2><p>清空镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi -f $(docker images -aq)</span><br></pre></td></tr></table></figure>

<p>查看网卡</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-4-6-centos ~]# ip addr </span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 52:54:00:e6:fb:2d brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.4.6/22 brd 10.0.7.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::5054:ff:fee6:fb2d/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class="line">    link/ether 02:42:d6:9a:ed:b7 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:d6ff:fe9a:edb7/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<p>docker如何处理容器于宿主机的网络</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试  运行一个tomcat</span><br><span class="line">$ docker run -d -P --name tomcat01 tomcat</span><br><span class="line"></span><br><span class="line"># 查看容器内部网络地址</span><br><span class="line">$ docker exec -it 容器id ip addr</span><br><span class="line"></span><br><span class="line"># 发现容器启动的时候会得到一个 eth0@if91 ip地址，docker分配！</span><br><span class="line">$ ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">261: eth0@if91: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default </span><br><span class="line">    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"># 思考？ linux能不能ping通容器内部！ 可以 容器内部可以ping通外界吗？ 可以！</span><br><span class="line">$ ping 172.18.0.2</span><br><span class="line">PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.069 ms</span><br><span class="line">64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.074 ms</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li><p>我们每启动一个docker容器，docker就会给docker容器分配一个ip，我们只要按照了docker，就会有一个docker0桥接模式，使用的技术是veth-pair技术！</p>
</li>
<li><p>再启动一个容器测试，发现又多了一对网络. </p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ad6d849117e30fda5f1d864b80508950.png"></p>
</li>
</ol>
<p>我们发现这个容器带来网卡，都是一对对的,veth-pair 就是一对的虚拟设备接口，他们都是成对出现的，一端连着协议，一端彼此相连正因为有这个特性 veth-pair 充当一个桥梁，连接各种虚拟网络设备的OpenStac,Docker容器之间的连接，OVS的连接，都是使用evth-pair技术</p>
<p>3、我们来测试下tomcat01和tomcat02是否可以ping通</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#获取tomcat01的ip 172.17.0.2</span><br><span class="line">$ docker-tomcat docker exec -it tomcat01 ip addr  </span><br><span class="line">550: eth0@if551: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default </span><br><span class="line">link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line"> valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 让tomcat02 ping tomcat01       </span><br><span class="line">$ docker-tomcat docker exec -it tomcat02 ping 172.17.0.2</span><br><span class="line">PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.098 ms</span><br><span class="line">64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.071 ms</span><br><span class="line"></span><br><span class="line"># 结论：容器和容器之间是可以互相ping通</span><br></pre></td></tr></table></figure>

<p><strong>网络模型图</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/42da936b21f047bb0d54430eb2095b85.png"></p>
<p>结论：tomcat01和tomcat02公用一个路由器，docker0。</p>
<p>所有的容器不指定网络的情况下，都是docker0路由的，docker会给我们的容器分配一个默认的可用ip。</p>
<blockquote>
<p>小结</p>
</blockquote>
<p>Docker使用的是Linux的桥接，宿主机是一个Docker容器的网桥 docker0</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d64348fa5254aee5a30a4ec3ea161a62.png"></p>
<p>Docker中所有网络接口都是虚拟的，虚拟的转发效率高（内网传递文件）</p>
<p>只要容器删除，对应的网桥一对就没了！</p>
<p><strong>思考一个场景：我们编写了一个微服务，database url=ip: 项目不重启，数据ip换了，我们希望可以处理这个问题，可以通过名字来进行访问容器</strong>？</p>
<h5 id="–-link"><a href="#–-link" class="headerlink" title="–-link"></a>–-link</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker exec -it tomcat02 ping tomca01   # ping不通</span><br><span class="line">ping: tomca01: Name or service not known</span><br><span class="line"></span><br><span class="line"># 运行一个tomcat03 --link tomcat02 </span><br><span class="line">$ docker run -d -P --name tomcat03 --link tomcat02 tomcat</span><br><span class="line">5f9331566980a9e92bc54681caaac14e9fc993f14ad13d98534026c08c0a9aef</span><br><span class="line"></span><br><span class="line"># 3连接2</span><br><span class="line"># 用tomcat03 ping tomcat02 可以ping通</span><br><span class="line">$ docker exec -it tomcat03 ping tomcat02</span><br><span class="line">PING tomcat02 (172.17.0.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.115 ms</span><br><span class="line">64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.080 ms</span><br><span class="line"></span><br><span class="line"># 2连接3</span><br><span class="line"># 用tomcat02 ping tomcat03 ping不通</span><br></pre></td></tr></table></figure>

<p><strong>探究：</strong></p>
<p>docker network inspect 网络id 网段相同</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/28a9ff1c86e4487e05ed57b4339803da.png"></p>
<p>docker inspect tomcat03</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/8813ee7857c38f9b33357e9c4c7b3998.png"></p>
<p>查看tomcat03里面的/etc/hosts发现有tomcat02的配置</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6718b40add3cbbd0601c9cb7093ff74b.png"></p>
<p>–link 本质就是在hosts配置中添加映射</p>
<p>现在使用Docker已经不建议使用–link了！</p>
<p>自定义网络，不适用docker0！</p>
<p>docker0问题：不支持容器名连接访问！</p>
<h5 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network</span><br><span class="line">connect     -- Connect a container to a network</span><br><span class="line">create      -- Creates a new network with a name specified by the</span><br><span class="line">disconnect  -- Disconnects a container from a network</span><br><span class="line">inspect     -- Displays detailed information on a network</span><br><span class="line">ls          -- Lists all the networks created by the user</span><br><span class="line">prune       -- Remove all unused networks</span><br><span class="line">rm          -- Deletes one or more networks</span><br></pre></td></tr></table></figure>

<p><strong>网络模式</strong></p>
<p>bridge ：桥接 docker（默认，自己创建也是用bridge模式）</p>
<p>none ：不配置网络，一般不用</p>
<p>host ：和所主机共享网络</p>
<p>container ：容器网络连通（用得少！局限很大）</p>
<p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们直接启动的命令 --net bridge,而这个就是我们得docker0</span><br><span class="line"># bridge就是docker0</span><br><span class="line">$ docker run -d -P --name tomcat01 tomcat</span><br><span class="line">等价于 =&gt; docker run -d -P --name tomcat01 --net bridge tomcat</span><br><span class="line"></span><br><span class="line"># docker0，特点：默认，域名不能访问。 --link可以打通连接，但是很麻烦！</span><br><span class="line"># 我们可以 自定义一个网络</span><br><span class="line">$ docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/img_convert/2cb31c620d7c02723333ada621392f31.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker network inspect mynet;</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/img_convert/6e9d3cfe891cff4ef8b663c54e7400d7.png"></p>
<p>启动两个tomcat,再次查看网络情况,在自定义的网络下，服务可以互相ping通，不用使用–link.</p>
<p>我们自定义的网络docker当我们维护好了对应的关系，推荐我们平时这样使用网络！</p>
<p>好处：</p>
<p>redis -不同的集群使用不同的网络，保证集群是安全和健康的</p>
<p>mysql-不同的集群使用不同的网络，保证集群是安全和健康的</p>
<h2 id="网络连通"><a href="#网络连通" class="headerlink" title="网络连通"></a>网络连通</h2><p>容器和网卡的网路连通 </p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/cfbacb1af865b2fb5ba797ecb518e81a.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试两个不同的网络连通  再启动两个tomcat 使用默认网络，即docker0$ docker run -d -P --name tomcat01 tomcat$ docker run -d -P --name tomcat02 tomcat# 此时ping不通</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/img_convert/4838a93c072a1c5608ff7c020a538038.png"></p>
<p>结论：假设要跨网络操作别人，就需要使用docker network connect 连通！</p>
<p>查看tomcat03里面的/etc/hosts发现有tomcat02的配置</p>
<p>[外链图片转存中…(img-IV7ISb15-1632447380551)]</p>
<p>–link 本质就是在hosts配置中添加映射</p>
<p>现在使用Docker已经不建议使用–link了！</p>
<p>自定义网络，不适用docker0！</p>
<p>docker0问题：不支持容器名连接访问！</p>
<h5 id="自定义网络-1"><a href="#自定义网络-1" class="headerlink" title="自定义网络"></a>自定义网络</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network</span><br><span class="line">connect     -- Connect a container to a network</span><br><span class="line">create      -- Creates a new network with a name specified by the</span><br><span class="line">disconnect  -- Disconnects a container from a network</span><br><span class="line">inspect     -- Displays detailed information on a network</span><br><span class="line">ls          -- Lists all the networks created by the user</span><br><span class="line">prune       -- Remove all unused networks</span><br><span class="line">rm          -- Deletes one or more networks</span><br></pre></td></tr></table></figure>

<p><strong>网络模式</strong></p>
<p>bridge ：桥接 docker（默认，自己创建也是用bridge模式）</p>
<p>none ：不配置网络，一般不用</p>
<p>host ：和所主机共享网络</p>
<p>container ：容器网络连通（用得少！局限很大）</p>
<p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们直接启动的命令 --net bridge,而这个就是我们得docker0</span><br><span class="line"># bridge就是docker0</span><br><span class="line">$ docker run -d -P --name tomcat01 tomcat</span><br><span class="line">等价于 =&gt; docker run -d -P --name tomcat01 --net bridge tomcat</span><br><span class="line"></span><br><span class="line"># docker0，特点：默认，域名不能访问。 --link可以打通连接，但是很麻烦！</span><br><span class="line"># 我们可以 自定义一个网络</span><br><span class="line">$ docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet</span><br></pre></td></tr></table></figure>

<p>[外链图片转存中…(img-VQpRBRbV-1632447380552)]</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker network inspect mynet;</span><br></pre></td></tr></table></figure>

<p>[外链图片转存中…(img-i1ByXXaq-1632447380553)]</p>
<p>启动两个tomcat,再次查看网络情况,在自定义的网络下，服务可以互相ping通，不用使用–link.</p>
<p>我们自定义的网络docker当我们维护好了对应的关系，推荐我们平时这样使用网络！</p>
<p>好处：</p>
<p>redis -不同的集群使用不同的网络，保证集群是安全和健康的</p>
<p>mysql-不同的集群使用不同的网络，保证集群是安全和健康的</p>
<h2 id="网络连通-1"><a href="#网络连通-1" class="headerlink" title="网络连通"></a>网络连通</h2><p>容器和网卡的网路连通 </p>
<p>[外链图片转存中…(img-kSj5c9Wq-1632447380554)]</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 测试两个不同的网络连通  再启动两个tomcat 使用默认网络，即docker0$ docker run -d -P --name tomcat01 tomcat$ docker run -d -P --name tomcat02 tomcat# 此时ping不通</span><br></pre></td></tr></table></figure>

<p>[外链图片转存中…(img-iZD6LTom-1632447380556)]</p>
<p>结论：假设要跨网络操作别人，就需要使用docker network connect 连通！</p>
]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>windows文档编码</title>
    <url>/2022/02/21/2022-02-21-windows%E6%96%87%E6%A1%A3%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<p>win上面的文档上传到linux, 编码不对，结尾为^M. </p>
<p>(^M是ctrl+v,ctrl+m)</p>
<ol>
<li><p>如果是<strong>单个文档的话，可以用vi打开，执行 :%s/^M//g　来去掉^M,</strong></p>
</li>
<li><p>set ff=unix </p>
</li>
<li><pre><code>unix2dos  filename  
dos2unix  filename

</code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>dockerfile使用</title>
    <url>/2022/02/18/2022-02-18-dockerfile%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h3 id="dockerfile使用方法"><a href="#dockerfile使用方法" class="headerlink" title="dockerfile使用方法"></a>dockerfile使用方法</h3><p>构建镜像的方式有两种：一种是基于容器制作，另一种就是通过Dockerfile。Dockerfile其实就是我们用来构建Docker镜像的源码，当然这不是所谓的编程源码，而是一些命令的组合，只要理解它的逻辑和语法格式，就可以编写Dockerfile了。</p>
<p>简要概括Dockerfile的作用：它可以让用户个性化定制Docker镜像。因为工作环境中的需求各式各样，网络上的镜像很难满足实际的需求。</p>
<h3 id="Dockerfile-Format"><a href="#Dockerfile-Format" class="headerlink" title="Dockerfile Format"></a>Dockerfile Format</h3><ol>
<li>Dockerfile整体就两类语句组成：<ul>
<li># Comment 注释信息</li>
<li>Instruction arguments 指令 参数，一行一个指令。</li>
</ul>
</li>
<li>Dockerfile文件名首字母必须大写。</li>
<li>Dockerfile指令不区分大小写，但是为方便和参数做区分，通常指令使用大写字母。</li>
<li>Dockerfile中指令按顺序从上至下依次执行。</li>
<li>Dockerfile中第一个非注释行必须是FROM指令，用来指定制作当前镜像依据的是哪个基础镜像。</li>
<li>Dockerfile中需要调用的文件必须跟Dockerfile文件在同一目录下，或者在其子目录下，父目录或者其它路径无效。</li>
</ol>
<h2 id="三、Dockerfile-Instructions"><a href="#三、Dockerfile-Instructions" class="headerlink" title="三、Dockerfile Instructions"></a>三、Dockerfile Instructions</h2><h4 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h4><ul>
<li>Introduction<ul>
<li>FROM指令必须为Dockerfile文件开篇的第一个非注释行，用于指定构建镜像所使用的基础镜像，后续的指令运行都要依靠此基础镜像所提供的的环境（简单说就是假如Dockerfile中所引用的基础镜像里面没有mkdir命令，那后续的指令是没法使用mkdir参数的。）</li>
<li>实际使用中，如果没有指定仓库，docker build会先从本机查找是否有此基础镜像，如果没有会默认去Docker Hub Registry上拉取，再找不到就会报错。</li>
</ul>
</li>
<li>Syntax<ul>
<li>FROM <Repository>[:<Tag>]</li>
<li>FROM <Repository>@<Digest><ul>
<li>Digest：镜像的哈希码，防止镜像被冒名顶替。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="MAINTAINER（deprecated）"><a href="#MAINTAINER（deprecated）" class="headerlink" title="MAINTAINER（deprecated）"></a>MAINTAINER（deprecated）</h4><ul>
<li>Introduction<ul>
<li>用于让Dockerfile的作者提供个人的信息</li>
<li>Dockerfile并不限制MAINTAINER指令的位置，但是建议放在FROM指令之后</li>
<li>在较新的docker版本中，已经被LABEL替代。</li>
</ul>
</li>
<li>Syntax<ul>
<li>MAINTAINER “<a href="mailto:&#109;&#101;&#x72;&#x6c;&#x65;&#x40;&#x65;&#120;&#x61;&#x6d;&#112;&#108;&#101;&#x2e;&#x63;&#111;&#109;">&#109;&#101;&#x72;&#x6c;&#x65;&#x40;&#x65;&#120;&#x61;&#x6d;&#112;&#108;&#101;&#x2e;&#x63;&#111;&#109;</a>“</li>
</ul>
</li>
</ul>
<h4 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h4><ul>
<li>Introduction<ul>
<li>同docker run -l</li>
<li>让用户为镜像指定各种元数据（键值对的格式）。</li>
</ul>
</li>
<li>Syntax<ul>
<li>LABEL <key>=<value> <key>=<value></li>
</ul>
</li>
</ul>
<h4 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h4><ul>
<li>Introduction<ul>
<li>复制宿主机上的文件到目标镜像中</li>
</ul>
</li>
<li>Syntax<ul>
<li>COPY <src>… <dest></li>
<li>COPY [“<src>“,… “<dest>“]<ul>
<li><src>：要复制的源文件或者目录，支持通配符</li>
<li><dest>：目标路径，即正创建的镜像的文件系统路径，建议使用绝对路径，否则，COPY指令会以WORKDIR为其起始路径。</li>
<li>如果路径中如果包含空白字符，建议使用第二种格式用引号引起来，否则会被当成两个文件。</li>
</ul>
</li>
</ul>
</li>
<li>Rules<ul>
<li><src>必须是build上下文中的目录，不能是其父目录中的文件。</li>
<li>如果<src>是目录，则其内部的文件或则子目录会被递归复制，但<src>目录本身不会被复制。</li>
<li>如果指定了多个<src>，或者<src>中使用通配符，则<dest>必须是一个目录，且必须以 / 结尾。</li>
<li>如果<dest>事先不存在，它将会被自动创建，包括其父目录路径。</li>
</ul>
</li>
</ul>
<h4 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h4><ul>
<li>Introduction<ul>
<li>ADD指令跟COPY类似，不过它还支持使用tar文件和URL路径。<ul>
<li>当拷贝的源文件是tar文件时，会自动展开为一个目录并拷贝进新的镜像中；然而通过URL获取到的tar文件不会自动展开。</li>
<li>主机可以联网的情况下，docker build可以将网络上的某文件引用下载并打包到新的镜像中。</li>
</ul>
</li>
</ul>
</li>
<li>Syntax<ul>
<li>ADD <src>… <dest></li>
<li>ADD [“<src>“,… “<dest>“]</li>
</ul>
</li>
</ul>
<h4 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h4><ul>
<li>Introduction<ul>
<li>同docker run -w</li>
<li>指定工作目录，可以指多个，每个WORKDIR只影响他下面的指令，直到遇见下一个WORKDIR为止。</li>
<li>WORKDIR也可以调用由ENV指令定义的变量。</li>
</ul>
</li>
<li>Syntax<ul>
<li>WORKDIR 相对路径或者绝对路径<ul>
<li>相对路径是相对于上一个WORKDIR指令的路径，如果上面没有WORKDIR指令，那就是当前Dockerfile文件的目录。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h4><ul>
<li>Introduction<ul>
<li>docker run -v简化版</li>
<li>用于在镜像中创建一个挂载点目录。上一章中有提到Volume有两种类型：绑定挂载卷和docker管理的卷。在dockerfile中只支持docker管理的卷，也就是说只能指定容器内的路径，不能指定宿主机的路径。</li>
</ul>
</li>
<li>Syntax<ul>
<li>VOLUME <mountpoint></li>
<li>VOLUME [“<mountpoint>“]</li>
</ul>
</li>
</ul>
<h4 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h4><ul>
<li>Introduction<ul>
<li>同docker run –expose</li>
<li>指定容器中待暴露的端口。比如容器提供的是一个https服务且需要对外提供访问，那就需要指定待暴露443端口，然后在使用此镜像启动容器时搭配 -P 的参数才能将待暴露的状态转换为真正暴露的状态，转换的同时443也会转换成一个随机端口，跟 -p :443一个意思。</li>
<li>EXPOSE指令可以一次指定多个端口，例如：EXPOSE 11111/udp 11112/tcp</li>
</ul>
</li>
<li>Syntax<ul>
<li>EXPOSE <port>[/<protocol>] [<port>[/<protocol>] …]</li>
<li><protocol>用于指定协议类型，如果不指定，默认TCP协议。</li>
</ul>
</li>
</ul>
<h4 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h4><ul>
<li>Introduction<ul>
<li>同docker run -e</li>
<li>为镜像定义所需的环境变量，并可被ENV指令后面的其它指令所调用。调用格式为$variable_name或者${variable_name}</li>
<li>使用docker run启动容器的时候加上 -e 的参数为variable_name赋值，可以覆盖Dockerfile中ENV指令指定的此variable_name的值。但是不会影响到dockerfile中已经引用过此变量的文件名。下面有举例说明：</li>
</ul>
</li>
<li>Syntax<ul>
<li>ENV <key> <value></li>
<li>ENV <key>=<value> …<ul>
<li>第一种格式一次只能定义一个变量，<key>之后所有内容都会被视为<value>的组成部分</li>
<li>第二种格式一次可以定义多个变量，每个变量为一个”=”的键值对，如果<value>中包含空格，可以用反斜线 \ 进行转义，也可以为<value>加引号，另外参数过长时可用反斜线做续行。</li>
<li>定义多个变量时，建议使用第二种方式，因为Dockerfile中每一行都是一个镜像层，构建起来比较吃资源。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h4><ul>
<li>Introduction<ul>
<li>用于指定docker build过程中运行的程序，可以是任何命令。</li>
<li>RUN指令后所执行的命令必须在FROM指令后的基础镜像中存在才行。</li>
</ul>
</li>
<li>Syntax<ul>
<li>RUN <command></li>
<li>RUN [“executable”, “param1”, “param2”]<ul>
<li><command>通常是一个shell命令，系统默认会把后面的命令作为shell的子进程来运行，以”/bin/sh -c”来运行它，也就意味着此进程在容器中的PID一定不为1，如果是1完事就结束了哇。</li>
<li>第二种格式的参数是一个JSON格式的数组，其中”executable”为要运行的命令，后面的”paramN”为传递给命令的选项或参数。此格式指定的命令不会以”/bin/sh -c”来发起，也就是直接由内核创建，因此不具备shell特性，类似于RUN [ “echo”, “$HOME” ]，是无法识别 $ 的；如果想要依赖shell特性，可以替换命令为这样的格式[ “/bin/sh”, “-c”, “echo $HOME” ]。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h4><ul>
<li>Introduction<ul>
<li>指定启动容器的默认要运行的程序，也就是PID为1的进程命令，且其运行结束后容器也会终止。如果不指定，默认是bash。</li>
<li>CMD指令指定的默认程序会被docker run命令行指定的参数所覆盖。</li>
<li>Dockerfile中可以存在多个CMD指令，但仅最后一个生效。因为一个docker容器只能运行一个PID为1的进程。</li>
<li>类似于RUN指令，也可以运行任意命令或程序，但是两者的运行时间点不同<ul>
<li>RUN指令运行在docker build的过程中，而CMD指令运行在基于新镜像启动容器（docker run）时。</li>
</ul>
</li>
</ul>
</li>
<li>Syntax<ul>
<li>CMD command param1 param2</li>
<li>CMD [“executable”,”param1”,”param2”]</li>
<li>CMD [“param1”,”param2”]<ul>
<li>前两种语法格式同RUN指令。第一种用法对于CMD指令基本没有意义，因为它运行的程序PID不为1。</li>
<li>第三种则需要结合ENTRYPOINT指令使用，CMD指令后面的命令作为ENTRYPOINT指令的默认参数。如果docker run命令行结尾有参数指定，那CMD后面的参数不生效。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h4><ul>
<li>Introduction<ul>
<li>类似CMD指令的功能，用于为容器指定默认运行程序。</li>
<li>Dockerfile中可以存在多个ENTRYPOINT指令，但仅最后一个生效</li>
<li>与CMD区别在于，由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且这些命令行参数会被当做参数传递给ENTRYPOINT指令指定的程序。</li>
<li>不过，docker run的–entrypoint选项的参数可覆盖ENTRYPOINT指定的默认程序。示例如下：</li>
</ul>
</li>
<li>Syntax<ul>
<li>ENTRYPOINT command param1 param2</li>
<li>ENTRYPOINT [“executable”, “param1”, “param2”]</li>
</ul>
</li>
</ul>
<h4 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h4><ul>
<li>Introduction<ul>
<li>用于指定docker build过程中任何RUN、CMD等指令的用户名或者UID。</li>
<li>默认情况下容器的运行用户为root。</li>
</ul>
</li>
<li>Syntax<ul>
<li>USER <user>[:<group>]</li>
<li>USER <UID>[:<GID>]<ul>
<li>实践中UID需要是/etc/passwd中某用户的有效UID，否则docker run命令将运行失败。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="HEALTHCHECK"><a href="#HEALTHCHECK" class="headerlink" title="HEALTHCHECK"></a>HEALTHCHECK</h4><ul>
<li>Introduction<ul>
<li>顾名思义，健康检查。此指令的就是告诉docker如果检查容器是否正常工作。拿nginx举例，即便进程运行，服务也不一定正常，因为万一root指错了呢？</li>
</ul>
</li>
<li>Syntax<ul>
<li>HEALTHCHECK [OPTIONS] CMD command</li>
<li>HEALTHCHECK NONE<ul>
<li>HEALTHCHECK指令让我们去定义一个CMD，在CMD后面编写一条命令去判断我们的服务运行是否正常。检查肯定不是一次性的，所以OPTIONS就是指定检查的频率等等。<ul>
<li>–interval=DURATION（默认值：30s）：每隔多久检查一次，默认30s</li>
<li>–timeout=DURATION（默认值：30s）：超时时长，默认30s</li>
<li>–start-period=DURATION（默认值：0s）：启动健康检查的等待时间。因为容器启动成功时，进程不一定立马就启动成功，那过早开始检查就会返回不健康。</li>
<li>–retries=N（默认值：3）：如果检查一次失败就返回不健康未免太武断，所以默认三次机会。</li>
<li>CMD健康检测命令发出时，返回值有三种情况<ul>
<li>0：成功</li>
<li>1：不健康</li>
<li>2：保留，无实际意义。</li>
</ul>
</li>
</ul>
</li>
<li>HEALTHCHECK NONE就是不做健康检查</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="SHELL"><a href="#SHELL" class="headerlink" title="SHELL"></a>SHELL</h4><ul>
<li>Introduction<ul>
<li>用来指定运行程序默认要使用的shell类型，因为windows环境默认是powershell。此指令一般不会使用。</li>
</ul>
</li>
<li>Syntax<ul>
<li>SHELL [“executable”, “parameters”]</li>
</ul>
</li>
</ul>
<h4 id="STOPSIGNAL"><a href="#STOPSIGNAL" class="headerlink" title="STOPSIGNAL"></a>STOPSIGNAL</h4><ul>
<li>Introduction<ul>
<li>指定发送使容器退出的系统调用信号。docker stop之所以能停止容器，就是发送了15的信号给容器内PID为1的进程。此指令一般不会使用。</li>
</ul>
</li>
<li>Syntax<ul>
<li>STOPSIGNAL signal</li>
</ul>
</li>
</ul>
<h4 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h4><ul>
<li>Introduction<ul>
<li>ARG命令同EVN类似，也是指定一个变量，但不同的是，ENV指令配合-e参数可以在docker run过程中传参，而使用ARG指令配合–build-arg参数可以在docker build过程中传参，这方便了我们为不同场景构建不同镜像。</li>
</ul>
</li>
<li>Syntax<ul>
<li>ARG <name>[=<default value>]</li>
</ul>
</li>
</ul>
<h4 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h4><ul>
<li>Introduction<ul>
<li>用于在Dockerfile中定义一个触发器。</li>
<li>ONBUILD后面指定的指令在docker build时是不会执行，构建完的镜像在被另一个Dockerfile文件中FROM指令所引用的时才会触发执行。</li>
</ul>
</li>
<li>Syntax<ul>
<li>ONBUILD [INSTRUCTION]<ul>
<li>几乎任何指令都可以成为触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和MAINTAINER指令，多数情况是使用RUN或者ADD。</li>
<li>另外在使用COPY指令时，应该注意后续引用该镜像的Dockerfile的同级目录下是否有被拷贝的文件。</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># dockerfile </span><br><span class="line">FROM python </span><br><span class="line">COPY containerfile  /root/containerfile</span><br><span class="line">RUN pip3 install -r /root/containerfile/requirements.txt </span><br><span class="line">ENV LANG=en_US.UTF-8</span><br><span class="line">ENV TZ=Asia/Shanghai</span><br><span class="line">RUN mkdir /usr/local/nodejs/ &amp;&amp; cp -r /root/containerfile/nodejs/node-v12.14.0-linux-x64/* /usr/local/nodejs/ &amp;&amp; ln -s /usr/local/nodejs/bin/node /usr/local/bin &amp;&amp; ln -s /usr/local/nodejs/bin/npm /usr/local/bin  &amp;&amp;  npm install hexo-cli -g </span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y &amp;&amp; cp  /root/containerfile/.git* /root/ &amp;&amp; git init &amp;&amp; cp -r  /root/containerfile/.ssh /root/.ssh </span><br><span class="line">ENTRYPOINT [&quot;sh&quot;,&quot;/root/containerfile/run_server.sh&quot;]</span><br><span class="line">#CMD /bin/bash /root/containerfile/run_server.sh  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat run_ser</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>django学习笔记</title>
    <url>/2022/01/06/2022-01-06-django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>开始django</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 安装特定版本的django </span><br><span class="line">pip install django==1.11.4 </span><br><span class="line"># 安装django会按照 django-admin命令行工具</span><br><span class="line"># 创建一个新的项目</span><br><span class="line">mkdir myproject </span><br><span class="line">cd myproject </span><br><span class="line">django-admin startproject myproject </span><br><span class="line"># 结构目录如下</span><br><span class="line">myproject/                  &lt;-- 高级别的文件夹</span><br><span class="line"> |-- myproject/             &lt;-- Django项目文件夹</span><br><span class="line"> |    |-- myproject/</span><br><span class="line"> |    |    |-- __init__.py</span><br><span class="line"> |    |    |-- settings.py</span><br><span class="line"> |    |    |-- urls.py</span><br><span class="line"> |    |    |-- wsgi.py</span><br><span class="line"> |    +-- manage.py</span><br></pre></td></tr></table></figure>

<p>最初的项目结构由五个文件组成：</p>
<ul>
<li><strong>manage.py</strong>：使用<strong>django-admin</strong>命令行工具的快捷方式。它用于运行与我们项目相关的管理命令。我们将使用它来运行开发服务器，运行测试，创建迁移等等。</li>
<li><strong>__init.py</strong>：这个空文件告诉python这个文件夹是一个python包。</li>
<li><strong>settings.py</strong>：这个文件包含了所有的项目配置。将来我们会一直提到这个文件！</li>
<li><strong>urls.py</strong>：这个文件负责映射我们项目中的路由和路径。例如，如果你想在访问URL <code>/ about/</code> 时显示某些内容，则必须先在这里做映射关系。</li>
<li><strong>wsgi.py</strong>：该文件是用于部署的简单网关接口。你可以暂且先不用关心她的内容，就先让他在那里就好了。</li>
</ul>
<p>django自带了一个简单的网络服务器。在开发过程中非常方便，所以我们无需安装任何其他软件即可在本地运行项目。我们可以通过执行命令来测试一下它：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver </span><br></pre></td></tr></table></figure>

<p>访问web, <a href="http://localhost:8000即可看到。">http://localhost:8000即可看到。</a></p>
<p>在Django的哲学中，我们有两个重要的概念：</p>
<ul>
<li><strong>app</strong>：是一个可以做完成某件事情的Web应用程序。一个应用程序通常由一组<strong>models(数据库表)<strong>，</strong>views(视图)<strong>，</strong>templates(模板)<strong>，</strong>tests(测试)</strong> 组成。</li>
<li><strong>project</strong>：是配置和应用程序的集合。一个项目可以由多个应用程序或一个应用程序组成。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在项目中新建一个应用</span><br><span class="line">django-admin startapp boards</span><br></pre></td></tr></table></figure>

<p>如何新建一个视图？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在views中新建一个header page+response </span><br><span class="line">def home(request):</span><br><span class="line">    return HttpResponse(&quot;hello world&quot;)</span><br><span class="line"># 在urls中新建一个路由匹配规则， 正则</span><br><span class="line">from boards import views </span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(r&#x27;^$&#x27;, views.home, name=&#x27;home&#x27;),</span><br><span class="line">]</span><br><span class="line"># ^$开始到结束，匹配空路径 </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程笔记</category>
      </categories>
  </entry>
  <entry>
    <title>podsecuritypolicy--seccomp</title>
    <url>/2022/02/22/2022-02-22-psp--seccomp/</url>
    <content><![CDATA[<h3 id="Seccomp-限制容器的系统调用"><a href="#Seccomp-限制容器的系统调用" class="headerlink" title="Seccomp 限制容器的系统调用"></a>Seccomp 限制容器的系统调用</h3><h3 id="1-seccomp是什么"><a href="#1-seccomp是什么" class="headerlink" title="1 seccomp是什么"></a>1 seccomp是什么</h3><p>seccomp（securecomputing mode）是linuxkernel从2.6.23版本开始所支持的一种安全机制。</p>
<p>在Linux系统里，大量的系统调用（systemcall）直接暴露给用户态程序。但是，并不是所有的系统调用都被需要，而且不安全的代码滥用系统调用会对系统造成安全威胁。通过seccomp，我们限制程序使用某些系统调用，这样可以减少系统的暴露面，同时是程序进入一种“安全”的状态。   </p>
<p>系统调用列表可查阅</p>
<p><a href="http://asm.sourceforge.net/syscall.html#p33">Linux/i386 system calls (sourceforge.net)</a> </p>
<p><a href="https://man7.org/linux/man-pages/man2/syscalls.2.html">syscalls(2) - Linux manual page (man7.org)</a></p>
<h3 id="2-配置方法"><a href="#2-配置方法" class="headerlink" title="2 配置方法"></a>2 配置方法</h3><p>k8s中，可以通过podsecurity policy来限制pod的系统调用。1.16以后为psp稳定版本，经测试1.14以后版本均可用。</p>
<h4 id="2-1-开启psp与rbac"><a href="#2-1-开启psp与rbac" class="headerlink" title="2.1 开启psp与rbac"></a>2.1 开启psp与rbac</h4><p>rke部署集群启用psp需要在cluster.yml中开启rbac与psp:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kube-api:</span><br><span class="line">   pod_security_policy: true</span><br><span class="line">authorization:</span><br><span class="line">  mode: rbac</span><br></pre></td></tr></table></figure>

<h4 id="2-2-配置seccomp"><a href="#2-2-配置seccomp" class="headerlink" title="2.2 配置seccomp"></a>2.2 配置seccomp</h4><p>Pod 对 seccomp 模版的使用可以通过在 PodSecurityPolicy 上设置<code>annotations</code>配置。 </p>
<p><strong>seccomp.security.alpha.kubernetes.io/allowedProfileNames</strong> - 指定defaultProfileName可用的模板类型。取值为一个可用值的列表。 表中每项可以以下字段的取值之一，还可以是 <code>*</code>，用来表示允许所有的模版。 如果没有设置此字段，意味着默认的 seccomp 模版是不可更改的。</p>
<p><strong>seccomp.security.alpha.kubernetes.io/defaultProfileName</strong>字段用来指定为容器配置默认的 seccomp 模版。可选值为：</p>
<ol>
<li><p><code>unconfined</code> - 不开启seccomp, Seccomp 不会被应用到容器进程上 （Kubernets 中的默认设置）。</p>
</li>
<li><p><code>runtime/default</code> - 使用默认的容器运行时模版。默认的容器系统调用配置<a href="https://docs.docker.com/engine/security/seccomp/">Seccomp security profiles for Docker | Docker Documentation</a> ，默认的配置为绝大多数容器提供了合理权限，限制了部分系统调用，增强了安全性。</p>
<p>此时可修改psp为:</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: &#x27;*&#x27;</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default</span><br><span class="line">  name: default-psp</span><br><span class="line">spec:</span><br><span class="line">  allowPrivilegeEscalation: true</span><br><span class="line">  allowedCapabilities:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  hostIPC: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPID: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - max: 65535</span><br><span class="line">    min: 0</span><br><span class="line">  privileged: true</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  volumes:</span><br><span class="line">  - &#x27;*&#x27;</span><br></pre></td></tr></table></figure>

<p>修改部分为添加<code>seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default</code></p>
<p>若部分容器需要特殊权限，就需要自定义配置seccomp模板。</p>
<p>3 .  <code>localhost/&lt;路径名&gt;</code> - 指定节点上路径 <code>&lt;seccomp_root&gt;/&lt;路径名&gt;</code> 下的一个 文件作为其模版。其中 <code>&lt;seccomp_root&gt;</code> 是通过 <code>kubelet</code> 的标志 <code>--seccomp-profile-root</code> 来指定的，默认的路径为<code> /var/lib/kubelet/seccomp/</code>，若没有改目录，需创建。</p>
</li>
</ol>
<p>seccomp模板可配置黑白名单，配置文件为json格式。</p>
<p>默认禁止全部系统调用，开启白名单为 white_list.json示例：  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;defaultAction&quot;: &quot;SCMP_ACT_ERRNO&quot;,</span><br><span class="line">    &quot;syscalls&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;names&quot;: [</span><br><span class="line">                &quot;read&quot;,</span><br><span class="line">                &quot;write&quot;,</span><br><span class="line">                &quot;_exit&quot;,</span><br><span class="line">                &quot;_sigreturn&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;action&quot;: &quot;SCMP_ACT_ALLOW&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"># 仅开启四种系统调用示例。</span><br></pre></td></tr></table></figure>

<p>默认开放全部系统调用，开启黑名单为black_list.json： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;defaultAction&quot;: &quot;SCMP_ACT_ALLOW&quot;,</span><br><span class="line">    &quot;syscalls&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;names&quot;: [&quot;mkdir&quot;, &quot;rmdir&quot;],</span><br><span class="line">            &quot;action&quot;: &quot;SCMP_ACT_ERRNO&quot;,</span><br><span class="line">            &quot;args&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果对全局修改配置可直接修改默认psp，如果对部分服务新建特殊需要可新建psp</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: &#x27;*&#x27;</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/defaultProfileName: localhost/black_list.json</span><br><span class="line">  name: psp-test</span><br><span class="line">spec:</span><br><span class="line">  allowPrivilegeEscalation: true</span><br><span class="line">  allowedCapabilities:</span><br><span class="line">  - &#x27;*&#x27;</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  hostIPC: true</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  hostPID: true</span><br><span class="line">  hostPorts:</span><br><span class="line">  - max: 65535</span><br><span class="line">    min: 0</span><br><span class="line">  privileged: true</span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  seLinux:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  volumes:</span><br><span class="line">  - &#x27;*&#x27;</span><br></pre></td></tr></table></figure>

<p>配置<code> seccomp.security.alpha.kubernetes.io/defaultProfileName: localhost/black_list.json</code>， 需要将配置文件存储在调度psp的节点/var/lib/kubelet/seccomp/下。</p>
<h4 id="2-3-rbac授权"><a href="#2-3-rbac授权" class="headerlink" title="2.3 rbac授权"></a>2.3 rbac授权</h4><p>配置完成psp后，需要通过rbac授予用户或者sa权限。配置示例如下：<PSPNAME>待绑定psp资源名称。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># clusterrole</span><br><span class="line">cat &gt; cr-&lt;PSPNAME&gt;.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: cr-&lt;PSPNAME&gt;</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;policy&#x27;]</span><br><span class="line">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class="line">  verbs:     [&#x27;use&#x27;]</span><br><span class="line">  resourceNames:</span><br><span class="line">  - &lt;PSPNAME&gt;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#  clusterrolebing</span><br><span class="line">cat &gt; crb-cr-&lt;PSPNAME&gt;-authorization.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: crb-cr-&lt;PSPNAME&gt;-authorization</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cr-&lt;PSPNAME&gt;</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line"># Authorize all service accounts in a namespace (recommended):# 授权命名空间下的所有服务账号（推荐）：</span><br><span class="line">- kind: Group</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  name: system:serviceaccounts:&lt;authorized namespace&gt;</span><br><span class="line"># Authorize specific service accounts (not recommended):# 授权特定的服务账号（不建议这样操作）：</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: &lt;authorized service account name&gt;</span><br><span class="line">  namespace: &lt;authorized pod namespace&gt;</span><br><span class="line"># Authorize specific users (not recommended):# 授权特定的用户（不建议这样操作）</span><br><span class="line">- kind: User</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  name: &lt;authorized user name&gt;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<p>替换</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># clusterrole</span><br><span class="line">cat &gt; cr-default-psp.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: cr-default-psp</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&#x27;policy&#x27;]</span><br><span class="line">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class="line">  verbs:     [&#x27;use&#x27;]</span><br><span class="line">  resourceNames:</span><br><span class="line">  - default-psp</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; crb-cr-default-psp-authorization.yml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: crb-cr-default-psp-authorization</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cr-default-psp</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  name: system:serviceaccounts</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
  <entry>
    <title>rke up bug</title>
    <url>/2022/03/18/2022-03-18-rke-up-bug/</url>
    <content><![CDATA[<p><code>Failed to reconcile etcd plane: Etcd plane nodes are replaced. Stopping provisioning. Please restore your cluster from backup.</code></p>
<p>因为没有清除干净，rke remove或者删除rkestate创建后遗留的文件。</p>
<p><code>kubernetes_version</code>字段无效</p>
<p>更新集群版本时，只指定kubernetes version无效，需要再指定</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">images:</span><br><span class="line">kubernetes: </span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>bug</category>
      </categories>
  </entry>
  <entry>
    <title>项目立项管理</title>
    <url>/2022/03/13/2022-03-13-%E9%A1%B9%E7%9B%AE%E7%AB%8B%E9%A1%B9%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h3 id="三-项目立项管理"><a href="#三-项目立项管理" class="headerlink" title="三 项目立项管理"></a>三 项目立项管理</h3><h4 id="3-1-项目管理内容"><a href="#3-1-项目管理内容" class="headerlink" title="3.1 项目管理内容"></a>3.1 项目管理内容</h4><h5 id="3-1-1-立项建议书"><a href="#3-1-1-立项建议书" class="headerlink" title="3.1.1 立项建议书"></a>3.1.1 立项建议书</h5><h5 id="3-1-2-项目可行性研究报告"><a href="#3-1-2-项目可行性研究报告" class="headerlink" title="3.1.2 项目可行性研究报告"></a>3.1.2 项目可行性研究报告</h5><h5 id="3-1-3-项目招投标"><a href="#3-1-3-项目招投标" class="headerlink" title="3.1.3 项目招投标"></a>3.1.3 项目招投标</h5><ol>
<li>招标</li>
<li>投标</li>
<li>评标</li>
<li>选定项目承建方</li>
</ol>
<h4 id="3-2-可行性研究"><a href="#3-2-可行性研究" class="headerlink" title="3.2 可行性研究"></a>3.2 可行性研究</h4><h5 id="3-2-1-可行性研究的内容"><a href="#3-2-1-可行性研究的内容" class="headerlink" title="3.2.1 可行性研究的内容"></a>3.2.1 可行性研究的内容</h5><ol>
<li>技术可行性分析</li>
<li>经济可行性分析</li>
<li>运行环境可行性分析</li>
<li>其他方面的可行性分析 </li>
</ol>
<h5 id="3-2-2-可行性研究的步骤"><a href="#3-2-2-可行性研究的步骤" class="headerlink" title="3.2.2 可行性研究的步骤"></a>3.2.2 可行性研究的步骤</h5><h5 id="3-2-3-初步可行性研究"><a href="#3-2-3-初步可行性研究" class="headerlink" title="3.2.3 初步可行性研究"></a>3.2.3 初步可行性研究</h5><ol>
<li>初步可行性研究的定义及目的 </li>
<li>初步可行性研究的主要内容</li>
<li>初步可行性研究的结果及作用 </li>
<li>辅助功能研究</li>
</ol>
<h5 id="3-2-4-详细可行性研究"><a href="#3-2-4-详细可行性研究" class="headerlink" title="3.2.4 详细可行性研究"></a>3.2.4 详细可行性研究</h5><ol>
<li>详细可行性研究的依据</li>
<li>详细可行性研究的原则于程序框架</li>
<li>详细可行性研究的方法</li>
<li>详细可行性研究的内容</li>
</ol>
<h5 id="3-2-5-效益的预测与评估"><a href="#3-2-5-效益的预测与评估" class="headerlink" title="3.2.5 效益的预测与评估"></a>3.2.5 效益的预测与评估</h5><ol>
<li>函数求解法</li>
<li>相关关系法</li>
<li>模糊数学法</li>
<li>专家意见法</li>
<li>成本降低法</li>
<li>利润增加法</li>
</ol>
<h4 id="3-3-项目的评估与论证"><a href="#3-3-项目的评估与论证" class="headerlink" title="3.3 项目的评估与论证"></a>3.3 项目的评估与论证</h4><h5 id="3-3-1-项目论证"><a href="#3-3-1-项目论证" class="headerlink" title="3.3.1 项目论证"></a>3.3.1 项目论证</h5><ol>
<li>项目论证的概念</li>
<li>项目论证的作用</li>
<li>项目论证的阶段划分</li>
<li>项目论证的一半程序</li>
</ol>
<h5 id="3-3-2-项目评估"><a href="#3-3-2-项目评估" class="headerlink" title="3.3.2 项目评估"></a>3.3.2 项目评估</h5><ol>
<li> 项目评估的含义及其依据 </li>
<li>项目评估的程序</li>
<li>项目评估的内容</li>
<li>项目评估报告内容大纲</li>
</ol>
<h3 id="四-项目整体管理"><a href="#四-项目整体管理" class="headerlink" title="四 项目整体管理"></a>四 项目整体管理</h3><h4 id="4-1-项目整体管理综述"><a href="#4-1-项目整体管理综述" class="headerlink" title="4.1 项目整体管理综述"></a>4.1 项目整体管理综述</h4><h4 id="4-2-制定项目章程"><a href="#4-2-制定项目章程" class="headerlink" title="4.2 制定项目章程"></a>4.2 制定项目章程</h4><h5 id="4-2-1-制定项目章程的过程"><a href="#4-2-1-制定项目章程的过程" class="headerlink" title="4.2.1 制定项目章程的过程"></a>4.2.1 制定项目章程的过程</h5><h5 id="4-2-2-制定项目章程的依据"><a href="#4-2-2-制定项目章程的依据" class="headerlink" title="4.2.2 制定项目章程的依据"></a>4.2.2 制定项目章程的依据</h5><ol>
<li>协议</li>
<li>项目工作说明书</li>
<li>商业论证</li>
<li>事业环境因素</li>
<li>组织生产过程</li>
</ol>
<h5 id="4-2-3-专家判断"><a href="#4-2-3-专家判断" class="headerlink" title="4.2.3 专家判断"></a>4.2.3 专家判断</h5><h5 id="4-2-4-项目选择方法"><a href="#4-2-4-项目选择方法" class="headerlink" title="4.2.4 项目选择方法"></a>4.2.4 项目选择方法</h5><ol>
<li>净现值分析</li>
<li>投资收益率分析</li>
<li>投资回收期分析</li>
</ol>
<h5 id="4-2-5-项目启动会议"><a href="#4-2-5-项目启动会议" class="headerlink" title="4.2.5 项目启动会议"></a>4.2.5 项目启动会议</h5><ol>
<li>确定会议目标</li>
<li>做好会前准备工作</li>
<li>明确并通知参加会议的人员</li>
<li>明确会议的主要议题</li>
<li>做好记录</li>
</ol>
<h5 id="4-2-6-项目目标"><a href="#4-2-6-项目目标" class="headerlink" title="4.2.6 项目目标"></a>4.2.6 项目目标</h5><ol>
<li>成果指标</li>
<li>制约条件指标</li>
</ol>
<h5 id="4-2-7-引导技术"><a href="#4-2-7-引导技术" class="headerlink" title="4.2.7 引导技术"></a>4.2.7 引导技术</h5><h4 id="4-3-制定项目管理计划"><a href="#4-3-制定项目管理计划" class="headerlink" title="4.3 制定项目管理计划"></a>4.3 制定项目管理计划</h4><h5 id="4-3-1-项目管理计划"><a href="#4-3-1-项目管理计划" class="headerlink" title="4.3.1 项目管理计划"></a>4.3.1 项目管理计划</h5><h5 id="4-3-2-制定项目管理计划的过程"><a href="#4-3-2-制定项目管理计划的过程" class="headerlink" title="4.3.2 制定项目管理计划的过程"></a>4.3.2 制定项目管理计划的过程</h5><h5 id="4-3-3-项目管理信息系统"><a href="#4-3-3-项目管理信息系统" class="headerlink" title="4.3.3 项目管理信息系统"></a>4.3.3 项目管理信息系统</h5><ol>
<li>配置管理系统</li>
<li>变更控制系统</li>
</ol>
<h4 id="4-4-指导与管理项目执行"><a href="#4-4-指导与管理项目执行" class="headerlink" title="4.4 指导与管理项目执行"></a>4.4 指导与管理项目执行</h4><h5 id="4-4-1-指导与管理项目的执行的依据"><a href="#4-4-1-指导与管理项目的执行的依据" class="headerlink" title="4.4.1 指导与管理项目的执行的依据"></a>4.4.1 指导与管理项目的执行的依据</h5><ol>
<li>项目管理计划</li>
<li>批准的变更请求</li>
<li>事业环境因素</li>
<li>组织过程资产</li>
</ol>
<h5 id="4-4-2-指导与管理项目执行的工具与技术"><a href="#4-4-2-指导与管理项目执行的工具与技术" class="headerlink" title="4.4.2 指导与管理项目执行的工具与技术"></a>4.4.2 指导与管理项目执行的工具与技术</h5><ol>
<li>专家判断</li>
<li>项目管理信息系统</li>
<li>会议</li>
</ol>
<h5 id="4-4-3-指导与管理项目执行的成果"><a href="#4-4-3-指导与管理项目执行的成果" class="headerlink" title="4.4.3 指导与管理项目执行的成果"></a>4.4.3 指导与管理项目执行的成果</h5><ol>
<li>可交付的成果</li>
<li>工作绩效数据</li>
<li>变更请求</li>
<li>项目管理计划的更新</li>
<li>项目文件更新</li>
</ol>
<h4 id="4-5-监控项目工作"><a href="#4-5-监控项目工作" class="headerlink" title="4.5 监控项目工作"></a>4.5 监控项目工作</h4><h5 id="4-5-1-监控项目工作的依据"><a href="#4-5-1-监控项目工作的依据" class="headerlink" title="4.5.1 监控项目工作的依据"></a>4.5.1 监控项目工作的依据</h5><ol>
<li>项目管理计划</li>
<li>进度预测</li>
<li>成本预测</li>
<li>确认的变更</li>
<li>工作绩效信息</li>
<li>事业环境因素</li>
<li>组织过程资产</li>
</ol>
<h5 id="4-5-2-监控项目工作的工具与技术"><a href="#4-5-2-监控项目工作的工具与技术" class="headerlink" title="4.5.2 监控项目工作的工具与技术"></a>4.5.2 监控项目工作的工具与技术</h5><ol>
<li>专家判断</li>
<li>分析技术</li>
<li>项目管理信息系统</li>
<li>会议</li>
</ol>
<h5 id="4-5-3-监控项目工作的成果"><a href="#4-5-3-监控项目工作的成果" class="headerlink" title="4.5.3 监控项目工作的成果"></a>4.5.3 监控项目工作的成果</h5><ol>
<li>变更请求</li>
<li>工作绩效报告</li>
<li>项目管理计划更新</li>
<li>项目文件更新</li>
</ol>
<h4 id="4-6-实施整体变更控制"><a href="#4-6-实施整体变更控制" class="headerlink" title="4.6 实施整体变更控制"></a>4.6 实施整体变更控制</h4><h5 id="4-6-1-整体变更控制的依据"><a href="#4-6-1-整体变更控制的依据" class="headerlink" title="4.6.1 整体变更控制的依据"></a>4.6.1 整体变更控制的依据</h5><ol>
<li>项目管理计划 </li>
<li>工作绩效报告</li>
<li>变更请求</li>
<li>事业环境因素</li>
<li>组织生产过程 </li>
</ol>
<h5 id="4-6-2-整体变更控制的工具的与技术"><a href="#4-6-2-整体变更控制的工具的与技术" class="headerlink" title="4.6.2 整体变更控制的工具的与技术"></a>4.6.2 整体变更控制的工具的与技术</h5><ol>
<li>专家判断</li>
<li>会议</li>
<li>变更控制工具</li>
</ol>
<h5 id="4-6-3-整体变更控制的成果"><a href="#4-6-3-整体变更控制的成果" class="headerlink" title="4.6.3 整体变更控制的成果"></a>4.6.3 整体变更控制的成果</h5><ol>
<li>批准的变更请求</li>
<li>变更日志</li>
<li>项目管理计划更新</li>
<li>项目文件更新</li>
</ol>
<h4 id="4-7-结束项目或阶段"><a href="#4-7-结束项目或阶段" class="headerlink" title="4.7 结束项目或阶段"></a>4.7 结束项目或阶段</h4><h5 id="4-7-1-结束项目或阶段的依据"><a href="#4-7-1-结束项目或阶段的依据" class="headerlink" title="4.7.1 结束项目或阶段的依据"></a>4.7.1 结束项目或阶段的依据</h5><ol>
<li>项目管理计划</li>
<li>验收的可交付成果</li>
<li>组织过程资产</li>
</ol>
<h5 id="4-7-2-结束项目或阶段的工具与技术"><a href="#4-7-2-结束项目或阶段的工具与技术" class="headerlink" title="4.7.2 结束项目或阶段的工具与技术"></a>4.7.2 结束项目或阶段的工具与技术</h5><ol>
<li> 专家判断</li>
<li>分析技术</li>
<li>会议</li>
</ol>
<h5 id="4-7-3-结束项目或阶段的成果"><a href="#4-7-3-结束项目或阶段的成果" class="headerlink" title="4.7.3 结束项目或阶段的成果"></a>4.7.3 结束项目或阶段的成果</h5><ol>
<li>最终产品、服务或成果移交</li>
<li>组织过程资产更新</li>
</ol>
<h3 id="五-项目范围管理"><a href="#五-项目范围管理" class="headerlink" title="五 项目范围管理"></a>五 项目范围管理</h3><p>5.1 范围管理概述</p>
<p>5.1.1 产品范围与项目范围</p>
<p>5.1.2 范围管理的重要性</p>
<p>5.1.3 范围管理的过程</p>
<ol>
<li>规划范围管理</li>
<li>收集需求</li>
<li>定义范围</li>
<li>创建WBS(Work Breakdown Structure)</li>
<li>确认范围</li>
<li>控制范围</li>
</ol>
<p>5.2 规范范围管理</p>
<p>5.2.1 范围管理计划</p>
<p>5.2.2 需求管理计划</p>
<p>5.3 收集需求</p>
<p>5.3.1 需求的分类</p>
<p>5.3.2 收集需求的工具与技术</p>
<ol>
<li>访谈</li>
<li>焦点小组</li>
<li>引导式研讨会</li>
<li>群体创新技术<ol>
<li>头脑风暴</li>
<li>名义小组技术</li>
<li>德尔菲技术</li>
<li>概念/思维导图 </li>
<li>亲和图</li>
<li>多标准决策分析</li>
</ol>
</li>
<li>群体决策技术</li>
<li>问卷调查</li>
<li>观察</li>
<li>原型法</li>
<li>标杆对照</li>
<li>系统交互图</li>
<li>文件分析</li>
</ol>
<p>5.3.3 需求文件</p>
<p>5.3.4 需求跟踪</p>
<ol>
<li>需求跟踪的内容 </li>
<li>需求跟踪矩阵</li>
</ol>
<p>5.4 定义范围</p>
<p>5.4.1 定义范围的工具与技术</p>
<ol>
<li>产品分析</li>
<li>备选方案生成</li>
</ol>
<p>5.4.2 项目范围说明书</p>
<ol>
<li>范围说明书的内容</li>
<li>范围说明书的作用</li>
</ol>
<p>5.5 创建工作分解结构</p>
<p>5.5.1 WBS的层次</p>
<ol>
<li>历程碑</li>
<li>工作包</li>
<li>控制账户</li>
<li>规划包</li>
<li>WBS词典</li>
</ol>
<p>5.5.2 分解</p>
<ol>
<li>分解的原则</li>
<li>工作过程</li>
<li>注意事项</li>
</ol>
<p>5.5.3 WBS的作用</p>
<p>5.6 确认范围</p>
<p>5.6.1 确认范围的概述</p>
<ol>
<li>确认范围的步骤</li>
<li>需要检查的问题</li>
</ol>
<p>5.6.2 干系人关注点</p>
<p>5.6.3 几个术语的比较</p>
<ol>
<li>确认范围与核实产品</li>
<li>确认范围与质量控制</li>
<li>确认范围与项目收尾</li>
</ol>
<p>5.7 控制范围</p>
<ol>
<li>范围变更的原因</li>
<li>范围变更控制的工作</li>
</ol>
]]></content>
      <categories>
        <category>软考</category>
      </categories>
  </entry>
</search>
